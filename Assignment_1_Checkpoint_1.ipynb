{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydPwziBqiTDB"
      },
      "source": [
        "# Today\n",
        "- decide if we want to inspect sentences from training\n",
        "- for ovv remove from list of words in training and test also words from glove, other than the ones in training\n",
        "- can we split compound terms?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oweJIGOAiTDF"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
        "\n",
        "**Keywords**: POS tagging, Sequence labelling, RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUQyJvmSiTDG"
      },
      "source": [
        "# [Task 1 - 0.5 points] Corpus\n",
        "\n",
        "You are going to work with the [Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip).\n",
        "\n",
        "**Ignore** the numeric value in the third column, use **only** the words/symbols and their POS label.\n",
        "\n",
        "### Example\n",
        "\n",
        "```Pierre\tNNP\t2\n",
        "Vinken\tNNP\t8\n",
        ",\t,\t2\n",
        "61\tCD\t5\n",
        "years\tNNS\t6\n",
        "old\tJJ\t2\n",
        ",\t,\t2\n",
        "will\tMD\t0\n",
        "join\tVB\t8\n",
        "the\tDT\t11\n",
        "board\tNN\t9\n",
        "as\tIN\t9\n",
        "a\tDT\t15\n",
        "nonexecutive\tJJ\t15\n",
        "director\tNN\t12\n",
        "Nov.\tNNP\t9\n",
        "29\tCD\t16\n",
        ".\t.\t8\n",
        "```\n",
        "\n",
        "### Splits\n",
        "\n",
        "The corpus contains 200 documents.\n",
        "\n",
        "   * **Train**: Documents 1-100\n",
        "   * **Validation**: Documents 101-150\n",
        "   * **Test**: Documents 151-199\n",
        "### Instructions\n",
        "\n",
        "* **Download** the corpus.\n",
        "* **Encode** the corpus into a pandas.DataFrame object.\n",
        "* **Split** it in training, validation, and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbygS-f2iTDG"
      },
      "source": [
        "# [Task 2 - 0.5 points] Text encoding\n",
        "\n",
        "To train a neural POS tagger, you first need to encode text into numerical format.\n",
        "### Instructions\n",
        "\n",
        "* Embed words using **GloVe embeddings**.\n",
        "* You are **free** to pick any embedding dimension.\n",
        "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xMAIuumiTDH"
      },
      "source": [
        "# [Task 3 - 1.0 points] Model definition\n",
        "\n",
        "You are now tasked to define your neural POS tagger.\n",
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
        "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
        "\n",
        "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
        "\n",
        "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEw9T5SPiTDH"
      },
      "source": [
        "# [Task 4 - 1.0 points] Metrics\n",
        "\n",
        "Before training the models, you are tasked to define the evaluation metrics for comparison.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Evaluate your models using macro F1-score, compute over **all** tokens.\n",
        "* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively)\n",
        "* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)\n",
        "\n",
        "**Note**: What about OOV tokens?\n",
        "   * All the tokens in the **training** set that are not in GloVe **must** be added to the vocabulary.\n",
        "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **special token** (e.g., [UNK]) and a **static** embedding.\n",
        "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)\n",
        "### More about OOV\n",
        "\n",
        "For a given token:\n",
        "\n",
        "* **If in train set**: add to vocabulary and assign an embedding (use GloVe if token in GloVe, custom embedding otherwise).\n",
        "* **If in val/test set**: assign special token if not in vocabulary and assign custom embedding.\n",
        "\n",
        "Your vocabulary **should**:\n",
        "\n",
        "* Contain all tokens in train set; or\n",
        "* Union of tokens in train set and in GloVe $\\rightarrow$ we make use of existing knowledge!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXpnk9Q1iTDH"
      },
      "source": [
        "# [Task 5 - 1.0 points] Training and Evaluation\n",
        "\n",
        "You are now tasked to train and evaluate the Baseline, Model 1, and Model 2.\n",
        "### Instructions\n",
        "\n",
        "* Train **all** models on the train set.\n",
        "* Evaluate **all** models on the validation set.\n",
        "* Compute metrics on the validation set.\n",
        "* Pick **at least** three seeds for robust estimation.\n",
        "* Pick the **best** performing model according to the observed validation set performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9bve1gSiTDI"
      },
      "source": [
        "# [Task 6 - 1.0 points] Error Analysis\n",
        "\n",
        "You are tasked to evaluate your best performing model.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Compare the errors made on the validation and test sets.\n",
        "* Aggregate model errors into categories (if possible)\n",
        "* Comment the about errors and propose possible solutions on how to address them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nT-1UeoiTDJ"
      },
      "source": [
        "# [Task 7 - 1.0 points] Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages).\n",
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtOU9cDQiTDJ"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves in Figure format.\n",
        "* The error analysis section should summarize your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpTvvXjgiTDJ"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us\n",
        "\n",
        "### Execution Order\n",
        "\n",
        "You are **free** to address tasks in any order (if multiple orderings are available).\n",
        "\n",
        "### Trainable Embeddings\n",
        "\n",
        "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings.\n",
        "\n",
        "### Model architecture\n",
        "\n",
        "You **should not** change the architecture of a model (i.e., its layers).\n",
        "\n",
        "However, you are **free** to play with their hyper-parameters.\n",
        "\n",
        "### Neural Libraries\n",
        "\n",
        "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)\n",
        "\n",
        "### Keras TimeDistributed Dense layer\n",
        "\n",
        "If you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`.\n",
        "\n",
        "### Robust Evaluation\n",
        "\n",
        "Each model is trained with at least 3 random seeds.\n",
        "\n",
        "Task 4 requires you to compute the average performance over the 3 seeds and its corresponding standard deviation.\n",
        "\n",
        "### Model Selection for Analysis\n",
        "\n",
        "To carry out the error analysis you are **free** to either\n",
        "\n",
        "* Pick examples or perform comparisons with an individual seed run model (e.g., Baseline seed 1337)\n",
        "* Perform ensembling via, for instance, majority voting to obtain a single model.\n",
        "\n",
        "### Error Analysis\n",
        "\n",
        "Some topics for discussion include:\n",
        "   * Model performance on most/less frequent classes.\n",
        "   * Precision/Recall curves.\n",
        "   * Confusion matrices.\n",
        "   * Specific misclassified samples.\n",
        "\n",
        "### Punctuation\n",
        "\n",
        "**Do not** remove punctuation from documents since it may be helpful to the model.\n",
        "\n",
        "You should **ignore** it during metrics computation.\n",
        "\n",
        "If you are curious, you can run additional experiments to verify the impact of removing punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YlPAIyouiTDK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import shutil\n",
        "import urllib\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from typing import Iterable, List, Callable, Dict\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "\n",
        "\n",
        "seed = 812\n",
        "\n",
        "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "# Set environment variable for TensorFlow\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.6387855  -0.89870685  0.07983305  0.19414163 -0.76766497]\n",
            " [-0.38364235  0.4428017   0.6928357  -0.8514683   0.09465076]\n",
            " [ 0.21068816  0.3536609  -0.43506557 -1.0789914   0.34279203]], shape=(3, 5), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.6387855  -0.89870685  0.07983305  0.19414163 -0.76766497]\n",
            " [-0.38364235  0.4428017   0.6928357  -0.8514683   0.09465076]\n",
            " [ 0.21068816  0.3536609  -0.43506557 -1.0789914   0.34279203]], shape=(3, 5), dtype=float32)\n",
            "Are the results equal? True\n"
          ]
        }
      ],
      "source": [
        "glorot_normal_1 = keras.initializers.GlorotNormal(seed=seed)\n",
        "glorot_normal_2 = keras.initializers.GlorotNormal(seed=seed)\n",
        "\n",
        "input_dim, neurons = 3, 5\n",
        "\n",
        "# Call two different objects with same shape\n",
        "result_1 = glorot_normal_1(shape=(input_dim, neurons))\n",
        "result_2 = glorot_normal_2(shape=(input_dim, neurons))\n",
        "print(result_1)\n",
        "print(result_2)\n",
        "# Check if the results are equal.\n",
        "equal = np.allclose(result_1, result_2)\n",
        "print(f\"Are the results equal? {equal}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8pJ4eaLciTDL"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hF3goeVNiTDL"
      },
      "outputs": [],
      "source": [
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "\n",
        "def download_dataset(download_path: Path, url: str):\n",
        "    response = requests.get(url)\n",
        "    with open(download_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "def download_url(download_path: Path, url: str):\n",
        "    print(\"Downloading dataset...\")\n",
        "    download_url(url=url, download_path=download_path)\n",
        "    print(\"Download complete!\")\n",
        "\n",
        "def extract_dataset(download_path: Path, extract_path: Path):\n",
        "    print(\"Extracting dataset... (it may take a while...)\")\n",
        "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Extraction completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMnZiRO2iTDL",
        "outputId": "d24ece9e-0d08-460f-951a-6ae19f69c579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current work directory: d:\\università\\Magistrale\\NLP\\Assignement\\Assignment1NLP\n"
          ]
        }
      ],
      "source": [
        "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
        "dataset_name = \"dependency_treebank\"\n",
        "\n",
        "print(f\"Current work directory: {Path.cwd()}\")\n",
        "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
        "\n",
        "if not dataset_folder.exists():\n",
        "    dataset_folder.mkdir(parents=True)\n",
        "\n",
        "dataset_zip_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\n",
        "dataset_path = dataset_folder.joinpath(dataset_name)\n",
        "\n",
        "if not dataset_zip_path.exists():\n",
        "    download_dataset(dataset_zip_path, url)\n",
        "\n",
        "if not dataset_path.exists():\n",
        "    extract_dataset(dataset_zip_path, dataset_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF-Vs1HPiTDM",
        "outputId": "2bb0834e-95e2-4b5b-dcad-4ac854ac111e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WindowsPath('d:/università/Magistrale/NLP/Assignement/Assignment1NLP/Datasets/dependency_treebank')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder = dataset_folder.joinpath(dataset_name)\n",
        "folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7roXidYqiTDM"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store the data rows\n",
        "dataframe_rows = []\n",
        "index = 0\n",
        "tag_set = set([])\n",
        "# Iterate through the files in the directory with the '.dp' extension\n",
        "for file_path in folder.glob('*.dp'):\n",
        "#file_path = folder.joinpath('wsj_0001.dp')\n",
        "    with file_path.open(mode='r', encoding='utf-8') as text_file:\n",
        "        index+=1\n",
        "        sentence =  '' # word1 + word2\n",
        "        tag = []\n",
        "        lines = text_file.readlines()\n",
        "        # Split the line by whitespace to separate columns\n",
        "        for line in lines:\n",
        "            line_parts = line.split('\\t')\n",
        "            if len(line_parts) == 1: #case '\\n'\n",
        "                dataframe_row = {\n",
        "                    \"sentence\": sentence,\n",
        "                    \"POS\": tag,\n",
        "                    \"index\": index,\n",
        "                    \"split\": 'train' if index <=100 else  'validation' if index<=150 else 'test'\n",
        "                }\n",
        "                dataframe_rows.append(dataframe_row)\n",
        "                sentence =  ''\n",
        "                tag = []\n",
        "            else:\n",
        "                sentence += line_parts[0] + \" \"\n",
        "                tag.append(line_parts[1])\n",
        "                tag_set.add(line_parts[1])\n",
        "        # Last sentence\n",
        "        dataframe_row = {\n",
        "                    \"sentence\": sentence,\n",
        "                    \"POS\": tag,\n",
        "                    \"index\": index,\n",
        "                    \"split\": 'train' if index <=100 else  'validation' if index<=150 else 'test'\n",
        "                }\n",
        "        dataframe_rows.append(dataframe_row)\n",
        "# Create a Pandas DataFrame\n",
        "df = pd.DataFrame(dataframe_rows)\n",
        "df.to_pickle(folder.with_name(dataset_name + \".pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an empty list to store the data rows\n",
        "dataframe_rows = []\n",
        "# Iterate through the files in the directory with the '.dp' extension\n",
        "for file_path in folder.glob('*.dp'):\n",
        "#file_path = folder.joinpath('wsj_0001.dp')\n",
        "    file_sentences =  [] # word1 + word2\n",
        "    tag = []\n",
        "    with file_path.open(mode='r', encoding='utf-8') as text_file:\n",
        "        lines = text_file.readlines()\n",
        "        # Split the line by whitespace to separate columns\n",
        "        for line in lines:\n",
        "            line_parts = line.split('\\t')\n",
        "            if len(line_parts) != 1: #case '\\n'\n",
        "                file_sentences.append(line_parts[0])\n",
        "                tag.append(line_parts[1])\n",
        "        # Last sentence\n",
        "        dataframe_row = {\n",
        "                    \"sentence\": file_sentences,\n",
        "                    \"POS\": tag,\n",
        "                }\n",
        "        dataframe_rows.append(dataframe_row)\n",
        "# Create a Pandas DataFrame\n",
        "df_file = pd.DataFrame(dataframe_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>POS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[A, form, of, asbestos, once, used, to, make, ...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Yields, on, money-market, mutual, funds, cont...</td>\n",
              "      <td>[NNS, IN, JJ, JJ, NNS, VBD, TO, VB, ,, IN, NNS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[J.P., Bolduc, ,, vice, chairman, of, W.R., Gr...</td>\n",
              "      <td>[NNP, NNP, ,, NN, NN, IN, NNP, NNP, CC, NNP, ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>[John, F., Barrett, ,, 40, ,, formerly, execut...</td>\n",
              "      <td>[NNP, NNP, NNP, ,, CD, ,, RB, JJ, NN, NN, CC, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>[Leon, J., Level, ,, vice, president, and, chi...</td>\n",
              "      <td>[NNP, NNP, NNP, ,, NN, NN, CC, NN, JJ, NN, IN,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>[David, A., DiLoreto, ,, president, of, metal,...</td>\n",
              "      <td>[NNP, NNP, NNP, ,, NN, IN, NN, NN, NN, ,, VBD,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>[Two, leading, constitutional-law, experts, sa...</td>\n",
              "      <td>[CD, VBG, NN, NNS, VBD, NNP, NNP, VBZ, RB, VB,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>[Trinity, Industries, Inc., said, it, reached,...</td>\n",
              "      <td>[NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>199 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentence  \\\n",
              "0    [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1    [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "2    [A, form, of, asbestos, once, used, to, make, ...   \n",
              "3    [Yields, on, money-market, mutual, funds, cont...   \n",
              "4    [J.P., Bolduc, ,, vice, chairman, of, W.R., Gr...   \n",
              "..                                                 ...   \n",
              "194  [John, F., Barrett, ,, 40, ,, formerly, execut...   \n",
              "195  [Leon, J., Level, ,, vice, president, and, chi...   \n",
              "196  [David, A., DiLoreto, ,, president, of, metal,...   \n",
              "197  [Two, leading, constitutional-law, experts, sa...   \n",
              "198  [Trinity, Industries, Inc., said, it, reached,...   \n",
              "\n",
              "                                                   POS  \n",
              "0    [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  \n",
              "1    [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  \n",
              "2    [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...  \n",
              "3    [NNS, IN, JJ, JJ, NNS, VBD, TO, VB, ,, IN, NNS...  \n",
              "4    [NNP, NNP, ,, NN, NN, IN, NNP, NNP, CC, NNP, ,...  \n",
              "..                                                 ...  \n",
              "194  [NNP, NNP, NNP, ,, CD, ,, RB, JJ, NN, NN, CC, ...  \n",
              "195  [NNP, NNP, NNP, ,, NN, NN, CC, NN, JJ, NN, IN,...  \n",
              "196  [NNP, NNP, NNP, ,, NN, IN, NN, NN, NN, ,, VBD,...  \n",
              "197  [CD, VBG, NN, NNS, VBD, NNP, NNP, VBZ, RB, VB,...  \n",
              "198  [NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...  \n",
              "\n",
              "[199 rows x 2 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kMWpUXp3iTDN",
        "outputId": "f5482db0-479c-4247-b21f-54c0e2013d75"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>POS</th>\n",
              "      <th>index</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pierre Vinken , 61 years old , will join the b...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mr. Vinken is chairman of Elsevier N.V. , the ...</td>\n",
              "      <td>[NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rudolph Agnew , 55 years old and former chairm...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>2</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A form of asbestos once used to make Kent ciga...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "      <td>3</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The asbestos fiber , crocidolite , is unusuall...</td>\n",
              "      <td>[DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...</td>\n",
              "      <td>3</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>They also said that more than a dozen presiden...</td>\n",
              "      <td>[PRP, RB, VBD, IN, JJR, IN, DT, NN, NNS, VBP, ...</td>\n",
              "      <td>198</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>Sen. Kennedy said in a separate statement that...</td>\n",
              "      <td>[NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...</td>\n",
              "      <td>198</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3911</th>\n",
              "      <td>Trinity Industries Inc. said it reached a prel...</td>\n",
              "      <td>[NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
              "      <td>199</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3912</th>\n",
              "      <td>Terms were n't disclosed .</td>\n",
              "      <td>[NNS, VBD, RB, VBN, .]</td>\n",
              "      <td>199</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>Trinity said it plans to begin delivery in the...</td>\n",
              "      <td>[NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...</td>\n",
              "      <td>199</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3914 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  \\\n",
              "0     Pierre Vinken , 61 years old , will join the b...   \n",
              "1     Mr. Vinken is chairman of Elsevier N.V. , the ...   \n",
              "2     Rudolph Agnew , 55 years old and former chairm...   \n",
              "3     A form of asbestos once used to make Kent ciga...   \n",
              "4     The asbestos fiber , crocidolite , is unusuall...   \n",
              "...                                                 ...   \n",
              "3909  They also said that more than a dozen presiden...   \n",
              "3910  Sen. Kennedy said in a separate statement that...   \n",
              "3911  Trinity Industries Inc. said it reached a prel...   \n",
              "3912                        Terms were n't disclosed .    \n",
              "3913  Trinity said it plans to begin delivery in the...   \n",
              "\n",
              "                                                    POS  index  split  \n",
              "0     [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...      1  train  \n",
              "1     [NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...      1  train  \n",
              "2     [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...      2  train  \n",
              "3     [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...      3  train  \n",
              "4     [DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...      3  train  \n",
              "...                                                 ...    ...    ...  \n",
              "3909  [PRP, RB, VBD, IN, JJR, IN, DT, NN, NNS, VBP, ...    198   test  \n",
              "3910  [NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...    198   test  \n",
              "3911  [NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...    199   test  \n",
              "3912                             [NNS, VBD, RB, VBN, .]    199   test  \n",
              "3913  [NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...    199   test  \n",
              "\n",
              "[3914 rows x 4 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "306npgAkiTDN",
        "outputId": "87bb4519-5ec7-488f-8b41-47cb3d0ae5a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 sentences have disparate input-output lengths.\n"
          ]
        }
      ],
      "source": [
        "#test for same lengths in sentences and POS\n",
        "different_length = [1 if len(input.split()) != len(output) else 0 for input, output in zip(df['sentence'].values, df['POS'])]\n",
        "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeksn63yiTDO",
        "outputId": "c3902039-0462-418d-ff42-69c119fbf138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'RBS', 2: 'WP', 3: 'VBG', 4: 'RB', 5: '-LRB-', 6: 'TO', 7: 'JJR', 8: 'NNP', 9: 'EX', 10: '``', 11: 'VBD', 12: 'RBR', 13: 'WDT', 14: 'IN', 15: 'PRP$', 16: 'NNS', 17: 'NNPS', 18: '-RRB-', 19: ':', 20: 'RP', 21: 'LS', 22: \"''\", 23: 'CD', 24: 'WP$', 25: 'UH', 26: 'POS', 27: 'CC', 28: 'PDT', 29: 'MD', 30: '.', 31: 'PRP', 32: 'WRB', 33: 'DT', 34: ',', 35: 'NN', 36: 'VB', 37: 'VBZ', 38: 'JJS', 39: '$', 40: 'SYM', 41: 'FW', 42: 'VBP', 43: 'VBN', 44: 'JJ', 45: '#'}\n",
            "{'RBS': 1, 'WP': 2, 'VBG': 3, 'RB': 4, '-LRB-': 5, 'TO': 6, 'JJR': 7, 'NNP': 8, 'EX': 9, '``': 10, 'VBD': 11, 'RBR': 12, 'WDT': 13, 'IN': 14, 'PRP$': 15, 'NNS': 16, 'NNPS': 17, '-RRB-': 18, ':': 19, 'RP': 20, 'LS': 21, \"''\": 22, 'CD': 23, 'WP$': 24, 'UH': 25, 'POS': 26, 'CC': 27, 'PDT': 28, 'MD': 29, '.': 30, 'PRP': 31, 'WRB': 32, 'DT': 33, ',': 34, 'NN': 35, 'VB': 36, 'VBZ': 37, 'JJS': 38, '$': 39, 'SYM': 40, 'FW': 41, 'VBP': 42, 'VBN': 43, 'JJ': 44, '#': 45}\n"
          ]
        }
      ],
      "source": [
        "#dictionaries with all the tags in the corpus\n",
        "treebank_index_to_tag = {}\n",
        "treebank_tag_to_index = {}\n",
        "index = 1\n",
        "for tag in tag_set:\n",
        "    treebank_index_to_tag[index] = tag\n",
        "    treebank_tag_to_index[tag] = index\n",
        "    index+=1\n",
        "print(treebank_index_to_tag)\n",
        "print(treebank_tag_to_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd_19p33iTDO"
      },
      "source": [
        "**Section 2:**\n",
        "\n",
        "Text pre-processing, Lemmatization, (Stemming ?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uV-CnbxniTDO"
      },
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def lower(text: str) -> str:\n",
        "    return text.lower() # lower casing words\n",
        "\n",
        "PREPROCESSING_PIPELINE = [\n",
        "                          lower\n",
        "                        ]\n",
        "\n",
        "def text_prepare(text: str,\n",
        "                 filter_methods: List[Callable[[str], str]] = None) -> str:\n",
        "    \"\"\"\n",
        "    Applies a list of pre-processing functions in sequence (reduce).\n",
        "    Note that the order is important here!\n",
        "    \"\"\"\n",
        "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
        "    return reduce(lambda txt, f: f(txt), filter_methods, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdbYruDniTDP",
        "outputId": "1f37f712-1c4b-437a-dfa6-379718a9b62c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Debug] Before:\n",
            "J.P. Bolduc , vice chairman of W.R. Grace & Co. , which holds a 83.4 % interest in this energy-services company , was elected a director . \n",
            "[Debug] After:\n",
            "j.p. bolduc , vice chairman of w.r. grace & co. , which holds a 83.4 % interest in this energy-services company , was elected a director . \n"
          ]
        }
      ],
      "source": [
        "print(f'[Debug] Before:\\n{df.sentence.values[50]}')\n",
        "df['sentence'] = df['sentence'].apply(lambda txt: text_prepare(txt))\n",
        "print(f'[Debug] After:\\n{df.sentence.values[50]}')\n",
        "#maybe convert also POS into lower case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jqRSShmYiTDa"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "def build_vocabulary(df: pd.DataFrame) -> (Dict[int, str],\n",
        "                                           Dict[str, int],\n",
        "                                           List[str]): # builds the vocabulary of the dataset\n",
        "\n",
        "    idx_to_word = OrderedDict() # vocabulary index to word map\n",
        "    word_to_idx = OrderedDict() # word to vocabulary index map (inverse of idx_to_word)\n",
        "\n",
        "    curr_idx = 0\n",
        "    for sentence in tqdm(df.sentence.values):\n",
        "        tokens = sentence.split()\n",
        "        for token in tokens:\n",
        "            if token not in word_to_idx:\n",
        "                word_to_idx[token] = curr_idx\n",
        "                idx_to_word[curr_idx] = token\n",
        "                curr_idx += 1\n",
        "\n",
        "    word_listing = list(idx_to_word.values()) # set of unique terms that make up the vocabulary\n",
        "    return idx_to_word, word_to_idx, word_listing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGifYYXqiTDa",
        "outputId": "0b020406-8027-4b09-f6e3-c141e6d38c3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3914/3914 [00:00<00:00, 279586.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Debug] Index -> Word vocabulary size: 10947\n",
            "[Debug] Word -> Index vocabulary size: 10947\n",
            "[Debug] Some words: [('vinken', 1), (',', 2), ('61', 3), ('years', 4), ('old', 5), ('will', 6), ('join', 7), ('the', 8), ('board', 9), ('as', 10)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "idx_to_word_corpus, word_to_idx_corpus, word_listing_corpus = build_vocabulary(df)\n",
        "print(f'[Debug] Index -> Word vocabulary size: {len(idx_to_word_corpus)}')\n",
        "print(f'[Debug] Word -> Index vocabulary size: {len(word_to_idx_corpus)}')\n",
        "print(f'[Debug] Some words: {[(idx_to_word_corpus[idx], idx) for idx in np.arange(10) + 1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdPkt5n4iTDb",
        "outputId": "b098d525-6381-4488-f4a0-d0847fb41df0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1963/1963 [00:00<00:00, 280382.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Debug] Index -> Word vocabulary size: 7404\n",
            "[Debug] Word -> Index vocabulary size: 7404\n",
            "[Debug] Some words in training: [('vinken', 1), (',', 2), ('61', 3), ('years', 4), ('old', 5), ('will', 6), ('join', 7), ('the', 8), ('board', 9), ('as', 10)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "idx_to_word_train, word_to_idx_train, word_listing_train = build_vocabulary(df[df['split']=='train'])\n",
        "print(f'[Debug] Index -> Word vocabulary size: {len(idx_to_word_train)}')\n",
        "print(f'[Debug] Word -> Index vocabulary size: {len(word_to_idx_train)}')\n",
        "print(f'[Debug] Some words in training: {[(idx_to_word_train[idx], idx) for idx in np.arange(10) + 1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jin2AmXSiTDb",
        "outputId": "e1d651fe-b3b1-4009-9336-ecff14477a08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1951/1951 [00:00<00:00, 278800.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Debug] vocabulary size validation and test: 6986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "_, _, word_listing_val_and_test = build_vocabulary(df[df['split']!='train'])\n",
        "print(f'[Debug] vocabulary size validation and test: {len(word_listing_val_and_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWEUNCppiTDb",
        "outputId": "94b3187f-9935-41cb-900e-5043f2eedf33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "words in training set: 7404\n",
            "words in validation and test set: 6986\n",
            "words not present in training set: 3543\n",
            "size vocabulary of corpus 10947\n",
            "size vocabulary of corpus 10947\n"
          ]
        }
      ],
      "source": [
        "words_in_train_set = set(word_listing_train)\n",
        "words_in_val_and_test_set = set(word_listing_val_and_test)\n",
        "oov = set(words_in_val_and_test_set).difference(words_in_train_set)\n",
        "print('words in training set:',len(words_in_train_set))\n",
        "print('words in validation and test set:',len(words_in_val_and_test_set))\n",
        "print('words not present in training set:',len(oov))\n",
        "print('size vocabulary of corpus', len(word_listing_corpus))\n",
        "print('size vocabulary of corpus', len(words_in_train_set)+len(oov))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oc5CmPiJiTDc"
      },
      "outputs": [],
      "source": [
        "# Check size, content, consistency and toy example\n",
        "def evaluate_vocabulary(idx_to_word: Dict[int, str], word_to_idx: Dict[str, int],\n",
        "                        word_listing: List[str], df: pd.DataFrame, check_default_size: bool = False):\n",
        "    print(\"[Vocabulary Evaluation] Size checking...\")\n",
        "    assert len(idx_to_word) == len(word_to_idx)\n",
        "    assert len(idx_to_word) == len(word_listing)\n",
        "\n",
        "    print(\"[Vocabulary Evaluation] Content checking...\")\n",
        "    for i in tqdm(range(0, len(idx_to_word))):\n",
        "        assert idx_to_word[i] in word_to_idx\n",
        "        assert word_to_idx[idx_to_word[i]] == i\n",
        "\n",
        "    print(\"[Vocabulary Evaluation] Consistency checking...\")\n",
        "    _, _, first_word_listing = build_vocabulary(df)\n",
        "    _, _, second_word_listing = build_vocabulary(df)\n",
        "    assert first_word_listing == second_word_listing\n",
        "\n",
        "    print(\"[Vocabulary Evaluation] Toy example checking...\")\n",
        "    toy_df = pd.DataFrame.from_dict({\n",
        "        'sentence': [\"all that glitters is not gold\", \"all in all i like this assignment\"]\n",
        "    })\n",
        "    _, _, toy_word_listing = build_vocabulary(toy_df)\n",
        "    toy_valid_vocabulary = set(' '.join(toy_df.sentence.values).split())\n",
        "    assert set(toy_word_listing) == toy_valid_vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7DLPCcuiTDc",
        "outputId": "281d164e-ea2b-4c3c-aab8-5e0fda2d19d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary evaluation...\n",
            "[Vocabulary Evaluation] Size checking...\n",
            "[Vocabulary Evaluation] Content checking...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10947/10947 [00:00<00:00, 2736785.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Vocabulary Evaluation] Consistency checking...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3914/3914 [00:00<00:00, 301142.93it/s]\n",
            "100%|██████████| 3914/3914 [00:00<00:00, 301082.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Vocabulary Evaluation] Toy example checking...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 1992.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation completed!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary evaluation...\")\n",
        "evaluate_vocabulary(idx_to_word_corpus, word_to_idx_corpus, word_listing_corpus, df)\n",
        "print(\"Evaluation completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ac4ZxCZViTDd"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "\n",
        "def load_embedding_model(embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:  #50,100,200\n",
        "    download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "    try:\n",
        "        emb_model = gloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "        print(\"Glove: 50, 100, 200, 300\")\n",
        "        raise e\n",
        "    return emb_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZX-SmHviTDd",
        "outputId": "26bf9850-97cc-4817-8785-1509899ae9f0"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 200\n",
        "embedding_model = load_embedding_model(embedding_dimension=embedding_dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jHDwlyOCiTDd"
      },
      "outputs": [],
      "source": [
        "def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                    word_listing: List[str]):\n",
        "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DY8SBQViTDe",
        "outputId": "a4444106-dd94-494a-a177-c379fe406279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total OOV terms: 317 (4.54%)\n"
          ]
        }
      ],
      "source": [
        "# this should be the number of oov from val and test\n",
        "embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
        "oov_terms = oov.difference(embedding_vocabulary) #words that appear only in val and test\n",
        "oov_percentage = float(len(oov_terms)) * 100 / len(word_listing_val_and_test)\n",
        "print(f\"Total OOV terms: {len(oov_terms)} ({oov_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfDAHSUsiTDe",
        "outputId": "abb14c16-8b4a-4814-fa4a-ed870ac57c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size OOV dictionary 317\n",
            "Same size True\n"
          ]
        }
      ],
      "source": [
        "# dictionary for oov to use for static embedding\n",
        "index = 0 #1+len(oov_terms) #here we used word_listing_train instead of oov_terms to start from the last index of the vocabulary\n",
        "oov_to_index_dict = {}\n",
        "index_to_oov_dict = {}\n",
        "for oov in oov_terms:\n",
        "    oov_to_index_dict[oov] = index\n",
        "    index_to_oov_dict[index] = oov\n",
        "    index+=1\n",
        "print('Size OOV dictionary',len(index_to_oov_dict))\n",
        "print('Same size', len(oov_to_index_dict) == len(index_to_oov_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L60hr4JHiTDe",
        "outputId": "e2db0d77-d860-4ae1-bb53-515d0fb59b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total OOV terms: 359 (4.85%)\n"
          ]
        }
      ],
      "source": [
        "oov_terms_train = check_OOV_terms(embedding_model, word_listing_train) #words to embed\n",
        "oov_percentage_train = float(len(oov_terms_train)) * 100 / len(word_listing_train)\n",
        "print(f\"Total OOV terms: {len(oov_terms_train)} ({oov_percentage_train:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWDxIGloiTDe",
        "outputId": "457253fc-6476-417f-ed67-dea0ce73a7b4"
      },
      "outputs": [],
      "source": [
        "new_POS_list = [[treebank_tag_to_index[tag] for tag in tags] for tags in df['POS']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nuvyhBLiTDf",
        "outputId": "18e71f27-03c1-4ca9-f21e-0a0ed04e09bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10632 10947 317 10630\n",
            "Same length True\n",
            "Same length True\n"
          ]
        }
      ],
      "source": [
        "#Vocabulary without oov\n",
        "word_listing = list(set(word_listing_corpus) - oov_terms)\n",
        "word_listing.append('UNK')\n",
        "word_listing.insert(0, (' '))  #may cause an error!!!\n",
        "print(len(word_listing),len(word_listing_corpus),len(oov_terms),len(word_listing_corpus)-len(oov_terms))\n",
        "index=0\n",
        "idx_to_word = {}\n",
        "word_to_idx = {}\n",
        "for word in word_listing:\n",
        "    idx_to_word[index] = word\n",
        "    word_to_idx[word] = index\n",
        "    index+=1\n",
        "print('Same length',len(word_to_idx)==len(idx_to_word))\n",
        "print('Same length',len(word_listing)==len(idx_to_word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovng5DZkiTDg",
        "outputId": "b7ae9843-3932-4919-8e2a-3234931fb888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of sentences:  3914\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "\n",
        "for sentence in df[df['split'] == 'train'].sentence:\n",
        "    sentences.append(sentence)\n",
        "\n",
        "for sentence in df[df['split'] != 'train'].sentence:\n",
        "    words = sentence.split()\n",
        "    modified_words = [word if word not in oov_terms else 'UNK' for word in words]\n",
        "    modified_sentence = ' '.join(modified_words)\n",
        "    sentences.append(modified_sentence)\n",
        "print('Num of sentences: ',len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IV8KJlrHiTDg"
      },
      "outputs": [],
      "source": [
        "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                           embedding_dimension: int,\n",
        "                           word_to_idx: Dict[str, int],\n",
        "                           vocab_size: int,\n",
        "                           oov_terms: Dict[str,int] = None) -> np.ndarray:\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dimension), dtype=np.float32)\n",
        "    for word, idx in tqdm(word_to_idx.items()):\n",
        "        if word == 'UNK':\n",
        "            embedding_matrix[idx] = np.zeros(embedding_dimension)\n",
        "        else:\n",
        "            try:\n",
        "                embedding_vector = embedding_model[word]\n",
        "            except (KeyError, TypeError):\n",
        "                embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "            embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHoKYUIAiTDg",
        "outputId": "3307895c-81cf-46f1-992e-2d59e4d99bd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10632/10632 [00:00<00:00, 483203.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding matrix shape: (10632, 200)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "embedding_matrix = build_embedding_matrix(embedding_model, embedding_dimension, word_to_idx, len(word_to_idx))\n",
        "unknown_idx = word_to_idx['UNK']\n",
        "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StdBH_QWiTDg",
        "outputId": "e272960d-1cf5-45ac-fc14-ac0bd3da3cf5"
      },
      "outputs": [],
      "source": [
        "encoded_sentences = [[word_to_idx[word] for word in sentence.split()] for sentence in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Z8GNIOfaiTDh",
        "outputId": "9fce0892-face-4ed5-f0d8-6ada4db7af03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of longest sentence: 1265\n",
            "Amount of sentences: 3914\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# check length of longest sentence\n",
        "lengths = [len(seq) for seq in df['sentence']]\n",
        "padding_length = 600\n",
        "print(\"Length of longest sentence: {}\".format(max(lengths)))\n",
        "print(\"Amount of sentences: {}\".format((len(lengths))))\n",
        "sns.boxplot(lengths)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of longest sentence: 4534\n",
            "Amount of sentences: 199\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfi0lEQVR4nO3dX0zV9/3H8dfh70EH36mEc0IB4zJjbNH+UrQIW6ObSiRjrL2Rje6szZyma6tS7VzdktX2QpxLaLswq82SeVHp6S7G0otCSvbHzQBKbfnNP3HJEiNgOWAZHLDlgIXP76Lx+9sRdaLW7/nA85GcpHzPW3yfGnue/Z7vOfiMMUYAAACWSfJ6AQAAgNtBxAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwUorXC3xRJicn9dFHHykzM1M+n8/rdQAAwC0wxmhkZES5ublKSrr5uZYZGzEfffSR8vPzvV4DAADchu7ubuXl5d10ZsZGTGZmpqTP/yVkZWV5vA0AALgVw8PDys/Pd5/Hb2bGRszVl5CysrKIGAAALHMrl4JwYS8AALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAOu0traqqqpKra2tXq8CwENEDACrxGIx1dXVqa+vT3V1dYrFYl6vBMAjRAwAqxw5ckQDAwOSpIGBATU0NHi8EQCvEDEArNHT06OGhgYZYyRJxhg1NDSop6fH480AeIGIAWAFY4xee+21Gx6/GjYAZg8iBoAVurq61NHRoYmJibjjExMT6ujoUFdXl0ebAfAKEQPACgUFBVq5cqWSk5PjjicnJ+vhhx9WQUGBR5sB8AoRA8AKPp9P27dvv+Fxn8/nwVYAvETEALBGXl6eqqur3WDx+Xyqrq7Wfffd5/FmALxAxACwyuOPP64FCxZIkrKzs1VdXe3xRgC8QsQAsIrf79eOHTsUCAT03HPPye/3e70SAI+keL0AAExXaWmpSktLvV4DgMc4EwMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArHRHEVNbWyufz6eamhr3mDFGe/bsUW5urjIyMrRmzRqdOXMm7teNjY1p69atys7O1ty5c1VZWamenp64mcHBQYVCITmOI8dxFAqFNDQ0dCfrAgCAGeS2I6ajo0NvvPGGli9fHnd8//79qqurU319vTo6OhQMBrV+/XqNjIy4MzU1NWpsbFQ4HNaxY8d0+fJlVVRUaGJiwp2prq5WZ2enmpub1dzcrM7OToVCodtdFwAAzDTmNoyMjJjFixeblpYWs3r1arN9+3ZjjDGTk5MmGAyaffv2ubOxWMw4jmMOHjxojDFmaGjIpKammnA47M5cvHjRJCUlmebmZmOMMWfPnjWSTHt7uzvT1tZmJJlz587d0o7RaNRIMtFo9HYeIgAA8MB0nr9v60zMM888o29961tat25d3PHz588rEomorKzMPZaenq7Vq1ertbVVknTy5ElduXIlbiY3N1eFhYXuTFtbmxzHUXFxsTuzatUqOY7jzlxrbGxMw8PDcTcAADBzpUz3F4TDYX3wwQfq6OiYcl8kEpEkBQKBuOOBQEAXLlxwZ9LS0jRv3rwpM1d/fSQSUU5OzpTvn5OT485cq7a2Vi+99NJ0Hw4AALDUtM7EdHd3a/v27XrzzTfl9/tvOOfz+eK+NsZMOXata2euN3+z77N7925Fo1H31t3dfdPfDwAA2G1aEXPy5En19/erqKhIKSkpSklJ0dGjR/XrX/9aKSkp7hmYa8+W9Pf3u/cFg0GNj49rcHDwpjN9fX1Tfv9Lly5NOctzVXp6urKysuJuAABg5ppWxKxdu1anTp1SZ2ene1uxYoUef/xxdXZ26itf+YqCwaBaWlrcXzM+Pq6jR4+qtLRUklRUVKTU1NS4md7eXp0+fdqdKSkpUTQa1YkTJ9yZ48ePKxqNujMAAGB2m9Y1MZmZmSosLIw7NnfuXC1YsMA9XlNTo71792rx4sVavHix9u7dqzlz5qi6ulqS5DiONm3apJ07d2rBggWaP3++nn/+eS1btsy9UHjp0qXasGGDNm/erEOHDkmStmzZooqKCi1ZsuSOHzQAALDftC/s/W927dql0dFRPf300xocHFRxcbHee+89ZWZmujOvvPKKUlJStHHjRo2Ojmrt2rU6fPiwkpOT3ZkjR45o27Zt7ruYKisrVV9ff7fXBQAAlvIZY4zXS3wRhoeH5TiOotEo18cAAGCJ6Tx/87OTAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWmlbEvP7661q+fLmysrKUlZWlkpISNTU1ufcbY7Rnzx7l5uYqIyNDa9as0ZkzZ+K+x9jYmLZu3ars7GzNnTtXlZWV6unpiZsZHBxUKBSS4zhyHEehUEhDQ0O3/ygBAMCMM62IycvL0759+/T+++/r/fff1ze/+U195zvfcUNl//79qqurU319vTo6OhQMBrV+/XqNjIy436OmpkaNjY0Kh8M6duyYLl++rIqKCk1MTLgz1dXV6uzsVHNzs5qbm9XZ2alQKHSXHjIAAJgRzB2aN2+e+e1vf2smJydNMBg0+/btc++LxWLGcRxz8OBBY4wxQ0NDJjU11YTDYXfm4sWLJikpyTQ3NxtjjDl79qyRZNrb292ZtrY2I8mcO3fulveKRqNGkolGo3f6EAEAwD0ynefv274mZmJiQuFwWJ988olKSkp0/vx5RSIRlZWVuTPp6elavXq1WltbJUknT57UlStX4mZyc3NVWFjozrS1tclxHBUXF7szq1atkuM47sz1jI2NaXh4OO4GAABmrmlHzKlTp/SlL31J6enpeuqpp9TY2Kj7779fkUhEkhQIBOLmA4GAe18kElFaWprmzZt305mcnJwpv29OTo47cz21tbXuNTSO4yg/P3+6Dw0AAFhk2hGzZMkSdXZ2qr29XT/+8Y/1xBNP6OzZs+79Pp8vbt4YM+XYta6dud78f/s+u3fvVjQadW/d3d23+pAAAICFph0xaWlp+upXv6oVK1aotrZWDz74oF577TUFg0FJmnK2pL+/3z07EwwGNT4+rsHBwZvO9PX1Tfl9L126NOUsz39KT0933zV19QZgZmptbVVVVdVNX2IGMPPd8efEGGM0NjamRYsWKRgMqqWlxb1vfHxcR48eVWlpqSSpqKhIqampcTO9vb06ffq0O1NSUqJoNKoTJ064M8ePH1c0GnVnAMxesVhMdXV16uvrU11dnWKxmNcrAfBIynSGf/azn6m8vFz5+fkaGRlROBzWX//6VzU3N8vn86mmpkZ79+7V4sWLtXjxYu3du1dz5sxRdXW1JMlxHG3atEk7d+7UggULNH/+fD3//PNatmyZ1q1bJ0launSpNmzYoM2bN+vQoUOSpC1btqiiokJLliy5yw8fgG2OHDmigYEBSdLAwIAaGhr0wx/+0OOtAHhhWhHT19enUCik3t5eOY6j5cuXq7m5WevXr5ck7dq1S6Ojo3r66ac1ODio4uJivffee8rMzHS/xyuvvKKUlBRt3LhRo6OjWrt2rQ4fPqzk5GR35siRI9q2bZv7LqbKykrV19ffjccLwGI9PT1qaGiQMUbS52eCGxoaVFZWpry8PI+3A3Cv+czV/xrMMMPDw3IcR9FolOtjgBnAGKNdu3bpgw8+iPtwzOTkZD300EPav3//f30TAYDEN53nb352EgArdHV1qaOjIy5gpM8/s6qjo0NdXV0ebQbAK0QMACsUFBRo5cqVcS89S5+fiXn44YdVUFDg0WYAvELEALCCz+fT9u3bb3icl5KA2YeIAWCNvLw8VVdXu8Hi8/lUXV2t++67z+PNAHiBiAFglccff1wLFiyQJGVnZ7sf4QBg9iFiAFjF7/drx44dCgQCeu655+T3+71eCYBHpvU5MQCQCEpLS/kEbwCciQEAAHYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYaVoRU1tbq5UrVyozM1M5OTl69NFH9c9//jNuxhijPXv2KDc3VxkZGVqzZo3OnDkTNzM2NqatW7cqOztbc+fOVWVlpXp6euJmBgcHFQqF5DiOHMdRKBTS0NDQ7T1KAAAw40wrYo4ePapnnnlG7e3tamlp0WeffaaysjJ98skn7sz+/ftVV1en+vp6dXR0KBgMav369RoZGXFnampq1NjYqHA4rGPHjuny5cuqqKjQxMSEO1NdXa3Ozk41NzerublZnZ2dCoVCd+EhAwCAGcHcgf7+fiPJHD161BhjzOTkpAkGg2bfvn3uTCwWM47jmIMHDxpjjBkaGjKpqakmHA67MxcvXjRJSUmmubnZGGPM2bNnjSTT3t7uzrS1tRlJ5ty5c7e0WzQaNZJMNBq9k4cIAADuoek8f9/RNTHRaFSSNH/+fEnS+fPnFYlEVFZW5s6kp6dr9erVam1tlSSdPHlSV65ciZvJzc1VYWGhO9PW1ibHcVRcXOzOrFq1So7juDPXGhsb0/DwcNwNAADMXLcdMcYY7dixQ1//+tdVWFgoSYpEIpKkQCAQNxsIBNz7IpGI0tLSNG/evJvO5OTkTPk9c3Jy3Jlr1dbWutfPOI6j/Pz8231oAADAArcdMc8++6z+8Y9/6K233ppyn8/ni/vaGDPl2LWunbne/M2+z+7duxWNRt1bd3f3rTwMAABgqduKmK1bt+qdd97RX/7yF+Xl5bnHg8GgJE05W9Lf3++enQkGgxofH9fg4OBNZ/r6+qb8vpcuXZpylueq9PR0ZWVlxd0AAMDMNa2IMcbo2Wef1R/+8Af9+c9/1qJFi+LuX7RokYLBoFpaWtxj4+PjOnr0qEpLSyVJRUVFSk1NjZvp7e3V6dOn3ZmSkhJFo1GdOHHCnTl+/Lii0ag7AwAAZrdpRcwzzzyjN998Uw0NDcrMzFQkElEkEtHo6Kikz18Cqqmp0d69e9XY2KjTp0/rySef1Jw5c1RdXS1JchxHmzZt0s6dO/WnP/1JH374ob7//e9r2bJlWrdunSRp6dKl2rBhgzZv3qz29na1t7dr8+bNqqio0JIlS+7yvwIAtmltbVVVVdUNL/QHMDv4jDHmlodvcD3K7373Oz355JOSPj9b89JLL+nQoUMaHBxUcXGxfvOb37gX/0pSLBbTT37yEzU0NGh0dFRr167VgQMH4i7G/fe//61t27bpnXfekSRVVlaqvr5eX/7yl29p1+HhYTmOo2g0yktLwAwSi8W0ceNGDQ8PKysrS7///e/l9/u9XgvAXTKd5+9pRYxNiBhgZjp06FDcGwqqq6u1ZcsWDzcCcDdN5/mbn50EwBo9PT0Kh8Nxx8Lh8JQfWwJgdiBiAFjBGKNf/vKXuvbk8eTk5HWPA5j5iBgAVrhw4YJOnTp13ftOnTqlCxcu3OONAHiNiAEAAFYiYgBYYeHChVq2bNl171u+fLkWLlx4jzcC4DUiBoAVfD6ffvrTn075qIcbHQcw8xExAKyRl5en7373u3HHvve97+m+++7zaCMAXiJiAFjliSeeUGZmpiQpKytLP/jBDzzeCIBXiBgAVvH7/dq9e7cCgYBeeOEFPq0XmMWIGAAAYCUiBoBVYrGY6urq1NfXp7q6OsViMa9XAuARIgaAVY4cOaKBgQFJ0sDAgBoaGjzeCIBXiBgA1ujp6VFDQ4P7IwaMMWpoaOBnJwGzFBEDwArGGL322ms3PM7PTgJmHyIGgBW6urrU0dGhiYmJuOMTExPq6OhQV1eXR5sB8AoRA8AKBQUFWrly5XU/sffhhx9WQUGBR5sB8AoRA8AKPp9PVVVVU142MsaoqqqKHzsAzEJEDAArGGP09ttvX/e+cDjMNTHALETEALDC1WtirodrYoDZiYgBYIW8vDwlJydf977k5GTl5eXd440AeI2IAWCFEydOTHln0lUTExM6ceLEPd4IgNeIGABWKC4uVlZW1nXvcxxHxcXF93gjAF4jYgBYISkpSb/4xS+ue9+LL76opCT+cwbMNileLwDYwBjDDxpMAA888IDuv/9+nT17Nu7Y0qVLNTo66uFm8Pv9vM0d9xwRA9yCWCym8vJyr9fAdZw5c4Y/mwTQ1NSkjIwMr9fALMP5VwAAYCXOxAC3wO/3q6mpyes1oM/Pij322GOSpMbGRvn9fo83giT+HOAJIga4BT6fj1PlCcjv9/PnAsxivJwEAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADAStOOmL/97W/69re/rdzcXPl8Pv3xj3+Mu98Yoz179ig3N1cZGRlas2aNzpw5EzczNjamrVu3Kjs7W3PnzlVlZaV6enriZgYHBxUKheQ4jhzHUSgU0tDQ0LQfIAAAmJmmHTGffPKJHnzwQdXX11/3/v3796uurk719fXq6OhQMBjU+vXrNTIy4s7U1NSosbFR4XBYx44d0+XLl1VRUaGJiQl3prq6Wp2dnWpublZzc7M6OzsVCoVu4yECAIAZydwBSaaxsdH9enJy0gSDQbNv3z73WCwWM47jmIMHDxpjjBkaGjKpqakmHA67MxcvXjRJSUmmubnZGGPM2bNnjSTT3t7uzrS1tRlJ5ty5c7e0WzQaNZJMNBq9k4cIIMF8+umnZvXq1Wb16tXm008/9XodAHfZdJ6/7+o1MefPn1ckElFZWZl7LD09XatXr1Zra6sk6eTJk7py5UrcTG5urgoLC92ZtrY2OY6j4uJid2bVqlVyHMedAQAAs1vK3fxmkUhEkhQIBOKOBwIBXbhwwZ1JS0vTvHnzpsxc/fWRSEQ5OTlTvn9OTo47c62xsTGNjY25Xw8PD9/+AwEAAAnvC3l3ks/ni/vaGDPl2LWunbne/M2+T21trXsRsOM4ys/Pv43NAQCALe5qxASDQUmacrakv7/fPTsTDAY1Pj6uwcHBm8709fVN+f6XLl2acpbnqt27dysajbq37u7uO348AAAgcd3ViFm0aJGCwaBaWlrcY+Pj4zp69KhKS0slSUVFRUpNTY2b6e3t1enTp92ZkpISRaNRnThxwp05fvy4otGoO3Ot9PR0ZWVlxd0AAMDMNe1rYi5fvqx//etf7tfnz59XZ2en5s+fr4KCAtXU1Gjv3r1avHixFi9erL1792rOnDmqrq6WJDmOo02bNmnnzp1asGCB5s+fr+eff17Lli3TunXrJElLly7Vhg0btHnzZh06dEiStGXLFlVUVGjJkiV343EDAADLTTti3n//fX3jG99wv96xY4ck6YknntDhw4e1a9cujY6O6umnn9bg4KCKi4v13nvvKTMz0/01r7zyilJSUrRx40aNjo5q7dq1Onz4sJKTk92ZI0eOaNu2be67mCorK2/42TQAAGD28RljjNdLfBGGh4flOI6i0SgvLQEzyOjoqMrLyyVJTU1NysjI8HgjAHfTdJ6/+dlJAADASkQMAACwEhEDAACsRMQAAAArETEAAMBKRAwAALASEQMAAKxExAAAACsRMQAAwEpEDAAAsBIRAwAArETEAAAAKxExAADASileL4AbM8YoFot5vQaQUP7z7wR/P4Dr8/v98vl8Xq/xhSNiElgsFlN5ebnXawAJ67HHHvN6BSAhNTU1KSMjw+s1vnC8nAQAAKzEmRhLXP6f78kk8ccFyBhp8rPP/zkpRZoFp8yBW+Gb/Exf6nzL6zXuKZ4VLWGSUqTkVK/XABJEmtcLAAnHeL2AB3g5CQAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlYgYAABgJSIGAABYiYgBAABWImIAAICVUrxeADdmjPn/LyaueLcIACDx/cfzRNzzxwxGxCSwsbEx958z/zfs4SYAAJuMjY1pzpw5Xq/xhePlJAAAYCXOxCSw9PR0959HHvyulJzq4TYAgIQ2ccU9a/+fzx8zGRGTwHw+3/9/kZxKxAAAbknc88cMxstJAADASkQMAACwEhEDAACsRMQAAAArcWGvJXyTn2l2fHQR8F8YI01+9vk/J6VIs+QCRuC/8V39ezGLEDGW+FLnW16vAABAQuHlJAAAYCXOxCQwv9+vpqYmr9cAEkosFtNjjz0mSWpsbJTf7/d4IyDxzJa/F0RMAvP5fMrIyPB6DSBh+f1+/o4AsxgvJwEAACsl/JmYAwcO6Fe/+pV6e3v1wAMP6NVXX9Ujjzzi9VqYZYwxisViXq8BKe7PgT+TxOH3+2fNR90jcSR0xLz99tuqqanRgQMH9LWvfU2HDh1SeXm5zp49q4KCAq/XwywSi8VUXl7u9Rq4xtVrY+C9pqYmXtrDPZfQLyfV1dVp06ZN+tGPfqSlS5fq1VdfVX5+vl5//XWvVwMAAB5L2DMx4+PjOnnypF544YW442VlZWptbZ0yPzY2prGxMffr4eHhL3xHzB68UyxxGGPcv+vp6em8hJEgZsu7YZBYEjZiPv74Y01MTCgQCMQdDwQCikQiU+Zra2v10ksv3av1MMvwTrHEMmfOHK9XAJAAEvrlJElT/i/LGHPd//PavXu3otGoe+vu7r5XKwIAAA8k7JmY7OxsJScnTznr0t/fP+XsjPT5aeX09PR7tR4AAPBYwp6JSUtLU1FRkVpaWuKOt7S0qLS01KOtAABAokjYMzGStGPHDoVCIa1YsUIlJSV644031NXVpaeeesrr1QAAgMcSOmKqqqo0MDCgl19+Wb29vSosLNS7776rhQsXer0aAADwmM8YY7xe4oswPDwsx3EUjUaVlZXl9ToAAOAWTOf5O2GviQEAALgZIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAVkroD7u7E1c//mZ4eNjjTQAAwK26+rx9Kx9jN2MjZmRkRJKUn5/v8SYAAGC6RkZG5DjOTWdm7Cf2Tk5O6qOPPlJmZqZ8Pp/X6wC4i4aHh5Wfn6/u7m4+kRuYYYwxGhkZUW5urpKSbn7Vy4yNGAAzFz9WBIDEhb0AAMBSRAwAALASEQPAOunp6XrxxReVnp7u9SoAPMQ1MQAAwEqciQEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAWCdAwcOaNGiRfL7/SoqKtLf//53r1cC4AEiBoBV3n77bdXU1OjnP/+5PvzwQz3yyCMqLy9XV1eX16sBuMd4izUAqxQXF+uhhx7S66+/7h5bunSpHn30UdXW1nq4GYB7jTMxAKwxPj6ukydPqqysLO54WVmZWltbPdoKgFeIGADW+PjjjzUxMaFAIBB3PBAIKBKJeLQVAK8QMQCs4/P54r42xkw5BmDmI2IAWCM7O1vJyclTzrr09/dPOTsDYOYjYgBYIy0tTUVFRWppaYk73tLSotLSUo+2AuCVFK8XAIDp2LFjh0KhkFasWKGSkhK98cYb6urq0lNPPeX1agDuMSIGgFWqqqo0MDCgl19+Wb29vSosLNS7776rhQsXer0agHuMz4kBAABW4poYAABgJSIGAABYiYgBAABWImIAAICViBgAAGAlIgYAAFiJiAEAAFYiYgAAgJWIGAAAYCUiBgAAWImIAQAAViJiAACAlf4PeCdZio12LNIAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#df_file\n",
        "lengths_file = [len(seq) for seq in df_file['sentence']]\n",
        "padding_length = 600\n",
        "print(\"Length of longest sentence: {}\".format(max(lengths_file)))\n",
        "print(\"Amount of sentences: {}\".format((len(lengths_file))))\n",
        "sns.boxplot(lengths_file)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3914,)\n",
            "3914\n",
            "[False False False ... False False False]\n",
            "['the following were barred or , where noted , suspended and consented to findings without admitting or denying wrongdoing : edward l. cole , jackson , miss. , $ 10,000 fine ; rita rae cross , denver , $ 2,500 fine and 30-day suspension ; thomas richard meinders , colorado springs , colo. , $ 2,000 fine , five-day suspension and eight-month suspension as a principal ; ronald a. cutrer , baton rouge , la. , $ 15,000 fine and one-month suspension ; karl grant hale , midvale , utah , $ 15,000 fine ; clinton p. hayne , new orleans , $ 7,500 fine and one-week suspension ; richard m. kane , coconut creek , fla. , $ 250,000 fine ; john b. merrick , aurora , colo. , $ 1,000 fine and 10-day suspension ; john p. miller , baton rouge , $ 2,000 fine and two-week suspension ; randolph k. pace , new york , $ 10,000 fine and 90-day suspension ; brian d. pitcher , new providence , n.j. , $ 30,000 fine ; wayne a. russo , bridgeville , pa. , $ 4,000 fine and 15-day suspension ; orville leroy sandberg , aurora , colo. , $ 3,500 fine and 10-day suspension ; richard t. marchese , las vegas , nev. , $ 5,000 and one-year suspension ; eric g. monchecourt , las vegas , $ 5,000 and one-year suspension ; and robert gerhard smith , carson city , nev. , two-year suspension . ']\n",
            "1854\n"
          ]
        }
      ],
      "source": [
        "np_len = np.array(lengths)\n",
        "print(np_len.shape)\n",
        "phrases = [seq for seq in df['sentence']]\n",
        "print(len(phrases))\n",
        "positions = np_len > 600\n",
        "print(positions)\n",
        "#print(sum(np_len < 200))\n",
        "looooong_sentences = []\n",
        "for i in range(np_len.shape[0]):\n",
        "    if positions[i]:\n",
        "        looooong_sentences.append(phrases[i])\n",
        "print(looooong_sentences)\n",
        "\n",
        "for i in range(len(phrases)):\n",
        "    if phrases[i] == looooong_sentences[0]:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOH_iX9fiTDh",
        "outputId": "f8ed6bb5-a8f4-4b33-f42a-676ed809414b"
      },
      "outputs": [],
      "source": [
        "from keras.utils import pad_sequences\n",
        "padded_sentences = pad_sequences(\n",
        "    encoded_sentences,\n",
        "    maxlen=padding_length,\n",
        "    padding='pre',\n",
        "    truncating='pre',\n",
        "    value=0 #his should be the space\n",
        ")\n",
        "padded_POS = pad_sequences(\n",
        "    new_POS_list,\n",
        "    maxlen=padding_length,\n",
        "    padding='pre',\n",
        "    truncating='pre',\n",
        "    value=0#10631\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HROcs8Y_iTDh"
      },
      "outputs": [],
      "source": [
        "# padded_sentences phrase x padding+real length\n",
        "#df_POS_new\n",
        "from keras.utils import to_categorical\n",
        "training_samples = df[df['split']=='train'].count().sentence\n",
        "validation_samples = df[df['split']=='validation'].count().sentence\n",
        "validation_samples+=training_samples\n",
        "\n",
        "X_train = padded_sentences[:training_samples,:]\n",
        "Y_train = to_categorical(padded_POS[:training_samples,:])\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "\n",
        "X_val = padded_sentences[training_samples:validation_samples,:]\n",
        "Y_val = to_categorical(padded_POS[training_samples:validation_samples,:])\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
        "\n",
        "X_test = padded_sentences[validation_samples:,:]\n",
        "Y_test = to_categorical(padded_POS[validation_samples:,:])\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(X_train),seed=seed).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "validation_dataset = validation_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRAfV8UgiTDh",
        "outputId": "a9351bdf-db02-4434-ef1f-269f66be2f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train.shape: (1963, 600)\n",
            "Y_train.shape: (1963, 600, 46)\n",
            "X_val.shape: (1299, 600)\n",
            "Y_val.shape: (1299, 600, 46)\n",
            "X_test.shape: (652, 600)\n",
            "Y_test.shape: (652, 600, 45)\n",
            "embedding_matrix.shape: (10632, 200)\n"
          ]
        }
      ],
      "source": [
        "variables = {\n",
        "    \"X_train\": X_train,\n",
        "    \"Y_train\": Y_train,\n",
        "    \"X_val\": X_val,\n",
        "    \"Y_val\": Y_val,\n",
        "    \"X_test\": X_test,\n",
        "    \"Y_test\": Y_test,\n",
        "    \"embedding_matrix\": embedding_matrix\n",
        "}\n",
        "\n",
        "for name, value in variables.items():\n",
        "    print(f\"{name}.shape:\", value.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ZVesomGAiTDh"
      },
      "outputs": [],
      "source": [
        "treebank_index_to_tag[0] = ' '\n",
        "treebank_tag_to_index[' '] = 0\n",
        "punctuations_indeces = [0,27,36,41,42,43]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "def macro_f1_score(num_classes, ignore_class_indices):\n",
        "    def f1(y_true, y_pred):\n",
        "        f1_scores = []\n",
        "        for i in range(num_classes):\n",
        "            if i not in ignore_class_indices:\n",
        "                true_positives = K.sum(K.cast(y_true[:, :, i] * y_pred[:, :, i], 'float32'))\n",
        "                possible_positives = K.sum(K.cast(y_true[:, :, i], 'float32'))\n",
        "                predicted_positives = K.sum(K.cast(y_pred[:, :, i], 'float32'))\n",
        "\n",
        "                precision = true_positives / (predicted_positives + K.epsilon())\n",
        "                recall = true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "                f1 = 2 * (precision * recall) / (precision + recall + K.epsilon()) if (precision + recall) > K.epsilon() else 0.0\n",
        "                f1_scores.append(f1)\n",
        "\n",
        "        macro_f1 = K.mean(K.stack(f1_scores), axis=0)\n",
        "        return macro_f1\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiCGWGmLiTDi",
        "outputId": "f864d2eb-44ce-4a43-dbcb-a2c4d51eee0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 600, 200)          2126400   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 600, 128)          135680    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 600, 46)           5934      \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2268014 (8.65 MB)\n",
            "Trainable params: 141614 (553.18 KB)\n",
            "Non-trainable params: 2126400 (8.11 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed\n",
        "bidirect_model = Sequential()\n",
        "bidirect_model.add(Embedding(input_dim     = len(word_to_idx),\n",
        "                             output_dim    = embedding_dimension,\n",
        "                             input_length  = padding_length,\n",
        "                             weights       = [embedding_matrix],\n",
        "                             trainable     = False\n",
        "))\n",
        "bidirect_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "bidirect_model.add(TimeDistributed(Dense(units=len(treebank_index_to_tag), activation='softmax'))) #test if adding whitespace to vocabulary makes some differences\n",
        "# Compile the model\n",
        "bidirect_model.compile(optimizer='adam',\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=[macro_f1_score(num_classes=len(treebank_index_to_tag), ignore_class_indices=punctuations_indeces)])\n",
        "\n",
        "# Display the model summary\n",
        "bidirect_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "31/31 [==============================] - 33s 916ms/step - loss: 1.3585 - f1: 0.0071 - val_loss: 0.1542 - val_f1: 0.0143\n",
            "Epoch 2/3\n",
            "31/31 [==============================] - 26s 833ms/step - loss: 0.1421 - f1: 0.0179 - val_loss: 0.1306 - val_f1: 0.0208\n",
            "Epoch 3/3\n",
            "31/31 [==============================] - 26s 833ms/step - loss: 0.1245 - f1: 0.0244 - val_loss: 0.1185 - val_f1: 0.0270\n"
          ]
        }
      ],
      "source": [
        "history_bidirectional_model = bidirect_model.fit(train_dataset, epochs=3, validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 3s 232ms/step - loss: 0.1165 - f1: 0.0261\n",
            "Loss: 0.11650922149419785,\n",
            "Macro F1 Score: 0.026055430993437767\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model, which will use the custom F1 score metric that ignores punctuation\n",
        "loss, f1 = bidirect_model.evaluate(test_dataset, verbose=1)\n",
        "\n",
        "# Print the loss and macro F1 score\n",
        "print(\"Loss: {0},\\nMacro F1 Score: {1}\".format(loss, f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': [1.3584645986557007, 0.14206714928150177, 0.12452154606580734], 'f1': [0.007059754338115454, 0.01792820170521736, 0.02440224587917328], 'val_loss': [0.15416070818901062, 0.13059855997562408, 0.11847259849309921], 'val_f1': [0.014303854666650295, 0.02083178423345089, 0.02695852890610695]}\n"
          ]
        }
      ],
      "source": [
        "history_dict = history_bidirectional_model.history\n",
        "print(history_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "31/31 [==============================] - 27s 743ms/step - loss: 1.9343 - f1: 0.0033 - val_loss: 0.2331 - val_f1: 0.0086\n",
            "Epoch 2/40\n",
            "31/31 [==============================] - 22s 700ms/step - loss: 0.1693 - f1: 0.0139 - val_loss: 0.1462 - val_f1: 0.0168\n",
            "Epoch 3/40\n",
            "31/31 [==============================] - 22s 707ms/step - loss: 0.1382 - f1: 0.0200 - val_loss: 0.1313 - val_f1: 0.0221\n",
            "Epoch 4/40\n",
            "31/31 [==============================] - 22s 699ms/step - loss: 0.1255 - f1: 0.0257 - val_loss: 0.1206 - val_f1: 0.0281\n",
            "Epoch 5/40\n",
            "31/31 [==============================] - 23s 736ms/step - loss: 0.1153 - f1: 0.0328 - val_loss: 0.1111 - val_f1: 0.0361\n",
            "Epoch 6/40\n",
            "31/31 [==============================] - 23s 730ms/step - loss: 0.1056 - f1: 0.0426 - val_loss: 0.1018 - val_f1: 0.0470\n",
            "Epoch 7/40\n",
            "31/31 [==============================] - 22s 697ms/step - loss: 0.0959 - f1: 0.0559 - val_loss: 0.0925 - val_f1: 0.0617\n",
            "Epoch 8/40\n",
            "31/31 [==============================] - 22s 709ms/step - loss: 0.0863 - f1: 0.0733 - val_loss: 0.0835 - val_f1: 0.0801\n",
            "Epoch 9/40\n",
            "31/31 [==============================] - 22s 700ms/step - loss: 0.0772 - f1: 0.0938 - val_loss: 0.0753 - val_f1: 0.1006\n",
            "Epoch 10/40\n",
            "31/31 [==============================] - 22s 709ms/step - loss: 0.0690 - f1: 0.1166 - val_loss: 0.0679 - val_f1: 0.1228\n",
            "Epoch 11/40\n",
            "19/31 [=================>............] - ETA: 7s - loss: 0.0626 - f1: 0.1361"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "\n",
        "# Define hyperparameters\n",
        "#embedding_dimensions = [100, 200, 300] # build the actual matrices\n",
        "#optimizers = [Adam, RMSprop, SGD]\n",
        "#batch_sizes = [32, 64, 128]\n",
        "lstm_sizes = [32, 64, 128]\n",
        "embedding_training_bool = [True,False]\n",
        "#learning_rates = [0.001, 0.01, 0.1]  # Define learning rates to be used\n",
        "\n",
        "# Create a function to build and compile the model with given hyperparameters\n",
        "def build_model(embedding_trainable_bool, lstm_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim= len(word_to_idx),\n",
        "                        output_dim    = embedding_dimension,\n",
        "                        input_length  = padding_length,\n",
        "                        weights       = [embedding_matrix],\n",
        "                        trainable     = embedding_trainable_bool\n",
        "    ))    \n",
        "    model.add(Bidirectional(LSTM(units=lstm_size, return_sequences=True)))\n",
        "    model.add(TimeDistributed(Dense(units=len(treebank_index_to_tag), activation='softmax')))\n",
        "    model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
        "                       metrics=[macro_f1_score(num_classes=len(treebank_index_to_tag), ignore_class_indices=punctuations_indeces)])\n",
        "    return model\n",
        "\n",
        "# Assume you have vocab_size and max_sequence_length defined\n",
        "\n",
        "# Grid search loop\n",
        "best_f1 = 0\n",
        "best_params = {}\n",
        "for (emb_training_bool, lstm_size) in product(embedding_training_bool, lstm_sizes):\n",
        "    model = build_model(emb_training_bool, lstm_size)\n",
        "    history_model = model.fit(train_dataset, epochs=40, validation_data=validation_dataset)\n",
        "    f1 = np.max(history_model.history['f1'])\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_params = {\n",
        "            'trainability embedding': emb_training_bool,\n",
        "            'lstm_size': lstm_size,\n",
        "        }\n",
        "\n",
        "print(\"Best f1:\", best_f1)\n",
        "print(\"Best hyperparameters:\", best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpSQPlRBiTDi",
        "outputId": "27d047ed-0e26-4fa3-e368-44607bc231a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "31/31 [==============================] - 16s 514ms/step - loss: 0.0248 - f1: 0.3979 - val_loss: 0.0273 - val_f1: 0.3813\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 15s 485ms/step - loss: 0.0242 - f1: 0.4044 - val_loss: 0.0267 - val_f1: 0.3875\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 15s 492ms/step - loss: 0.0235 - f1: 0.4106 - val_loss: 0.0262 - val_f1: 0.3933\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 15s 497ms/step - loss: 0.0229 - f1: 0.4163 - val_loss: 0.0257 - val_f1: 0.3987\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 17s 536ms/step - loss: 0.0224 - f1: 0.4222 - val_loss: 0.0252 - val_f1: 0.4040\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 16s 517ms/step - loss: 0.0218 - f1: 0.4275 - val_loss: 0.0247 - val_f1: 0.4090\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 16s 505ms/step - loss: 0.0213 - f1: 0.4326 - val_loss: 0.0242 - val_f1: 0.4140\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 16s 513ms/step - loss: 0.0208 - f1: 0.4385 - val_loss: 0.0238 - val_f1: 0.4186\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 15s 493ms/step - loss: 0.0203 - f1: 0.4431 - val_loss: 0.0234 - val_f1: 0.4228\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 15s 500ms/step - loss: 0.0199 - f1: 0.4472 - val_loss: 0.0230 - val_f1: 0.4274\n"
          ]
        }
      ],
      "source": [
        "history_bidirectional_model = bidirect_model.fit(X_train, Y_train, batch_size=64, epochs=10, validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekSe-6E8iTDi",
        "outputId": "0fc1aba7-140d-40e8-cb05-5e86c435fd9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 1s 65ms/step - loss: 0.0208 - f1: 0.4264\n",
            "Loss: 0.020767146721482277,\n",
            "Macro F1 Score: 0.42644646763801575\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model, which will use the custom F1 score metric that ignores punctuation\n",
        "loss, f1 = bidirect_model.evaluate(X_test, Y_test, verbose=1)\n",
        "\n",
        "# Print the loss and macro F1 score\n",
        "print(\"Loss: {0},\\nMacro F1 Score: {1}\".format(loss, f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(652, 600)"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true_classes = np.argmax(Y_test, axis=-1)\n",
        "y_true_classes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'RBS': 1,\n",
              " 'NNPS': 2,\n",
              " 'LS': 3,\n",
              " 'DT': 4,\n",
              " 'POS': 5,\n",
              " 'NNS': 6,\n",
              " 'PRP$': 7,\n",
              " '#': 8,\n",
              " 'JJS': 9,\n",
              " 'WP$': 10,\n",
              " 'JJ': 11,\n",
              " 'VB': 12,\n",
              " ',': 13,\n",
              " 'VBD': 14,\n",
              " 'FW': 15,\n",
              " 'PDT': 16,\n",
              " 'WRB': 17,\n",
              " 'VBN': 18,\n",
              " 'EX': 19,\n",
              " 'CD': 20,\n",
              " 'VBP': 21,\n",
              " 'TO': 22,\n",
              " '.': 23,\n",
              " '-RRB-': 24,\n",
              " 'RB': 25,\n",
              " 'WDT': 26,\n",
              " 'JJR': 27,\n",
              " 'IN': 28,\n",
              " 'UH': 29,\n",
              " 'PRP': 30,\n",
              " ':': 31,\n",
              " 'SYM': 32,\n",
              " 'VBG': 33,\n",
              " 'RP': 34,\n",
              " '-LRB-': 35,\n",
              " 'CC': 36,\n",
              " 'NN': 37,\n",
              " 'RBR': 38,\n",
              " 'MD': 39,\n",
              " '$': 40,\n",
              " \"''\": 41,\n",
              " 'NNP': 42,\n",
              " 'WP': 43,\n",
              " '``': 44,\n",
              " 'VBZ': 45,\n",
              " ' ': 0}"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_to_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 1s 63ms/step\n",
            "(652, 600)\n",
            "Misclassified Pair: ('NN', 'JJ'), Frequency: 183\n",
            "Misclassified Pair: ('NN', 'NNP'), Frequency: 136\n",
            "Misclassified Pair: ('JJ', 'NN'), Frequency: 99\n",
            "Misclassified Pair: ('NNP', 'NN'), Frequency: 92\n",
            "Misclassified Pair: ('NN', 'NNS'), Frequency: 71\n",
            "Misclassified Pair: (' ', 'NNP'), Frequency: 66\n",
            "Misclassified Pair: ('NNS', 'NN'), Frequency: 59\n",
            "Misclassified Pair: ('NNP', 'CD'), Frequency: 59\n",
            "Misclassified Pair: ('JJ', 'NNP'), Frequency: 50\n",
            "Misclassified Pair: ('NNP', 'JJ'), Frequency: 43\n",
            "Misclassified Pair: ('NN', 'VBG'), Frequency: 39\n",
            "Misclassified Pair: ('NNS', 'JJ'), Frequency: 33\n",
            "Misclassified Pair: ('VBN', 'VBD'), Frequency: 31\n",
            "Misclassified Pair: ('JJ', 'NNS'), Frequency: 29\n",
            "Misclassified Pair: ('VBD', 'VBN'), Frequency: 28\n",
            "Misclassified Pair: ('IN', 'WDT'), Frequency: 28\n",
            "Misclassified Pair: ('VBN', 'RB'), Frequency: 27\n",
            "Misclassified Pair: ('RP', 'RB'), Frequency: 24\n",
            "Misclassified Pair: ('RB', 'JJ'), Frequency: 23\n",
            "Misclassified Pair: ('NN', 'VBN'), Frequency: 22\n",
            "Misclassified Pair: ('JJ', 'VBG'), Frequency: 22\n",
            "Misclassified Pair: ('IN', 'RB'), Frequency: 22\n",
            "Misclassified Pair: ('JJ', 'VBN'), Frequency: 22\n",
            "Misclassified Pair: ('NN', 'VBZ'), Frequency: 21\n",
            "Misclassified Pair: ('RB', 'IN'), Frequency: 21\n",
            "Misclassified Pair: ('NNP', 'NNPS'), Frequency: 21\n",
            "Misclassified Pair: ('NNS', 'NNPS'), Frequency: 20\n",
            "Misclassified Pair: ('JJ', 'RB'), Frequency: 19\n",
            "Misclassified Pair: ('NN', 'VBD'), Frequency: 18\n",
            "Misclassified Pair: ('JJ', 'JJS'), Frequency: 16\n",
            "Misclassified Pair: ('IN', 'WRB'), Frequency: 15\n",
            "Misclassified Pair: ('RP', 'IN'), Frequency: 15\n",
            "Misclassified Pair: ('NNS', 'VBD'), Frequency: 15\n",
            "Misclassified Pair: ('NNP', 'VBD'), Frequency: 15\n",
            "Misclassified Pair: ('VBD', 'JJR'), Frequency: 14\n",
            "Misclassified Pair: ('NNP', 'NNS'), Frequency: 14\n",
            "Misclassified Pair: ('CD', 'NN'), Frequency: 14\n",
            "Misclassified Pair: ('CD', 'NNS'), Frequency: 14\n",
            "Misclassified Pair: ('VBN', 'JJ'), Frequency: 14\n",
            "Misclassified Pair: ('NN', 'CD'), Frequency: 13\n",
            "Misclassified Pair: ('VBG', 'VBD'), Frequency: 12\n",
            "Misclassified Pair: ('IN', 'RP'), Frequency: 12\n",
            "Misclassified Pair: (' ', 'NN'), Frequency: 12\n",
            "Misclassified Pair: ('IN', 'VBG'), Frequency: 11\n",
            "Misclassified Pair: ('VBG', 'NN'), Frequency: 11\n",
            "Misclassified Pair: ('VB', 'JJ'), Frequency: 11\n",
            "Misclassified Pair: ('IN', 'DT'), Frequency: 11\n",
            "Misclassified Pair: ('RB', 'VBN'), Frequency: 11\n",
            "Misclassified Pair: ('VB', 'VBP'), Frequency: 11\n",
            "Misclassified Pair: ('IN', 'JJ'), Frequency: 11\n",
            "Misclassified Pair: ('CD', 'JJ'), Frequency: 10\n",
            "Misclassified Pair: ('CD', 'VBD'), Frequency: 10\n",
            "Misclassified Pair: ('NNP', 'VBN'), Frequency: 10\n",
            "Misclassified Pair: ('VB', 'NN'), Frequency: 10\n",
            "Misclassified Pair: ('NNS', 'NNP'), Frequency: 10\n",
            "Misclassified Pair: ('VBG', 'VBN'), Frequency: 9\n",
            "Misclassified Pair: ('NNS', 'VBP'), Frequency: 9\n",
            "Misclassified Pair: ('VBD', 'RB'), Frequency: 9\n",
            "Misclassified Pair: ('NNS', 'VBG'), Frequency: 9\n",
            "Misclassified Pair: ('NN', 'IN'), Frequency: 9\n",
            "Misclassified Pair: ('JJ', 'VB'), Frequency: 8\n",
            "Misclassified Pair: ('JJ', 'IN'), Frequency: 8\n",
            "Misclassified Pair: ('RB', 'VBG'), Frequency: 8\n",
            "Misclassified Pair: ('NNS', 'RB'), Frequency: 8\n",
            "Misclassified Pair: ('NNP', '-LRB-'), Frequency: 8\n",
            "Misclassified Pair: ('NN', 'JJS'), Frequency: 7\n",
            "Misclassified Pair: ('NN', 'VBP'), Frequency: 7\n",
            "Misclassified Pair: ('VB', 'VBN'), Frequency: 7\n",
            "Misclassified Pair: ('NN', 'RB'), Frequency: 7\n",
            "Misclassified Pair: ('DT', 'RB'), Frequency: 7\n",
            "Misclassified Pair: ('RB', 'VBD'), Frequency: 7\n",
            "Misclassified Pair: ('JJ', 'JJR'), Frequency: 7\n",
            "Misclassified Pair: ('VBN', 'VBG'), Frequency: 6\n",
            "Misclassified Pair: ('JJ', 'CD'), Frequency: 6\n",
            "Misclassified Pair: ('NNS', 'JJR'), Frequency: 6\n",
            "Misclassified Pair: (' ', 'NNS'), Frequency: 6\n",
            "Misclassified Pair: ('CD', '-LRB-'), Frequency: 6\n",
            "Misclassified Pair: ('CD', '-RRB-'), Frequency: 6\n",
            "Misclassified Pair: ('VB', 'CD'), Frequency: 6\n",
            "Misclassified Pair: ('PRP', 'RB'), Frequency: 6\n",
            "Misclassified Pair: ('NNP', '-RRB-'), Frequency: 6\n",
            "Misclassified Pair: ('VBN', 'NNP'), Frequency: 6\n",
            "Misclassified Pair: ('VBZ', 'NNS'), Frequency: 6\n",
            "Misclassified Pair: ('JJ', 'VBD'), Frequency: 5\n",
            "Misclassified Pair: ('NN', 'VB'), Frequency: 5\n",
            "Misclassified Pair: ('VB', 'NNS'), Frequency: 5\n",
            "Misclassified Pair: ('VBG', 'NNS'), Frequency: 5\n",
            "Misclassified Pair: ('VBP', 'VB'), Frequency: 5\n",
            "Misclassified Pair: ('RB', 'VBP'), Frequency: 5\n",
            "Misclassified Pair: ('VBP', 'MD'), Frequency: 5\n",
            "Misclassified Pair: ('RB', 'JJR'), Frequency: 5\n",
            "Misclassified Pair: ('MD', 'VBN'), Frequency: 5\n",
            "Misclassified Pair: ('JJ', 'DT'), Frequency: 5\n",
            "Misclassified Pair: ('DT', 'EX'), Frequency: 5\n",
            "Misclassified Pair: ('NNS', 'IN'), Frequency: 5\n",
            "Misclassified Pair: ('JJR', 'RBR'), Frequency: 5\n",
            "Misclassified Pair: ('CD', 'NNP'), Frequency: 5\n",
            "Misclassified Pair: ('NN', '-RRB-'), Frequency: 5\n",
            "Misclassified Pair: ('NNS', 'VBN'), Frequency: 5\n",
            "Misclassified Pair: ('DT', 'JJ'), Frequency: 5\n",
            "Misclassified Pair: ('RB', 'NNS'), Frequency: 5\n",
            "Misclassified Pair: ('CD', 'RB'), Frequency: 5\n",
            "Misclassified Pair: ('IN', 'NN'), Frequency: 5\n",
            "Misclassified Pair: ('JJ', 'VBP'), Frequency: 5\n",
            "Misclassified Pair: ('CD', 'JJS'), Frequency: 5\n",
            "Misclassified Pair: ('RB', 'NN'), Frequency: 4\n",
            "Misclassified Pair: ('NNP', 'VBZ'), Frequency: 4\n",
            "Misclassified Pair: ('MD', 'NNP'), Frequency: 4\n",
            "Misclassified Pair: ('POS', 'VBZ'), Frequency: 4\n",
            "Misclassified Pair: ('VB', 'VBG'), Frequency: 4\n",
            "Misclassified Pair: ('VB', 'RB'), Frequency: 4\n",
            "Misclassified Pair: ('RB', 'DT'), Frequency: 4\n",
            "Misclassified Pair: (' ', 'JJ'), Frequency: 4\n",
            "Misclassified Pair: ('VBP', 'WRB'), Frequency: 4\n",
            "Misclassified Pair: ('JJ', 'WP$'), Frequency: 4\n",
            "Misclassified Pair: ('VBD', 'NNS'), Frequency: 4\n",
            "Misclassified Pair: ('DT', 'CD'), Frequency: 4\n",
            "Misclassified Pair: ('VBG', 'NNP'), Frequency: 4\n",
            "Misclassified Pair: ('VBD', 'VBG'), Frequency: 3\n",
            "Misclassified Pair: (' ', 'VBG'), Frequency: 3\n",
            "Misclassified Pair: ('VB', 'MD'), Frequency: 3\n",
            "Misclassified Pair: ('JJ', 'RBR'), Frequency: 3\n",
            "Misclassified Pair: ('JJ', 'RBS'), Frequency: 3\n",
            "Misclassified Pair: ('VB', 'IN'), Frequency: 3\n",
            "Misclassified Pair: ('IN', 'VBN'), Frequency: 3\n",
            "Misclassified Pair: ('VBD', 'NNPS'), Frequency: 3\n",
            "Misclassified Pair: ('JJ', 'VBZ'), Frequency: 3\n",
            "Misclassified Pair: ('VB', 'JJR'), Frequency: 3\n",
            "Misclassified Pair: ('RB', 'CC'), Frequency: 3\n",
            "Misclassified Pair: ('NNS', 'VBZ'), Frequency: 3\n",
            "Misclassified Pair: ('NNS', 'VB'), Frequency: 3\n",
            "Misclassified Pair: ('RB', 'RBR'), Frequency: 3\n",
            "Misclassified Pair: ('PRP$', 'VB'), Frequency: 3\n",
            "Misclassified Pair: ('VBZ', 'NNP'), Frequency: 3\n",
            "Misclassified Pair: ('VBD', 'NN'), Frequency: 3\n",
            "Misclassified Pair: ('VB', 'NNP'), Frequency: 3\n",
            "Misclassified Pair: ('VBN', 'NN'), Frequency: 3\n",
            "Misclassified Pair: ('VBZ', 'RB'), Frequency: 3\n",
            "Misclassified Pair: ('RB', 'RP'), Frequency: 3\n",
            "Misclassified Pair: ('NNS', 'DT'), Frequency: 3\n",
            "Misclassified Pair: ('NNP', 'VBG'), Frequency: 3\n",
            "Misclassified Pair: ('VBD', 'JJ'), Frequency: 3\n",
            "Misclassified Pair: ('VBD', 'RBR'), Frequency: 3\n",
            "Misclassified Pair: ('NNP', 'RB'), Frequency: 3\n",
            "Misclassified Pair: ('RB', 'WRB'), Frequency: 3\n",
            "Misclassified Pair: ('DT', 'NN'), Frequency: 3\n",
            "Misclassified Pair: ('RB', 'VB'), Frequency: 3\n",
            "Misclassified Pair: ('DT', 'NNP'), Frequency: 2\n",
            "Misclassified Pair: ('NN', 'DT'), Frequency: 2\n",
            "Misclassified Pair: ('CD', 'IN'), Frequency: 2\n",
            "Misclassified Pair: ('VBN', 'VB'), Frequency: 2\n",
            "Misclassified Pair: ('NNS', 'CD'), Frequency: 2\n",
            "Misclassified Pair: ('VBD', 'IN'), Frequency: 2\n",
            "Misclassified Pair: ('VBG', 'RB'), Frequency: 2\n",
            "Misclassified Pair: ('VBN', 'IN'), Frequency: 2\n",
            "Misclassified Pair: ('VBP', 'JJ'), Frequency: 2\n",
            "Misclassified Pair: ('PRP', 'WP'), Frequency: 2\n",
            "Misclassified Pair: ('NN', '-LRB-'), Frequency: 2\n",
            "Misclassified Pair: ('JJ', '-LRB-'), Frequency: 2\n",
            "Misclassified Pair: ('CC', 'VBD'), Frequency: 2\n",
            "Misclassified Pair: ('VBD', 'NNP'), Frequency: 2\n",
            "Misclassified Pair: ('MD', 'NN'), Frequency: 2\n",
            "Misclassified Pair: ('VB', 'DT'), Frequency: 2\n",
            "Misclassified Pair: ('CC', 'DT'), Frequency: 2\n",
            "Misclassified Pair: ('RB', 'PRP'), Frequency: 2\n",
            "Misclassified Pair: ('DT', 'PDT'), Frequency: 2\n",
            "Misclassified Pair: ('VBG', 'JJ'), Frequency: 2\n",
            "Misclassified Pair: ('CC', 'VBN'), Frequency: 2\n",
            "Misclassified Pair: ('IN', 'PRP'), Frequency: 2\n",
            "Misclassified Pair: ('PRP$', 'JJ'), Frequency: 2\n",
            "Misclassified Pair: ('NNP', 'PRP'), Frequency: 2\n",
            "Misclassified Pair: ('IN', 'VBD'), Frequency: 2\n",
            "Misclassified Pair: ('VBZ', 'NN'), Frequency: 2\n",
            "Misclassified Pair: ('VB', 'JJS'), Frequency: 2\n",
            "Misclassified Pair: ('VBP', 'VBN'), Frequency: 2\n",
            "Misclassified Pair: ('IN', 'WP'), Frequency: 1\n",
            "Misclassified Pair: ('PRP$', 'VBN'), Frequency: 1\n",
            "Misclassified Pair: ('VB', 'VBD'), Frequency: 1\n",
            "Misclassified Pair: ('VBZ', 'JJ'), Frequency: 1\n",
            "Misclassified Pair: ('CD', 'VB'), Frequency: 1\n",
            "Misclassified Pair: ('IN', 'JJR'), Frequency: 1\n",
            "Misclassified Pair: ('CC', 'NNP'), Frequency: 1\n",
            "Misclassified Pair: ('VBP', 'NNP'), Frequency: 1\n",
            "Misclassified Pair: (' ', 'VBD'), Frequency: 1\n",
            "Misclassified Pair: ('VBN', 'VBP'), Frequency: 1\n",
            "Misclassified Pair: ('POS', \"''\"), Frequency: 1\n",
            "Misclassified Pair: ('DT', 'JJS'), Frequency: 1\n",
            "Misclassified Pair: ('NNP', 'VB'), Frequency: 1\n",
            "Misclassified Pair: ('VBN', 'NNS'), Frequency: 1\n",
            "Misclassified Pair: ('VBN', 'CD'), Frequency: 1\n",
            "Misclassified Pair: ('NNS', '-RRB-'), Frequency: 1\n",
            "Misclassified Pair: ('IN', 'NNP'), Frequency: 1\n",
            "Misclassified Pair: ('NNP', 'VBP'), Frequency: 1\n",
            "Misclassified Pair: ('RB', 'NNP'), Frequency: 1\n",
            "Misclassified Pair: ('VBP', 'NNS'), Frequency: 1\n",
            "Misclassified Pair: ('CD', '$'), Frequency: 1\n",
            "Misclassified Pair: ('JJ', 'PDT'), Frequency: 1\n",
            "Misclassified Pair: ('VB', 'VBZ'), Frequency: 1\n",
            "Misclassified Pair: ('VBZ', 'VBP'), Frequency: 1\n",
            "Misclassified Pair: ('IN', 'PDT'), Frequency: 1\n",
            "Misclassified Pair: ('NN', 'WRB'), Frequency: 1\n",
            "Misclassified Pair: ('NNP', 'CC'), Frequency: 1\n",
            "Misclassified Pair: ('NNP', 'IN'), Frequency: 1\n",
            "Misclassified Pair: ('IN', 'MD'), Frequency: 1\n",
            "Misclassified Pair: ('VB', 'RBR'), Frequency: 1\n",
            "Misclassified Pair: ('VB', 'WRB'), Frequency: 1\n",
            "Misclassified Pair: ('VBZ', 'VBN'), Frequency: 1\n",
            "Misclassified Pair: ('VBZ', 'PRP'), Frequency: 1\n",
            "Misclassified Pair: ('NN', 'PRP'), Frequency: 1\n",
            "Misclassified Pair: ('PRP', 'NN'), Frequency: 1\n",
            "Misclassified Pair: ('CD', 'VBG'), Frequency: 1\n",
            "Misclassified Pair: ('NN', 'JJR'), Frequency: 1\n",
            "Misclassified Pair: ('CD', 'VBZ'), Frequency: 1\n",
            "Misclassified Pair: ('IN', 'VB'), Frequency: 1\n",
            "Misclassified Pair: ('PRP', 'RP'), Frequency: 1\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "y_pred = bidirect_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "print(y_pred_classes.shape)\n",
        "\n",
        "y_true_classes = np.argmax(Y_test, axis=-1)\n",
        "y_pred_classes_flat = y_pred_classes.flatten()\n",
        "\n",
        "y_true_classes_flat = y_true_classes.flatten()\n",
        "\n",
        "index_to_word = {v: k for k, v in word_to_idx.items()}\n",
        "index_to_tag = {v: k for k, v in treebank_index_to_tag.items()}\n",
        "misclassified = []\n",
        "for (pred, true) in zip(y_pred_classes_flat, y_true_classes_flat):\n",
        "    if pred != true:\n",
        "        #word_index = X_test[i // padding_length][i % padding_length]\n",
        "        #word = index_to_word[word_index]\n",
        "        true_tag = treebank_index_to_tag[pred]\n",
        "        pred_tag = treebank_index_to_tag[true]\n",
        "        misclassified.append((true_tag, pred_tag)) # (predicted_tag, true_tag, sentence_number, position_inside_sentence)\n",
        "\n",
        "\n",
        "#Count occurrences of each misclassified pair\n",
        "misclassification_counter = Counter(misclassified)\n",
        "\n",
        "#Get the most common misclassified pairs\n",
        "most_common_misclassifications = misclassification_counter.most_common()\n",
        "\n",
        "#Print or process the most common misclassifications\n",
        "for pair, count in most_common_misclassifications:\n",
        "    print(f\"Misclassified Pair: {pair}, Frequency: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "BqHtzkj3iTDi",
        "outputId": "f98841e7-b9e4-4625-b50a-b8e9eb093169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 2s 59ms/step\n",
            "[' ', ' ', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', ',', 'VBD', 'PRP', 'NNP', 'CD', 'CD', 'NN', ',', 'IN', 'IN', 'CD', 'NN', ',', 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', '$', 'NN', 'DT', 'NN', ',', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['DT', 'NN', 'NN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NN', 'TO', 'CD', 'NN', 'IN', 'CD', 'NN', 'CC', 'IN', 'TO', 'NN', 'NNP', 'NNP', 'IN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'RB', 'VBZ', 'NN', 'TO', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', 'IN', 'NNP', 'NNP', ',', 'DT', 'NN', 'NNP', '.']\n",
            "['DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'DT', 'NN', 'NN', 'NN', 'RB', 'VB', 'NN', 'DT', 'NN', 'NNP', 'TO', 'NN', 'NNS', '``', 'TO', 'NN', 'NN', 'NN', ',', \"''\", 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['IN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NN', 'NN', ',', 'NNP', 'NN', 'NNP', 'CD', 'NN', 'TO', 'NN', 'IN', 'CD', 'CD', '.']\n",
            "['NNP', 'NNP', 'NNP', 'TO', 'NN', 'RB', 'NN', 'DT', 'NN', 'NN', ',', 'VBD', 'RB', 'VBP', 'NN', 'IN', 'TO', 'NN', 'NN', 'IN', '``', 'DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', '.', \"''\"]\n",
            "['PRP', 'NN', ',', '``', 'DT', 'VBZ', 'RB', 'TO', 'VB', 'IN', 'NNP', 'NNP', 'CC', 'RB', 'VBZ', 'RB', 'NN', ',', 'JJ', ',', 'TO', 'TO', 'DT', 'NN', 'NN', '.', \"''\"]\n",
            "['RB', 'NNP', 'NNP', 'VBD', 'DT', 'NN', ',', 'CC', 'DT', 'NN', 'NN', 'NN', ',', 'NN', 'DT', 'NNP', 'NNP', 'VBZ', 'NN', '.', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', 'VBD', 'VBZ', 'NN', 'DT', 'CD', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'JJ', 'NN', 'IN', 'CD', 'NNP', 'NNP', 'NNP', 'NNP', '.']\n",
            "['DT', 'NN', ',', 'NN', 'IN', 'IN', '$', 'CD', 'CD', 'IN', 'DT', 'CD', 'NN', 'IN', 'NNP', 'DT', 'NNP', 'NNP', 'VBZ', 'RB', 'RB', 'NN', ',', 'VBD', 'RB', 'IN', 'TO', 'NNS', 'NNP', 'NNP', '.']\n",
            "['NNP', 'NNP', ',', 'DT', 'NNP', 'IN', 'CD', 'CD', 'IN', 'NNP', 'NNP', 'CD', 'CD', 'JJ', 'NN', 'NN', ',', 'VBD', 'IN', 'IN', 'CD', 'NN', 'NNS', 'IN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "[' ', 'DT', 'IN', 'NN', 'NN', 'NNS', 'NN', 'DT', 'NN', 'IN', 'NN', '.']\n",
            "['IN', 'NNP', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'NN', 'NN', ',', 'NNP', 'NNP', 'NNP', 'IN', 'CD', 'CD', ',', 'IN', 'CD', 'NN', '.']\n",
            "[' ', ' ', 'DT', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'DT', 'NN', 'NNP', 'NNP', ',', 'NNP', 'NNP', 'NN', ',', 'CC', 'NN', 'NNS', 'CC', 'NN', 'NN', 'NN', 'NN', 'CC', 'NN', 'NN', 'JJ', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NNP', 'CD', '.']\n",
            "['DT', 'NN', ',', 'NN', 'NN', ',', 'NN', 'CC', 'NN', 'NN', 'IN', 'NN', 'DT', 'DT', 'IN', 'NN', 'IN', 'NN', 'NNP', 'VB', 'RB', '.', '.']\n",
            "['IN', 'DT', 'NN', ',', 'NNP', 'NNP', ',', 'NNP', ',', 'VBD', 'NN', 'NN', 'NN', 'VB', 'NN', 'DT', 'JJ', 'IN', 'NN', ',', 'NN', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'CC', 'NN', 'NNS', '.']\n",
            "['RB', ',', 'PRP', 'NN', ',', 'RB', 'DT', 'NN', 'NN', 'NN', 'JJ', 'NN', ',', 'NNP', 'VB', 'RB', 'VB', 'TO', 'NNS', 'IN', 'DT', 'DT', 'NN', 'CC', 'IN', 'NN', 'NN', 'NNP', 'NN', 'NN', 'NN', 'IN', '$', 'NN', 'CD', '.']\n",
            "['IN', 'NN', 'NNP', 'NNP', 'NN', 'NN', ',', 'NNP', 'NNP', 'NN', 'NNS', 'CD', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'DT', 'NN', '.']\n",
            "['DT', 'NN', 'IN', 'NN', 'NNS', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'DT', 'NN', ',', 'DT', 'NN', 'NN', '.']\n",
            "['DT', ' ', 'NN', 'NN', 'DT', 'NN', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'CC', 'DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', ',', 'IN', 'IN', 'NN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'DT', 'NN', '.']\n",
            "['NNS', 'NNP', 'CD', 'NN', 'TO', 'CD', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['NNP', 'NNP', 'VBD', 'DT', 'IN', 'VBD', 'NNS', 'NN', 'IN', 'DT', 'NN', 'NNS', 'CC', 'NN', 'DT', 'JJ', 'NN', 'NN', 'IN', 'DT', 'NN', 'NNP', 'NN', 'NN', '.']\n",
            "['NN', ',', 'NN', 'NN', 'NNS', 'NNS', 'CD', 'NN', 'TO', '$', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['IN', 'IN', 'NNS', 'VBD', 'NN', 'NN', 'IN', 'DT', 'IN', 'NNS', 'NN', 'NNP', 'CD', '.']\n",
            "['IN', 'DT', 'NN', ',', 'NNP', 'NN', 'IN', 'NNP', 'NN', 'NN', 'NN', 'IN', 'NN', 'IN', 'NN', 'CC', 'NNS', ',', 'NNS', 'IN', 'NN', 'IN', 'DT', 'NN', '.', '.']\n",
            "['DT', 'NN', 'NN', ',', 'DT', 'IN', 'VBD', 'NNP', 'IN', 'IN', 'DT', 'NNP', 'IN', 'DT', 'NN', ',', 'NN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'CD', 'NN', 'TO', '$', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['IN', 'DT', 'NN', ',', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', ',', 'NNS', 'NNS', 'NN', 'NN', '.']\n",
            "[' ', 'NNS', ' ', 'CD', 'NN', 'IN', 'DT', 'NN', 'CC', 'CD', 'NN', 'IN', 'DT', 'NN', ',', 'JJ', 'NN', 'TO', 'NN', 'NN', 'NN', 'NN', ',', 'DT', 'IN', 'IN', 'DT', 'JJ', 'NN', 'IN', 'IN', 'NNP', 'NNP', '.']\n",
            "['DT', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', 'NNS', 'CC', 'NN', 'NN', 'IN', 'NN', 'NN', 'NNS', '.']\n",
            "['DT', 'NN', 'IN', 'IN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNP', 'CC', 'NNP', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', 'NNP', 'NN', 'DT', 'NN', 'NN', ',', 'NN', 'TO', 'NNS', '.']\n",
            "['IN', 'NN', 'NNP', ',', 'DT', 'NN', 'NN', 'NN', 'IN', '$', 'NN', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'IN', 'IN', 'CD', 'NN', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'IN', 'NN', 'NNP', '.']\n",
            "[' ', ' ', ' ', 'TO', 'NN', 'IN', 'NN', 'NN', ',', 'NNS', 'NN', 'NN', 'IN', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'IN', 'CD', 'CD', 'IN', 'NN', 'NNP', '.']\n",
            "['NNS', 'IN', 'DT', 'NN', 'NNP', 'CD', 'NN', 'TO', '$', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', 'IN', 'NN', 'NNP', '.']\n",
            "[' ', ' ', 'NNP', 'VBD', 'RB', 'NNS', 'NNS', 'IN', 'JJ', 'IN', 'DT', 'NN', 'NN', 'NNS', 'IN', 'CD', 'NN', 'TO', 'CD', 'NN', '.']\n",
            "['DT', 'NNP', ',', 'NNP', 'NN', ',', 'DT', 'NNP', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', 'NNS', 'CC', 'NNS', ',', 'VBD', 'DT', 'NN', 'NN', 'IN', 'DT', '$', 'CD', 'NN', 'IN', 'DT', 'NN', 'CD', 'NN', 'IN', 'CD', 'CD', 'IN', 'NN', ',', 'DT', 'NN', 'VB', 'NN', 'CC', 'DT', '.', 'NN', '.']\n",
            "['DT', 'NN', 'RB', 'NN', 'IN', 'IN', 'CD', 'CD', '.']\n",
            "['DT', 'NN', 'IN', 'DT', 'NN', 'NNP', 'NNP', 'NNP', 'NN', ',', 'IN', 'IN', 'NNS', 'IN', 'NN', 'CC', 'DT', 'NN', 'NNS', 'NN', 'RB', 'NN', 'IN', 'CD', 'NN', ',', 'IN', 'IN', 'CD', 'NN', '.']\n",
            "[' ', 'NN', 'NNS', 'IN', 'NNS', 'IN', 'DT', 'NN', 'CD', 'CC', 'CD', 'NNS', ',', 'DT', 'DT', 'NNP', 'NNS', 'NN', ',', 'NNS', 'NNS', 'IN', 'NN', 'IN', 'IN', 'NN', 'NNS', 'NNS', 'NN', '.']\n",
            "['IN', ' ', 'NNP', 'NNS', 'NN', 'IN', 'NN', 'DT', 'NN', ',', 'DT', 'NN', 'NN', 'CC', 'NN', ',', 'RB', 'RB', 'NN', 'NN', 'DT', 'NN', 'NN', 'CC', 'NN', '.']\n",
            "[' ', 'IN', 'IN', 'NN', 'IN', 'DT', 'NN', 'DT', 'NNP', ',', 'JJ', 'DT', 'JJ', 'NNP', 'CC', 'NN', ',', 'RB', 'RB', 'TO', 'NN', 'DT', 'JJ', 'NN', 'IN', 'NN', '.']\n",
            "[' ', 'NNS', ' ', 'TO', 'NNS', 'NNS', 'NNS', ',', 'NNS', 'JJ', 'JJ', 'IN', 'DT', 'NN', 'NN', ',', 'DT', 'VB', 'RB', 'RB', 'NN', ',', 'NNS', 'VBD', '.']\n",
            "['DT', 'NNP', 'CC', 'IN', 'NNS', 'NNP', 'TO', 'NNS', 'NN', 'NNS', 'IN', 'NNP', 'NN', 'CC', 'NNP', 'NN', 'IN', 'IN', 'NN', 'NNS', 'IN', 'DT', 'NN', '.']\n",
            "['DT', 'NNP', 'NN', ',', 'DT', 'VBZ', 'DT', 'NN', ',', 'NNP', 'IN', 'NNP', 'NN', ',', 'IN', 'NNP', 'NN', 'DT', 'NN', '.']\n",
            "['DT', 'IN', 'NN', ',', 'DT', 'NN', 'VBZ', 'JJ', 'NN', ',', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', 'NN', 'TO', 'NN', 'NN', '.']\n",
            "['DT', 'NNP', 'NN', 'NNP', 'DT', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', 'DT', 'NN', 'TO', 'NN', 'NN', ',', 'IN', 'IN', 'NN', 'NN', 'NN', 'NN', 'NNS', '.']\n",
            "['NNP', 'TO', 'NN', 'NN', 'IN', 'NNS', 'NN', 'NN', ',', 'DT', 'NN', 'NN', 'VBD', 'DT', 'NN', 'NNS', 'DT', 'RB', 'NN', 'RB', 'RB', 'NN', 'TO', 'NN', 'NN', 'NN', 'DT', 'NN', 'NN', 'NN', ',', 'IN', 'IN', 'IN', 'CD', ',', 'CC', 'DT', 'NN', 'NN', 'RB', 'RB', 'RB', 'VB', 'RB', 'IN', 'TO', 'NNS', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "['DT', 'NNP', ',', 'NNP', 'NNP', ',', 'IN', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'CD', 'DT', 'CD', 'NN', 'IN', 'IN', 'IN', 'NNP', 'NNP', 'NNP', 'IN', 'NNS', 'NN', 'IN', 'NN', 'CC', 'NN', 'RB', 'VB', 'NN', '.']\n",
            "['``', 'DT', 'VBZ', 'DT', 'NN', 'DT', 'VB', 'VB', 'NNP', ',', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', ',', \"''\", 'VBD', 'NNP', 'NNP', '.']\n",
            "[' ', 'DT', 'DT', 'NN', 'NNP', 'CC', 'DT', 'NN', 'NN', 'IN', 'NN', 'IN', 'DT', '.', '.']\n",
            "['DT', 'NN', 'TO', 'JJ', 'IN', 'NN', 'CC', 'JJ', 'NN', 'VBD', 'RB', 'NN', ',', 'RB', 'DT', 'NN', 'NN', ',', 'RB', 'NN', ',', 'NN', 'DT', 'JJ', 'NN', 'NN', 'IN', 'VBD', 'RB', 'NN', '.']\n",
            "['IN', 'DT', 'NN', 'NN', 'NN', ',', 'NNP', 'VBD', 'NN', 'TO', 'NNS', 'CD', 'CD', 'CD', 'IN', 'NN', ',', 'DT', 'NN', 'IN', 'CD', 'CD', 'CD', 'IN', 'CD', '.']\n",
            "['DT', ' ', 'NNS', 'IN', 'NNS', 'TO', 'CD', 'NNS', 'CD', 'IN', 'NNS', 'TO', 'NNS', 'IN', 'CD', 'CD', 'CD', 'IN']\n",
            "['``', 'RB', 'VBZ', 'NNS', 'NNS', 'CD', 'DT', 'NNS', 'IN', 'NN', 'IN', 'DT', 'NN', 'NN', ',', \"''\", 'NN', 'NNP', 'NNP', ',', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', ',', 'NNP', 'NNP', '.']\n",
            "['``', 'NNS', 'IN', 'NN', 'DT', 'NN', 'VBD', 'DT', 'NN', 'TO', 'NN', 'NN', 'CC', 'DT', 'NN', 'NNS', 'IN', 'NNS', 'TO', 'VB', 'NNS', 'TO', 'VB', 'NN', \"''\", 'NN', '.']\n",
            "['IN', 'DT', 'NN', ',', 'NNP', 'NNP', 'VBD', ',', 'VBZ', 'VBZ', 'VBD', 'DT', 'IN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'VBZ', 'RB', 'NNS', 'RB', ',', 'RB', 'RB', 'DT', 'NN', 'NN', 'DT', 'CD', 'NN', 'NN', '.']\n",
            "['IN', 'IN', 'DT', 'NN', 'IN', 'IN', 'NN', 'NN', 'IN', 'NNP', 'NN', 'IN', 'NN', 'NN', ',', 'NNP', 'TO', 'NNP', 'NNP', '.']\n",
            "['IN', ',', 'IN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'TO', 'NN', 'IN', 'NN', 'IN', 'IN', 'NNS', 'IN', 'IN', 'NN', 'IN', 'IN', 'NN', ',', 'CC', 'DT', 'NN', 'VBZ', 'RB', 'VBD', 'RB', ',', 'PRP', 'VBD', '.']\n",
            "[' ', 'NN', ',', 'NNP', 'NNP', 'NNP', ',', '``', 'NN', 'NN', 'VBD', 'DT', 'DT', 'NN', 'VBZ', 'IN', 'NN', 'IN', 'IN', 'IN', 'DT', 'NN', 'IN', 'NN', '.', \"''\"]\n",
            "['NNP', 'NNP', ',', 'NNP', 'NNP', 'IN', 'NNP', 'IN', 'NNP', ',', 'NNP', ',', 'VBD', ',', '``', 'PRP', 'NN', 'NN', 'JJ', 'DT', 'NN', 'VB', 'NN', 'NN', 'NN', ',', 'JJ', 'IN', 'DT', 'NN', 'IN', 'NN', 'IN', 'IN', 'CD', 'NN', 'DT', 'NN', '.', \"''\"]\n",
            "[' ', 'IN', ',', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NN', 'VBZ', 'NN', 'NN', '.']\n",
            "['``', 'NN', 'NN', 'IN', 'IN', 'VBD', 'RB', 'NN', 'JJ', 'IN', 'DT', 'NN', 'NN', 'NN', 'NNS', 'RB', 'VB', 'TO', 'NN', 'DT', 'NN', 'IN', 'VB', 'RB', 'NN', 'TO', 'NN', 'DT', 'NN', ',', \"''\", 'IN', 'VBD', '.']\n",
            "['``', 'DT', 'DT', 'DT', 'NN', 'IN', 'JJ', 'NN', 'IN', 'DT', 'DT', 'NN', 'VB', 'VB', 'NN', 'IN', ',', 'IN', 'IN', 'DT', 'DT', 'NN', 'NN', 'VB', 'RB', 'NN', ',', 'CC', 'NN', 'DT', 'VB', 'NN', '.', '.', \"''\"]\n",
            "['NNP', ' ', ' ', 'DT', 'DT', 'NN', 'IN', 'NNP', 'VBZ', 'JJ', 'RB', 'JJ', '.']\n",
            "['IN', 'DT', 'DT', 'NN', ',', 'NNP', 'IN', 'DT', 'NN', 'NN', 'IN', 'CD', 'IN', 'NNP', 'TO', 'NN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNS', 'CC', 'VBZ', 'RB', 'NN', 'TO', 'DT', 'NN', '.']\n",
            "['``', 'RB', 'VBZ', 'TO', 'NNS', ',', 'IN', 'DT', 'NNS', 'NN', ',', 'DT', 'JJ', 'IN', 'NN', 'IN', 'NN', 'RB', 'VB', 'NNS', 'IN', 'DT', 'NN', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'TO', 'VB', 'TO', 'NN', 'NN', 'IN', 'NN', ',', \"''\", 'NNP', 'NNP', 'VBD', '.']\n",
            "[' ', ',', 'DT', 'DT', 'NN', 'DT', 'NN', 'NN', ',', 'VBZ', 'VBD', 'NN', 'JJ', 'IN', 'DT', 'JJ', 'IN', 'IN', ',', 'NNS', 'VBD', '.']\n",
            "['IN', 'NN', ',', 'RB', 'VBD', 'TO', 'NN', 'NN', 'IN', 'DT', 'IN', 'NN', 'TO', 'NN', 'NN', 'NNS', ',', 'RB', 'NN', '.']\n",
            "['DT', 'NN', 'RB', 'VBZ', 'NN', 'TO', 'VB', 'DT', 'NN', 'NN', 'CC', 'VBZ', 'VBD', 'TO', 'VB', 'NN', 'TO', 'NNS', 'IN', 'CD', 'CD', 'IN', 'NN', 'TO', 'NN', 'NN', 'NN', ',', 'NNS', 'VBD', '.']\n",
            "['IN', 'NNS', 'NN', 'NNS', 'NN', ',']\n",
            "[' ', ',']\n",
            "[' ', 'NNP', 'IN', 'NNS', 'NN', 'IN', 'NN', 'NN', 'NN', 'DT', 'NN', '.']\n",
            "['IN', 'DT', 'NNP', 'NNP', 'NNP', 'NN', ',', 'NNS', 'NN', 'IN', 'NNP', 'NN', 'NN', 'CD', 'NN', 'TO', 'NNS', 'IN', 'NN', 'NN', 'DT', 'NN', '.']\n",
            "[' ', 'NNP', 'IN', 'NN', 'TO', 'NN', '.']\n",
            "['RB', 'DT', 'NN', 'IN', 'JJ', 'NN', 'NN', 'NN', 'IN', 'NNS', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNS', 'IN', 'NNP', 'NN', 'NNP', 'CD', 'NN', 'DT', 'NN', 'TO', 'NNS', 'IN', 'CD', 'CD', '.']\n",
            "['DT', ' ', 'IN', 'NN', 'NN', 'VBD', 'NN', 'TO', 'JJ', 'JJ', 'IN', 'NNS', 'IN', 'DT', 'NNP', 'CC', 'TO', 'DT', 'NN', 'NN', 'NN', 'IN', 'DT', 'NNP', 'NN', 'NNP', ',', 'DT', 'NN', 'DT', 'NN', 'IN', 'NNS', 'IN', 'DT', 'NN', '.']\n",
            "[' ', 'CC', 'NNS', ',']\n",
            "['NNS', 'NNP', 'NNS', 'NNS', 'IN', 'JJ', 'JJ', 'NN', 'IN', 'NNS', 'JJ', 'TO', 'NNS', 'IN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', 'NNS', 'TO', 'VB', '.']\n",
            "['NNP', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'IN', 'NN', 'NN', 'IN', 'NNS', 'IN', 'IN', 'NN', '.']\n",
            "[' ', 'NNS', 'NN', 'IN', 'NN', 'NNS', '.']\n",
            "['IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', 'IN', 'DT', 'NNP', ',', 'NN', 'NNS', 'VBD', 'DT', 'NN', 'NNP', 'DT', 'NN', 'NN', ',', 'IN', 'JJ', 'NN', 'NNP', 'NNS', 'IN', 'NN', ',', 'VBD', 'IN', 'TO', 'NNP', 'TO', 'NNS', 'CD', 'CD', 'CD', 'IN', 'NN', '.']\n",
            "[' ', 'VBD', 'NNS', 'IN', 'IN', 'NN', 'IN', 'JJ', 'NN', 'DT', 'DT', 'NN', 'NN', 'DT', 'IN', 'DT', 'NN', 'IN', 'NN', 'JJ', 'NN', 'NN', 'NN', 'IN', 'DT', 'NNP', '.']\n",
            "['DT', 'NN', 'VB', ',', 'JJ', 'NNS', 'RB', ',', 'NNS', 'IN', 'NN', 'NNS', 'NN', 'IN', 'DT', 'DT', 'NN', 'VB', 'NN', 'NN', '.']\n",
            "['DT', ' ', 'NNS', 'JJ', 'VBD', 'TO', 'VB', 'NNS', 'NNS', ',', 'JJ', 'NN', 'IN', 'NN', 'NN', 'NNS', 'IN', 'CD', 'CD', 'CD', 'IN', 'NN', 'IN', 'NNP', '.']\n",
            "[' ', ' ']\n",
            "['NNP', 'NNS', 'NNP', ',', 'NNP', 'NNP', 'NNP', 'NN', '.']\n",
            "['DT', 'NNP', 'NN', 'NN', 'NN', 'NN', 'DT', 'NN', 'TO', '$', 'NN', '.']\n",
            "[' ', 'IN', 'DT', 'JJ', 'DT', 'NN', 'IN', 'IN', 'DT', 'NN', 'NN', ',', 'CC', 'NNS', 'JJ', 'JJ', 'NN', 'DT', 'DT', 'NN', 'NN', 'NN', 'IN', 'RB', 'NN', 'NN', 'IN', 'RB', 'IN', ',', 'DT', 'NNP', 'VBD', '.']\n",
            "['NNP', 'TO', 'NN', 'NN', 'NN', ',', 'JJ', 'NNS', 'IN', 'DT', 'NN', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'TO', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'DT', 'CD', 'NN', 'NN', 'CC', 'NNS', 'NNS', '.']\n",
            "[' ', ',', 'IN', 'NNS', 'NNS', 'RB', 'RB', 'NN', 'DT', 'NNP', 'NN', 'CC', 'NNS', 'NN', 'NN', ',', 'DT', 'NNP', 'VBD', '.']\n",
            "[' ', ',', 'NNP', 'NNP', 'DT', 'DT', 'NN', 'NNP', 'NN', 'NN', 'DT', 'NN', 'TO', 'NN', 'DT', 'NN', 'IN', 'NN', 'IN', 'NNP', 'NNP', 'IN', 'IN', 'IN', 'NNS', '.']\n",
            "['DT', ' ', ' ', ' ', 'VBZ', 'RB', 'JJ', 'IN', 'IN', 'CD', 'RB', 'IN', 'JJ', 'IN', 'NNP', 'NNS', 'VBD', 'VB', 'NNP', 'TO', 'VB', 'IN', 'NNS', 'IN', '.']\n",
            "['DT', 'NN', 'IN', 'NN', ',', 'IN', 'NN', 'TO', 'VB', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', 'NNP', 'NNS', ',', 'VBD', 'PRP', 'VB', 'NNS', 'DT', 'NN', 'IN', 'DT', 'NN', 'TO', 'NN', 'CC', 'TO', 'IN', 'NNS', 'TO', 'NN', 'DT', 'NN', 'IN', 'NN', '.']\n",
            "[' ', 'IN', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'VBD', 'IN', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNP', ',', 'IN', 'RB', 'NN', 'DT', 'NN', 'TO', 'NN', 'IN', 'IN', 'TO', 'NN', 'DT', 'NN', 'NN', '.']\n",
            "['RB', ' ', 'VBD', 'RB', 'VBD', 'NN', 'TO', 'VB', 'DT', 'NN', 'NN', 'TO', 'NN', 'RB', 'RB', 'NN', '``', 'NN', 'NN', \"''\", 'IN', 'NN', 'RB', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'CC', 'NN', 'NNS', 'CC', 'IN', 'NN', '.']\n",
            "[' ', ' ', 'IN', 'NN', 'IN', 'NNP', 'IN', '$', 'CD', 'CD', '.']\n",
            "['RB', 'NN', 'NNS', 'NNS', 'IN', 'NNP', 'CC', 'NNP', '.']\n",
            "[' ', 'NN', 'VBZ', 'NN', 'TO', 'NN', 'DT', 'CD', 'NN', 'TO', 'CD', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'VBD', 'NNP', 'NNP', 'NNP', ',', 'NN', 'NNP', 'NNP', 'CC', 'NNP', 'NNP', 'NNP', '.']\n",
            "['PRP', 'VBD', 'NN', 'NN', 'TO', 'NN', 'NN', 'DT', 'NN', 'IN', 'NN', 'TO', 'NN', 'IN', 'CD', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'VBD', 'DT', 'NNP', 'NN', 'NNP', 'NN', 'NN', 'VBZ', 'NN', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'TO', '$', 'NN', 'IN', 'NNS', 'CC', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['IN', 'NN', 'IN', 'DT', 'NNP', 'NN', ',', 'NNP', ',', 'NN', 'IN', 'NNP', 'NNP', 'NNP', ',', 'NNP', ',', 'TO', 'NNS', 'CD', 'CD', 'NNS', 'CC', 'DT', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'CD', 'CD', 'DT', 'NN', 'IN', 'DT', 'IN', 'NNP', 'NNP', 'IN', 'CD', 'CD', 'NN', 'NN', '.']\n",
            "['NNP', ',', 'PRP', 'NN', '$', 'NN', 'DT', 'NN', 'IN', 'NNS', ',', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['DT', 'NNP', 'NNP', ',', 'NNP', ',', 'NN', 'IN', 'NNP', 'NNP', 'CC', 'NNS', 'NNS', 'VBD', 'DT', 'NN', 'NN', 'VB', 'NNS', 'NNS', 'IN', 'DT', 'CD', 'NN', 'NN', ',', 'RB', 'VB', 'RB', 'VB', 'NN', 'IN', 'DT', 'IN', 'IN', 'IN', '.']\n",
            "['DT', 'NN', 'TO', 'RB', 'NNS', 'IN', 'CD', 'IN', ',', 'NN', 'TO', 'NN', 'IN', 'DT', 'NN', 'NN', 'NNP', 'NN', '.']\n",
            "[' ', ' ', ' ', 'NNP', 'NNP', 'VBD', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'CC', 'NNP', 'NNP', 'VB', 'RB', 'VB', 'NN', 'IN', 'NN', '.']\n",
            "[' ', ',', 'NNP', 'NNP', 'VBD', 'RB', 'VB', 'NN', 'NNS', 'DT', 'NN', 'TO', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', 'VBD', 'NNP', 'NNP', 'NNP', 'IN', 'NN', 'NN', 'TO', 'NN', 'NN', 'NN', ',', 'DT', 'NN', 'DT', 'NN', 'NN', 'NN', 'DT', \"''\", 'NN', 'NN', '.', \"''\"]\n",
            "['NNP', ' ', ',', 'NNP', 'IN', 'NN', 'CC', 'DT', 'NN', 'NN', 'NN', ',', 'VBD', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'IN', 'IN', 'CD', 'NN', '.']\n",
            "['IN', 'NNP', 'TO', 'DT', 'NN', ',', 'DT', 'VBZ', 'NN', 'NN', ',', 'NN', 'CC', 'NN', 'NN', ',', 'NN', 'DT', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', '.']\n",
            "['DT', 'NNP', 'VBD', 'NNP', ',', 'CC', 'NNP', 'NNP', 'NNP', 'NN', 'VB', 'VB', 'NN', 'IN', 'IN', 'NNS', 'NNP', 'NNP', 'NNS', ',', 'DT', 'NN', 'VBD', '.']\n",
            "['IN', 'DT', 'NN', 'NN', ',', 'NNP', 'NNP', 'VBD', 'IN', 'NN', 'IN', 'IN', \"''\", 'NN', 'NN', ',', \"''\", 'IN', 'IN', 'NN', 'TO', 'NNS', '.']\n",
            "['``', 'IN', 'VBZ', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', ',', \"''\", 'NN', 'DT', 'NN', 'IN', 'NN', ',', 'IN', 'NN', '.']\n",
            "['PRP', 'IN', 'NN', 'NN', 'DT', 'IN', 'NN', 'NN', 'IN', 'NN', 'DT', 'NN', 'NN', 'NNP', 'NN', 'VBD', 'RB', 'IN', 'NN', 'TO', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "['NNP', ' ', 'VBD', 'DT', 'IN', 'CD', 'NNS', 'IN', 'NN', 'NNP', 'NN', 'NN', 'NN', 'VBD', 'VBD', 'RB', 'IN', 'NNS', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "['``', 'RB', 'PRP', 'IN', 'NN', 'DT', 'IN', 'IN', 'NN', ',', 'PRP', 'VB', 'VB', 'NN', 'DT', 'IN', 'VBD', 'NNS', 'IN', 'IN', 'DT', 'NN', ',', \"''\", 'IN', 'VBD', '.']\n",
            "['DT', ' ', 'VBD', 'VBD', 'DT', 'NN', 'NN', '``', 'DT', 'NN', 'IN', 'NN', 'IN', 'NNS', '.', \"''\"]\n",
            "['NNP', ' ', ',', 'DT', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', ',', 'VBD', ',', '``', 'PRP', 'NN', 'NN', 'DT', 'NN', 'NN', 'VB', 'RB', 'NNS', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['PRP', 'RB', 'RB', 'RB', 'NN', 'RB', 'IN', 'NN', 'NN', 'NN', 'NN', 'IN', 'NN', 'IN', 'NN', 'IN', 'NN', 'NN', '.', \"''\"]\n",
            "['IN', 'NNP', 'NNP', 'NN', 'NN', ',', 'NNP', 'NNP', 'NNP', 'CD', 'NN', 'TO', 'CD', 'NN', 'NN', 'CD', 'CD', 'CD', '.']\n",
            "['IN', 'DT', 'NNP', 'JJ', 'NN', ',', 'NNP', 'NNP', 'NN', 'IN', 'NN', ',', 'DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'NNP', 'NN', ',', 'NNP', 'NN', 'IN', 'CD', 'NN', '.']\n",
            "['DT', 'NN', 'IN', 'DT', 'JJ', 'NNS', ',', 'VB', 'NN', 'NNP', 'NNP', 'NNP', 'NN', 'VBZ', 'NNP', 'NNP', ',', 'NNP', ',', 'NN', 'NNP', 'CC', 'DT', 'NN', 'NN', 'NNP', '.']\n",
            "['NNP', 'NNP', ',', 'CD', ',', 'NNP', 'NN', 'NN', ',', 'NN', 'NNP', 'IN', 'NN', 'NNP', '.']\n",
            "['CC', 'NNP', 'NNP', ',', 'NNP', ',', 'NNP', 'NN', 'NN', ',', 'NN', 'NNP', 'IN', 'NN', 'NN', 'NNS', '.']\n",
            "[' ', ' ', 'NNP', ',', 'DT', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NN', 'CC', 'NNP', 'NN', 'NNP', ',', 'NNP', 'TO', 'NNP', 'CD', 'DT', 'CD', 'NN', 'NN', 'IN', 'IN', 'NN', 'NNP', 'NNP', 'NN', 'NN', '.']\n",
            "['DT', 'NN', ',', 'DT', 'VBD', 'NN', 'TO', 'NNS', 'NN', ',', 'DT', 'NN', 'IN', 'NN', 'NN', 'IN', 'NNP', 'JJ', 'NN', ',', 'IN', 'DT', 'NN', 'NN', 'NN', ',', 'IN', 'NN', 'CC', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "[' ', ' ', 'VBZ', 'NNP', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'NN', 'DT', 'NN', 'IN', 'NNP', 'NN', 'NN', 'NN', 'NN', 'CC', 'NN', 'NN', 'NN', 'NN', ',', 'DT', 'DT', 'NN', 'IN', 'NN', 'IN', 'IN', 'TO', 'NNS', 'NNS', '.']\n",
            "[' ', ' ', 'VBD', 'CD', 'CD', 'NN', ',', 'IN', 'IN', 'CD', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'NNS', 'IN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['DT', 'NNP', 'VBD', 'RB', 'JJ', 'NN', 'CD', 'NN', 'IN', 'IN', 'NN', 'NN', '.']\n",
            "[' ', 'VBZ', 'IN', 'NNP', 'CD', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', 'NNS', 'NN', '.']\n",
            "[' ', ' ', 'VBD', 'DT', 'NN', 'VBZ', 'TO', 'VB', 'DT', 'NN', 'TO', 'VB', 'NN', '.']\n",
            "[' ', 'VBZ', 'NNP', 'IN', 'NNP', ',', 'IN', '.']\n",
            "[' ', ',', 'DT', 'NN', 'NN', 'NN', 'NN', 'CC', 'NN', ',', 'DT', 'NN', 'NN', ',', 'NNS', 'NN', 'IN', 'NNP', '.']\n",
            "[' ', 'NNP', 'NNP', 'DT', 'NN', 'NN', 'NN', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'DT', 'NN', ',', 'NN', 'IN', 'NN', 'NN', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'DT', 'NN', 'DT', 'NN', '.']\n",
            "['DT', 'NN', 'IN', 'DT', 'NNP', ',', 'NNP', 'NN', 'VBD', 'NN', 'VBD', 'DT', 'NN', 'IN', '$', 'CD', 'CD', 'IN', 'DT', 'NN', ',', 'IN', 'NN', ',', 'DT', 'NN', 'VBD', 'NN', 'IN', 'NNS', 'NNS', 'NNS', 'CD', 'CD', 'CD', 'CC', 'CD', 'CD', 'CD', 'IN', 'NN', 'NNS', 'IN', 'IN', 'NN', 'IN', \"''\", 'JJ', '.', \"''\"]\n",
            "['DT', 'NN', 'IN', 'NN', 'NNS', 'IN', 'DT', 'CD', 'CD', 'CD', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNS', 'IN', 'IN', 'NN', 'NNP', ',', 'IN', 'VBD', '.']\n",
            "['NNS', 'NNP', 'NNP', 'NN', 'TO', '$', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'CD', 'DT', 'NN', 'NN', '.']\n",
            "[' ', ' ', '``', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', 'NNS', 'IN', 'DT', 'NN', 'NNS', 'IN', 'DT', 'NNP', 'NN', '.']\n",
            "[' ', 'NNP', 'VBD', 'RB', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', 'NN', 'IN', 'CD', 'CD', 'CD', 'TO', 'CD', 'CD', 'CD', 'IN', 'IN', 'NN', 'NN', 'CC', 'NN', 'NNS', 'NN', 'NNS', '.']\n",
            "['DT', 'NNP', 'NNP', 'NNP', 'CC', 'NN', 'NN', 'VBD', 'RB', 'VB', 'NN', 'DT', '$', 'CD', 'CD', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'IN', 'DT', '$', 'CD', 'CD', 'NN', 'NNS', 'TO', 'NNS', 'IN', 'DT', 'NN', 'NN', 'NN', 'CC', '$', 'CD', 'CD', 'IN', 'NN', 'NN', 'DT', 'NN', 'RB', 'RB', 'NNS', '.']\n",
            "['IN', 'NN', ',', 'NNP', 'VBD', 'PRP', 'VB', 'NNS', 'IN', 'IN', '$', 'CD', 'CD', 'IN', 'NNS', 'NNS', 'TO', 'NN', 'NN', 'NNS', 'IN', 'NN', 'NN', 'NNS', 'RB', 'NN', '.']\n",
            "['DT', 'NN', 'IN', 'NN', 'NN', 'NN', 'CC', 'NNS', 'IN', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['DT', 'NN', 'VBD', ',', 'NN', 'NNS', 'IN', '$', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'DT', 'NN', ',', 'IN', 'NN', 'IN', '$', 'CD', 'CD', '.']\n",
            "['DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'JJ', 'DT', 'NN', 'NN', 'NN', 'NN', 'TO', 'NN', 'NNP', 'NN', 'NN', 'NNS', ',', 'IN', 'NNS', 'NN', 'NN', 'NN', 'IN', 'NNS', 'NN', '.']\n",
            "['IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', 'NN', 'JJ', 'NN', 'NN', 'NNS', ',', 'NNS', 'VBD', 'NNP', 'NN', 'IN', 'DT', 'NN', ',', 'IN', 'NN', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['DT', 'NNP', 'NNP', 'NN', 'NN', ',', 'DT', 'VBD', 'NN', 'NNP', 'CD', 'IN', 'NNP', ',', 'NNP', 'IN', 'NN', 'IN', 'IN', 'DT', 'NN', 'NN', 'CC', 'NN', 'IN', 'DT', 'NN', 'IN', '.', 'NNP', 'IN', 'NNP', '.']\n",
            "[' ', 'NNP', ' ', 'NNP', 'NNP', 'NNP', 'NN', 'NNP', 'TO', 'NN', ',', 'DT', 'NN', 'VBD', 'NN', 'TO', 'DT', 'NN', 'IN', 'IN', 'CD', 'CD', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['DT', 'NNP', 'NNP', 'NNP', 'NN', 'NNP', 'NNP', 'NNP', 'TO', 'NN', 'CC', 'DT', 'NNP', 'NNP', 'NN', 'NN', 'NNP', 'NN', 'NNP', 'IN', 'NNP', 'TO', 'NN', '.']\n",
            "[' ', 'NNS', 'NNP', 'NNP', 'IN', 'DT', 'NNP', 'NNP', 'NN', 'NN', 'IN', 'CD', 'TO', 'CD', '.']\n",
            "[' ', 'NNP', 'NN', 'NN', 'TO', 'NN', 'NN', ',', 'IN', 'IN', 'NN', 'CD', 'NNP', '.']\n",
            "['DT', 'NNP', 'NN', 'IN', 'NN', 'NN', 'NNS', ',', 'IN', 'NN', ',', 'NN', 'NN', 'DT', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'IN', 'NN', 'NN', 'JJ', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', 'IN', 'NN', 'NN', ',', 'DT', 'NN', 'IN', 'CD', 'NN', 'VB', 'VB', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "['RB', 'IN', 'DT', 'NN', 'JJ', 'JJ', 'NN', 'IN', 'NN', 'CC', 'DT', 'JJ', 'NN', 'NN', 'IN', 'NNP', 'NN', 'NNP', 'TO', 'NNS', 'NN', ',', 'NN', 'NNS', 'NN', 'IN', 'NNS', 'IN', 'NN', 'TO', 'DT', 'NN', 'CC', '.', 'NN', '.']\n",
            "['``', 'DT', 'NN', 'NN', 'RB', 'RB', 'IN', 'DT', 'NN', ',', \"''\", 'VBD', 'NNP', 'NNP', ',', 'NNP', 'IN', 'NNP', 'NN', 'IN', 'NNP', 'NNP', '.']\n",
            "['``', 'DT', 'NN', 'VBZ', 'RB', ',', 'NN', 'RB', 'VB', 'NN', 'NNS', 'NN', 'IN', ',', 'RB', 'RB', 'RB', 'RB', 'RB', 'VB', 'RB', 'RB', 'RB', 'TO', 'NNS', 'IN', '.', 'NN', \"''\"]\n",
            "[' ', 'IN', 'DT', 'NN', 'IN', 'JJ', 'NN', 'TO', 'NN', 'NN', 'NN', ',', 'DT', 'NN', 'IN', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', ',', 'IN', 'NNP', 'TO', 'DT', 'NN', 'IN', 'NN', ',', 'NNP', 'NNP', 'VBD', '.']\n",
            "[' ', 'NNP', 'IN', 'DT', 'NN', 'VBD', 'JJ', 'JJ', 'TO', 'DT', 'NN', 'IN', 'NNS', 'NNS', 'IN', 'DT', 'NN', ',', 'DT', 'NN', 'NNS', 'DT', 'NN', 'IN', 'NN', 'NNS', 'NNP', 'NNS', '.']\n",
            "['NNP', 'DT', 'NN', 'TO', 'NNS', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'IN', 'DT', 'NNS', 'NNS', 'IN', 'DT', 'NN', 'DT', 'RB', 'VB', 'DT', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "['``', 'PRP', 'NN', 'DT', 'IN', 'IN', 'NNS', 'NNS', 'TO', 'NN', 'IN', 'NNS', 'IN', 'IN', 'NN', 'NN', 'IN', 'IN', 'IN', 'DT', 'JJ', 'VB', 'IN', ',', \"''\", 'VBD', 'NNP', 'NNP', ',', 'NNP', 'IN', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',']\n",
            "[' ', ' ', 'NNP', 'NNP', 'NNP', 'TO', 'NNP', 'NNP', 'IN', 'DT', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', 'CC', 'NNP', 'NN', 'NN', 'NN', 'DT', 'NN', 'IN', 'NN', 'DT', 'DT', 'NN', 'VB', 'NN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', ' ', 'DT', 'NN', 'NN', 'JJ', 'NN', 'NN', 'IN', 'NN', 'TO', 'DT', 'NN', ',', 'NNP', 'NNP', 'NNP', 'VBD', 'IN', 'NN', 'DT', 'NN', 'VB', 'VB', 'TO', 'IN', 'NN', '``', 'DT', 'NN', 'VB', 'NNS', 'NN', '.', \"''\"]\n",
            "['IN', 'NN', 'NN', 'CC', 'NN', 'NNS', 'TO', 'NNS', 'NNS', 'JJ', 'NNP', ',', 'IN', 'NNP', 'IN', 'CD', 'NN', 'TO', 'CD', 'NNP', ',', 'NNP', 'NNS', ',', 'IN', 'CD', 'NNP', 'TO', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'IN', 'CD', 'TO', 'CD', 'NNP', ',', 'CC', 'NNP', ',', 'IN', 'CD', 'NNP', 'TO', 'CD', 'NNP', '.']\n",
            "[' ', ',', 'DT', 'NN', 'NN', 'NN', 'DT', 'NN', 'NN', ',', 'NNP', 'NNP', 'TO', 'CD', 'NNP', '.']\n",
            "['DT', 'NN', 'VBD', 'RB', 'NN', 'DT', 'NN', 'NN', ',', 'DT', 'RB', 'VBD', 'RB', 'NN', ',', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', ' ', 'NNP', 'NNP', 'TO', 'NNP', 'NNP', 'NN', 'NN', 'DT', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'VBD', 'NN', 'NN', 'TO', 'NNP', 'DT', 'NN', ',', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNP', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'DT', 'CD', 'NN', 'NN', 'IN', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', 'NNP', 'TO', 'CD', '.']\n",
            "[' ', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'VBD', 'IN', 'NN', 'DT', 'CD', 'NN', 'NN', 'DT', 'DT', 'NN', 'IN', 'NNP', 'NN', ',', 'DT', 'NN', 'IN', 'DT', 'NN', '$', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'VB', 'VB', 'NN', 'IN', 'NN', 'NN', 'CD', 'CD', '.']\n",
            "['NNP', 'NNP', 'VBD', 'NNP', 'NNP', 'TO', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', ',', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'NN', 'TO', 'NN', 'DT', 'NN', 'RB', 'VBZ', 'RB', 'VB', 'NN', 'IN', '$', 'CD', 'DT', 'NN', '.']\n",
            "[' ', ',', 'DT', 'NN', 'NN', 'IN', 'NNP', 'NNP', ',', 'VBZ', 'DT', 'NN', 'IN', 'NN', 'IN', 'CD', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', ',', 'DT', 'NN', 'CD', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', 'DT', '$', 'CD', 'CD', 'NN', 'IN', 'DT', 'NN', ',', 'NN', 'CD', 'NNP', 'TO', 'CD', 'NNP', 'IN', 'NN', 'NN', 'NNP', 'NN', 'IN', 'CD', 'CD', 'NN', '.']\n",
            "[' ', ',', 'DT', 'NNP', 'VBD', 'NNP', 'NNP', 'NNP', ',', 'NNP', 'DT', 'NN', 'TO', 'CD', 'NN', '.']\n",
            "['IN', 'NN', 'CC', 'NN', 'NNS', 'NNP', 'JJ', '.']\n",
            "['NNP', 'NNP', 'NNP', 'TO', 'NNP', 'NNP', ',', 'NNP', 'NN', 'NN', 'NN', 'NN', 'TO', 'CD', 'NNP', 'CC', 'NNP', 'NN', 'NN', 'NNP', 'TO', 'CD', 'NNP', ',', 'IN', 'NNP', 'NN', 'NNP', 'NNP', 'TO', 'CD', 'NNP', ',', 'NNP', 'NNP', 'NNP', 'NNP', 'TO', 'NNP', 'NNP', 'CC', 'NNP', 'NN', 'NNP', 'TO', 'CD', 'NN', '.']\n",
            "[' ', 'NNP', ' ', 'TO', 'NNP', 'NNP', 'IN', 'CD', 'CD', 'NN', 'NN', 'NN', '.']\n",
            "['IN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', 'NN', 'NN', ',', 'NNP', 'VBZ', 'DT', 'NN', 'IN', 'CD', 'NN', 'CC', 'NN', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'TO', 'CD', 'NNP', '.']\n",
            "['DT', 'NN', 'NNP', 'NN', 'TO', 'NNS', 'DT', 'CD', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'IN', '$', 'CD', 'CD', 'VBZ', 'NN', 'NNS', 'TO', 'NN', 'VB', 'TO', 'NN', 'IN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NN', 'NN', '.']\n",
            "[' ', ' ', 'NNP', 'TO', 'CD', '.']\n",
            "['DT', 'NN', 'NN', 'DT', 'NN', 'NN', 'IN', 'NN', 'NN', 'VB', 'VB', '``', 'NN', \"''\", 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', 'IN', 'NNP', 'TO', 'CD', 'NNP', '.']\n",
            "['DT', 'NN', 'CC', 'NN', 'NN', 'NN', 'DT', 'NN', 'TO', 'NNS', 'NN', 'DT', 'NNP', 'NN', 'IN', 'NN', 'IN', 'NN', 'NNS', '.']\n",
            "['DT', 'NNP', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'CD', 'TO', 'NN', '.']\n",
            "[' ', 'NNS', ' ', 'NNP', '.']\n",
            "[' ', ' ', ' ', 'NNP', 'CD', 'TO', 'CD', 'NNP', '.']\n",
            "['DT', 'NN', 'NN', 'IN', 'DT', 'NNP', 'NN', 'NNP', 'IN', 'CD', 'NN', 'IN', 'DT', 'NN', 'NNP', '.']\n",
            "[' ', 'NNP', 'VBD', 'PRP', 'VB', 'NN', 'DT', 'NN', 'NN', 'NNP', 'NNP', 'NNP', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'IN', 'JJ', 'NN', '.']\n",
            "['DT', 'NN', 'VBD', 'DT', 'NN', 'VBZ', 'RB', 'NN', 'TO', 'VB', 'DT', 'NN', ',', 'NN', 'IN', 'NNS', ',', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', ',', 'DT', 'NNP', 'NNP', 'NN', 'NNP', 'NN', ',', 'VBD', 'DT', 'NN', 'VB', 'NN', 'DT', 'NNS', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', ' ', 'NNP', 'TO', 'RB', 'NNS', 'CC', 'NN', 'IN', 'DT', 'NNP', 'NN', 'NNS', 'TO', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "[' ', ' ', 'NN', 'IN', 'NNS', 'CD', 'NN', 'NN', 'NNS', 'IN', 'DT', 'NN', 'VBZ', 'NNS', 'IN', 'JJ', 'NNP', ',', 'DT', 'NN', 'VBD', '.']\n",
            "['RB', 'VBZ', 'NN', 'DT', 'JJ', 'NN', 'NN', 'TO', 'DT', 'NNS', 'IN', 'NNS', 'NN', 'NNS', 'IN', 'CD', 'CD', 'IN', 'NNP', 'CD', 'NNP', 'VB', 'VB', 'NN', 'IN', 'DT', 'IN', 'NN', 'IN', 'NNP', '.']\n",
            "[' ', ',', 'DT', 'NN', 'NN', ',', 'NN', 'CD', 'CD', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', ',', 'NNP', 'NNP', 'NN', 'NN', 'NN', ',', 'NNP', 'NNP', 'DT', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'IN', 'DT', 'IN', 'NN', 'NN', 'IN', 'NNP', 'CD', 'NNP', 'CD', 'NN', 'TO', 'NN', 'CD', 'NNS', 'NNP', 'CD', 'CD', 'CD', 'CD', 'IN', 'CD', 'CD', 'NN', 'DT', 'CD', 'NN', '.']\n",
            "[' ', 'NNP', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', 'NN', '.']\n",
            "[' ', ' ', 'CD', 'NN', 'TO', 'NN', 'CD', 'NNP', ',', 'IN', 'NN', 'NN', 'DT', 'NN', ',', 'IN', 'NN', 'CD', 'NNP', ',', 'IN', 'NN', 'NN', 'DT', 'NN', '.']\n",
            "['NNS', 'NNS', ' ', 'CD', 'NNP', ',', 'NN', 'CD', 'NN', 'IN', 'NNP', 'CD', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', 'DT', 'NN', 'NN', 'NN', 'NN', ',', 'NN', '.']\n",
            "[' ', ' ', ',', 'NNP', 'NNP', 'NNP', 'CC', 'NNP', 'NN', 'NN', 'IN', 'NNP', ',', 'VBD', ',', '``', 'DT', 'NN', 'VBZ', 'JJ', 'DT', 'NN', 'NN', 'IN', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NNP', 'NNP', ',', 'IN', 'DT', 'NN', 'CC', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NNS', 'JJ', '.']\n",
            "['``', 'RB', 'VB', 'RB', 'VBD', 'DT', 'DT', 'NN', 'IN', 'NN', 'NN', 'VBZ', 'RB', 'NN', 'IN', ',', \"''\", 'IN', 'NN', '.']\n",
            "[' ', 'NN', 'NNP', ',', 'NNP', 'NNP', ',', 'VBD', 'PRP', 'NN', 'TO', 'NN', 'DT', 'NN', 'IN', 'NN', 'NN', 'NNP', 'RB', 'VBZ', 'RB', 'VB', 'NN', 'IN', 'DT', 'NN', 'NNS', '.']\n",
            "[' ', ',', 'DT', 'NN', 'NNP', 'NN', 'IN', 'NN', 'NN', 'CD', 'CD', 'NN', 'NN', ',', 'VBD', 'RB', 'VB', 'NN', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NN', 'NN', 'IN', 'NN', 'NN', 'NN', 'NN', 'RB', 'VBZ', 'RB', 'RB', 'NN', '.']\n",
            "[' ', 'IN', 'VB', 'NNS', 'NNS', 'CC', 'NN', 'NNS', 'NN', 'NN', 'TO', 'NN', 'IN', 'DT', 'NN', ',', 'NN', 'VB', 'NN', 'IN', 'CD', 'CD', 'CC', 'CD', 'CD', 'NN', 'NN', ',', 'DT', 'NN', 'NN', 'CD', '.']\n",
            "['IN', 'NN', 'NNS', 'NN', 'NN', ',', 'NN', 'NN', 'CD', 'CD', 'TO', 'CD', 'CD', '.']\n",
            "['DT', 'NN', 'NN', ',', 'DT', 'VB', 'VB', 'DT', 'NN', 'NN', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'TO', 'VB', 'NN', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'IN', 'JJ', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "['IN', 'NNP', 'NN', 'NN', 'NN', ',', 'IN', 'DT', 'NN', ',', 'JJ', 'NN', ',', 'DT', 'NN', 'NN', ',', 'NN', 'CC', 'NN', 'NN', 'DT', 'NN', '.', 'NN', '.']\n",
            "[' ', 'NNP', 'CC', 'NN', 'NN', 'CC', 'NN', 'NNS', 'CC', 'NNS', 'NN', 'CC', 'NN', 'NNS', '.']\n",
            "[' ', 'NNP', ',', 'NN', 'IN', 'DT', 'NN', 'NN', 'CC', 'NNS', 'NN', 'NN', ',', 'VBD', 'RB', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', 'VB', 'VB', 'NN', 'IN', 'IN', 'IN', 'NN', 'CD', 'CD', 'CD', '.']\n",
            "['DT', ' ', ',', 'NNP', 'NN', 'IN', 'VBD', 'DT', 'NNS', 'NN', 'IN', 'NN', 'NN', 'VB', 'VB', 'RB', 'IN', 'IN', 'IN', 'IN', '$', 'CD', 'CD', '.']\n",
            "['IN', 'NN', 'DT', 'JJ', 'NNS', 'DT', 'NN', 'NN', 'IN', 'CD', 'CD', 'CD', 'IN', 'NN', 'CC', 'JJ', 'NNS', '.']\n",
            "['RB', 'DT', 'NN', 'NNS', 'CC', 'NN', 'NN', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NNP', 'CD', 'VB', 'NNS', 'IN', 'NN', 'IN', 'NN', 'NN', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'NN', 'RB', 'IN', '$', 'CD', 'CD', 'IN', 'NNS', 'IN', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "['NNP', ' ', ',', 'DT', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', ',', 'VBD', 'NN', 'DT', 'JJ', 'NNS', 'NNS', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNP', ',', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'DT', 'NN', 'NN', 'JJ', 'IN', 'NN', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', ',', 'NNP', 'NNP', ',', 'VBD', 'NN', 'NN', 'VBD', 'NN', 'NN', 'JJ', 'DT', 'JJ', 'NN', 'NN', 'DT', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'CC', 'NN', 'NN', 'NN', 'VBD', 'NN', 'IN', 'DT', 'NN', 'NN', 'CD', 'NN', 'TO', '$', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'CD', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'DT', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'DT', 'CD', 'NN', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'NNS', ',', 'CC', 'DT', 'CD', 'NN', 'NN', 'IN', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "[' ', 'VBD', ' ', 'NNP', 'NNS', 'IN', 'CD', 'CD', 'CD', ',', 'CD', 'IN', 'CD', 'CD', 'CD', 'DT', 'NN', 'NN', '.']\n",
            "['DT', 'VBD', 'NN', 'NN', 'NN', 'DT', '$', 'CD', 'CD', 'NN', 'IN', 'NNP', 'NNP', '.']\n",
            "['DT', 'IN', 'CD', 'DT', 'NNS', 'IN', 'DT', 'NNP', 'CD', 'NNP', 'IN', 'NNP', 'TO', 'VB', 'DT', 'IN', 'IN', 'CD', 'CD', 'CD', ',', 'CC', 'TO', 'VB', 'IN', 'IN', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', ',', 'JJ', 'DT', 'NN', 'NN', ',', 'VBD', 'VBZ', 'VBZ', 'NN', 'IN', 'NNS', 'JJ', 'CC', 'NNS', 'IN', 'NN', 'NNS', '.']\n",
            "['DT', 'NN', 'VBD', 'DT', 'RB', 'IN', 'NN', 'NN', 'RB', 'VBZ', 'RB', 'IN', 'NN', 'IN', 'NN', 'DT', 'RB', 'NN', '$', 'CD', 'CD', 'IN', 'NN', 'IN', '.']\n",
            "[' ', ' ', ' ', ' ', 'CC', 'NN', 'NN', 'NNS', 'CC', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'VBD', 'DT', 'VBD', 'DT', 'NN', 'IN', 'CD', 'NN', ',', 'IN', 'CD', 'NN', 'DT', 'NN', ',', 'IN', 'DT', 'NN', 'NN', ',', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'CD', 'NN', ',', 'IN', 'IN', 'NN', 'DT', 'NN', '.']\n",
            "['NNS', 'NNP', 'TO', 'CD', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['IN', 'DT', 'CD', 'NN', ',', 'DT', 'NN', 'NN', 'DT', 'NN', 'NN', 'IN', 'CD', 'NN', ',', 'IN', 'CD', 'NN', 'DT', 'NN', ',', 'NN', 'IN', 'NN', 'NN', 'NN', 'IN', 'CD', 'NN', ',', 'IN', 'CD', 'NN', 'DT', 'NN', '.']\n",
            "['NNS', 'NNP', 'TO', 'CD', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "[' ', 'NNP', 'NNP', 'VBD', 'PRP', 'NNP', 'CD', 'NN', 'IN', 'DT', 'JJ', 'NN', 'TO', 'DT', 'NNP', 'NNP', 'NN', ',', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'CD', 'NN', 'IN', 'NNP', 'NNP', 'NN', 'NN', '.']\n",
            "['DT', 'NNP', 'DT', ',', 'DT', 'NN', 'DT', 'JJ', 'IN', 'NN', 'NNS', ',', 'IN', 'DT', 'NN', 'NN', 'CC', 'NN', 'NN', ',', 'IN', 'NNP', 'TO', 'NNP', 'NN', '$', 'CD', '.']\n",
            "['DT', 'NN', 'VBZ', 'NN', 'IN', 'NN', 'IN', 'NNP', 'JJ', 'NN', 'IN', 'CD', 'CD', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'IN', 'RB', 'NN', 'IN', 'DT', 'NNP', 'NN', 'IN', 'DT', 'NNS', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'TO', '$', 'NN', 'DT', 'NN', '.']\n",
            "['DT', 'NN', 'IN', 'NN', 'TO', 'DT', 'NNP', 'DT', 'IN', 'IN', 'DT', 'NN', 'NN', 'IN', 'CD', 'NN', 'IN', 'NNP', 'NNP', 'TO', 'NNP', 'NNP', 'NN', 'NNP', 'IN', 'NNP', ',', 'NNP', 'CC', 'DT', 'NN', 'NN', 'NN', 'NNS', 'NN', 'NNP', 'NNP', 'NN', 'CD', 'TO', 'CD', 'CD', 'CD', ',', 'VBD', 'NNP', 'NNP', ',', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', ',', 'NNP', 'NNP', '.']\n",
            "[' ', 'NNP', 'NNP', ',', 'DT', 'NN', ',', 'NNP', 'NNP', 'NNP', ',', 'NNP', 'DT', 'NN', 'IN', 'NNP', 'NN', 'NNP', 'NNP', 'NNP', 'NNP', 'TO', '$', 'CD', 'DT', 'NN', ',', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'DT', 'NN', 'VBD', 'RB', 'VB', 'RB', 'VB', 'TO', 'NN', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "['DT', 'NNS', 'NN', 'VBD', 'RB', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'VBD', 'DT', 'NN', 'NN', 'IN', '``', 'NN', 'NN', 'TO', 'NN', '.', \"''\"]\n",
            "['IN', 'NNP', 'IN', 'NNP', 'NN', ',', 'NNP', 'NNP', 'NN', 'IN', 'IN', 'CD', 'NN', 'NN', 'CD', 'NN', 'NN', ',', 'IN', 'CD', 'NN', 'NNP', 'CD', 'CD', 'CD', '.']\n",
            "['DT', 'NN', 'NN', 'VBZ', 'NN', 'IN', 'IN', 'IN', 'CD', 'NN', 'IN', 'NN', 'NN', 'NN', ',', 'CC', 'RB', 'VBZ', 'NN', 'IN', 'NN', 'IN', 'NNP', 'CD', '.']\n",
            "['DT', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NN', 'NN', 'NNP', 'NNP', 'NN', 'TO', 'CD', 'NNS', '.']\n",
            "['IN', 'CD', 'NN', 'IN', 'NNP', 'NN', 'NN', 'NN', 'DT', 'NN', 'IN', 'DT', 'NNP', '.']\n",
            "[' ', ' ', 'NNS', 'NNP', 'VBD', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'IN', 'NN', 'NN', 'NNS', 'IN', 'NNP', 'NNS', 'RB', 'NN', '.']\n",
            "['IN', 'NN', ',', 'NN', 'NN', 'NN', 'DT', 'NN', 'NN', 'NN', ',', 'DT', 'NN', 'NNP', 'NN', 'VBZ', 'NN', 'NN', 'NN', 'NNP', 'NN', 'JJ', ',', 'NN', 'TO', 'NNS', 'IN', 'NN', '.']\n",
            "[' ', ',', 'NN', 'VBD', 'DT', 'NNP', 'NN', 'VBZ', 'RB', 'NNP', 'IN', 'NNP', 'DT', 'VB', 'VB', 'IN', 'NN', 'NN', 'NNP', 'NN', '.']\n",
            "[' ', 'VBD', 'RB', 'VB', 'VB', 'DT', 'CD', 'NN', 'NN', 'IN', 'DT', 'NNP', 'NN', '.']\n",
            "[' ', 'VBD', 'DT', 'NN', ',', 'DT', 'NN', 'NN', 'DT', 'VBD', 'NNP', 'TO', 'VB', 'NN', 'DT', 'NN', ',', 'VB', 'RB', 'NN', 'IN', 'NNP', '.']\n",
            "['DT', 'DT', 'NN', 'VBZ', 'RB', 'NN', 'TO', 'VB', 'NN', 'NN', 'NN', 'NN', 'IN', 'IN', 'IN', 'NNP', '.']\n",
            "[' ', 'VBD', 'NN', 'DT', 'NN', 'TO', 'VB', 'NN', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'DT', 'NN', 'RB', 'IN', 'RB', 'IN', 'IN', 'DT', 'NN', 'NNP', ',', 'IN', 'IN', 'RB', 'NN', 'NNS', ',', 'NN', 'VBD', '.']\n",
            "[' ', 'NNP', 'NN', 'NNP', 'NNP', 'NNP', 'IN', 'DT', '$', 'CD', 'CD', 'NN', 'IN', 'DT', 'NN', 'DT', 'NN', 'NN', 'IN', '$', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', '.']\n",
            "['DT', 'NNP', 'NNP', ',', 'NNP', ',', 'NNP', 'VBD', 'NN', 'NN', 'IN', 'CD', 'CD', ',', 'IN', 'IN', 'NN', 'DT', 'NN', ',', 'DT', 'NN', 'CD', '.']\n",
            "['DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'DT', 'DT', '$', 'CD', 'CD', 'NN', 'IN', 'NNS', 'NNS', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', ',', 'DT', 'DT', 'NN', 'VBD', 'VBD', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNS', '.']\n",
            "['DT', 'NN', 'VBD', 'DT', 'NN', 'NN', 'VB', 'NN', 'NNS', 'IN', 'NN', 'NNS', 'IN', 'DT', 'NN', '.']\n",
            "['NNP', 'NNP', 'IN', 'NN', 'CD', 'CD', 'CD', 'TO', 'NNS', 'NN', 'NNS', 'CC', 'NNS', 'CD', 'CD', 'CD', 'IN', 'NN', 'VB', '.']\n",
            "['DT', 'NNP', 'VBD', 'DT', '``', 'IN', 'NNS', 'NN', 'CC', 'NN', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', ',', 'DT', 'NN', 'NN', 'TO', 'NN', 'IN', 'NN', 'NN', 'IN', 'NNP', '.', \"''\"]\n",
            "[' ', 'NNP', 'VBZ', 'NN', 'RB', 'NN', 'IN', 'NNS', '.']\n",
            "['IN', 'NNS', 'NNS', 'TO', 'NN', ',', 'RB', 'IN', '$', 'CD', 'CD', 'IN', 'DT', 'NN', 'NN', 'IN', 'CD', 'NN', 'CD', 'DT', 'NN', 'CD', '.']\n",
            "['DT', 'NNP', 'VBZ', 'NNS', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['IN', 'IN', 'NNP', 'NNP', 'NNP', 'VBD', 'DT', 'NN', 'DT', 'NN', 'IN', 'NNP', 'NN', 'NN', 'NNP', 'IN', 'IN', '$', 'CD', 'CD', '.']\n",
            "['IN', 'IN', 'NNP', ',', 'DT', 'RB', 'VBZ', 'CD', 'NNS', 'CC', 'CD', 'CD', 'CD', 'IN', 'NNS', ',', 'NNP', 'DT', 'NN', 'TO', 'NN', 'DT', 'NNP', ',', 'NNP', ',', 'NNP', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "[' ', 'NNP', 'VBZ', 'CD', 'CD', 'CD', 'IN', 'NNS', 'CC', 'CD', 'NNS', '.']\n",
            "['DT', 'NN', 'NN', 'NNP', 'NNS', 'TO', 'NNS', 'TO', 'NNS', 'IN', 'IN', 'NN', 'NNS', 'IN', 'JJ', 'NNP', ',', 'IN', 'DT', 'VB', 'NN', 'DT', 'IN', 'IN', 'NNP', 'NN', '.']\n",
            "[' ', ',', 'NNP', 'IN', 'IN', 'NNP', 'VBD', 'RB', 'VB', 'NNS', 'DT', 'CD', 'NN', 'NNS', 'IN', 'DT', 'NNP', 'NNP', 'NN', 'NN', 'NN', '.']\n",
            "['IN', 'IN', 'NNP', 'VBD', 'IN', 'IN', 'DT', 'NNS', 'VB', 'TO', 'IN', 'NNS', 'IN', 'IN', 'IN', 'NNP', '.']\n",
            "['RB', 'RB', 'VBD', 'DT', 'NN', 'NNS', 'TO', 'NNS', 'NNS', 'RB', 'NN', 'IN', 'DT', 'NN', 'VB', 'NN', 'IN', 'IN', 'NNP', 'NN', 'NN', 'NN', 'IN', 'NNP', 'IN', 'CD', 'CD', 'CD', 'TO', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'TO', 'CD', 'NN', 'DT', 'NN', '.']\n",
            "[' ', ' ', 'NNP', ',', 'DT', 'NN', 'JJ', 'NN', 'NN', 'NN', 'NN', 'NN', 'IN', '$', 'CD', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'NNP', 'DT', 'NN', 'CD', 'NN', 'NN', 'DT', 'NN', 'IN', 'NN', 'NN', 'DT', 'NN', 'IN', 'JJ', 'NN', '.']\n",
            "['IN', 'DT', 'NN', ',', 'NNS', 'NNS', ',', 'VBD', 'NNS', 'NNS', 'IN', '$', 'CD', 'CD', ',', 'TO', 'NNS', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'IN', 'DT', 'NN', 'RB', 'NNS', 'NNS', '.']\n",
            "['IN', 'NN', ',', 'RB', 'VB', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'DT', 'VB', 'RB', 'NNP', 'NNP', 'NNP', 'NNP', '.']\n",
            "['IN', 'NNS', 'NNS', ',', 'IN', 'CD', 'CD', 'VB', 'VB', 'NNS', 'IN', 'DT', 'CD', 'CD', 'NNS', 'NN', 'NN', '.']\n",
            "['DT', 'NNP', ',', 'NNP', ',', 'NN', 'NNP', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', 'IN', 'DT', 'NN', 'DT', 'NNP', 'IN', 'NN', ',', 'RB', 'DT', 'NN', 'DT', 'NN', 'IN', 'NNS', 'CC', 'DT', 'NN', 'NN', 'NN', 'NNP', '.']\n",
            "['RB', ' ', ' ', 'RB', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', ',', 'NN', 'NN', 'IN', '$', 'CD', 'CD', 'IN', 'NNP', '.']\n",
            "['RB', 'IN', 'DT', 'NN', 'NNP', ',', 'NNP', 'NN', 'TO', 'VB', 'IN', 'IN', 'DT', 'NN', 'CC', 'NNP', 'IN', 'NN', 'NN', 'IN', 'NNP', 'NNP', '.']\n",
            "['DT', 'NN', 'DT', 'NNP', 'NNP', 'IN', 'NNS', 'NNS', 'IN', 'NN', 'NN', 'NNP', 'IN', 'NNP', 'NNP', 'CC', 'NNS', 'RB', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "[' ', 'NNP', 'DT', 'NN', 'IN', 'DT', 'NNP', 'CC', 'VBD', 'NN', 'IN', 'NN', '.']\n",
            "['DT', ' ', 'NNP', ',', 'NN', 'JJ', 'IN', 'DT', 'NN', 'JJ', ',', 'NNP', 'DT', 'NN', 'NN', 'CC', 'NNP', 'NNP', 'IN', \"''\", 'NN', 'IN', '.', \"''\"]\n",
            "['IN', 'IN', 'NNP', 'NN', 'IN', 'DT', 'NN', 'NN', 'NNP', 'CD', 'NN', ',', 'NNP', 'NN', 'DT', 'NN', 'NNP', 'NN', 'NN', 'TO', 'DT', 'NN', 'VB', 'NN', 'DT', 'NN', '.']\n",
            "['PRP', 'VBD', 'NNP', 'NN', 'VB', 'RB', 'IN', 'TO', 'NNS', 'DT', 'JJ', '.']\n",
            "['DT', 'NNP', 'NNP', 'NN', 'NN', 'DT', 'NN', 'NN', 'IN', '``', 'NN', \"''\", 'RB', 'JJ', 'IN', 'NN', 'IN', 'NN', 'JJ', 'NN', 'IN', 'DT', 'JJ', '.']\n",
            "['DT', 'NNP', 'JJ', 'NN', ',', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'VBD', 'NN', 'IN', 'VBD', 'NN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', '.', '.']\n",
            "[' ', 'NN', 'NNP', 'NNP', 'DT', 'DT', 'NN', 'IN', 'IN', 'NN', 'DT', '``', 'NN', 'NN', ',', \"''\", 'VBD', 'DT', 'IN', 'IN', 'NNS', 'JJ', 'IN', 'NN', 'NN', 'IN', 'NN', 'NN', 'IN', '``', 'DT', 'NN', 'IN', 'NN', '.', \"''\"]\n",
            "['DT', 'NN', 'NN', 'NN', ',', 'IN', 'NNP', 'IN', 'NN', 'IN', 'JJ', 'NN', ',', 'IN', 'VBD', 'NNP', 'NNP', 'TO', 'NNS', 'NNP', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'IN', 'NNP', 'NNS', 'NNP', 'TO', 'NNP', 'IN', 'DT', 'NNP', 'NNP', 'NN', 'NN', 'NNS', 'NNS', '.']\n",
            "['DT', 'NN', 'IN', 'NN', 'NN', 'VBD', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNS', 'TO', 'NNP', 'NNP', '.']\n",
            "['IN', ',', 'DT', 'NN', 'NN', 'IN', 'DT', 'DT', 'IN', 'VBD', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NN', 'VB', 'VB', 'NN', 'TO', 'NN', '.']\n",
            "[' ', 'VBD', 'NN', 'TO', 'NN', 'DT', 'NN', 'IN', 'NN', 'NN', 'IN', 'NNP', 'JJ', 'NN', 'NNS', '.']\n",
            "['DT', 'NNP', 'NNP', 'NNP', 'VBD', 'DT', 'NN', '``', 'VB', 'VB', 'NN', 'NN', '.', \"''\"]\n",
            "['IN', 'NNS', 'NN', 'JJ', 'NNS', 'VB', 'TO', 'VB', 'JJ', 'IN', 'NN', 'NN', ',', 'NNP', 'NN', 'DT', 'NN', '.']\n",
            "['NNP', 'NNP', 'IN', 'NNP', 'NN', 'TO', 'NN', 'NN', 'DT', 'NN', 'DT', 'VB', 'NN', 'IN', 'NNP', 'NN', 'NN', 'NNP', 'IN', 'DT', 'NN', 'IN', 'NN', 'DT', 'NN', 'TO', 'NN', '.', '.']\n",
            "['DT', 'NNP', 'NNP', 'NN', 'DT', 'NN', 'IN', 'NN', 'JJ', 'CC', 'NNS', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'TO', 'NN', 'NN', 'NN', '.']\n",
            "[' ', ' ', ' ', 'NN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'IN', 'IN', 'CD', 'CD', 'CD', 'IN', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "['DT', 'NN', 'NN', 'NNS', 'IN', '$', 'CD', 'CD', 'IN', 'NNS', 'CC', 'NN', 'NNS', 'IN', 'NN', 'NNP', 'IN', 'NN', 'IN', 'NN', 'NN', 'NN', 'CC', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'JJ', 'NN', 'JJ', 'JJ', 'IN', 'NNP', 'IN', 'NNS', 'IN', 'NNP', 'NNP', ',', 'NNP', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "['NNP', 'JJ', 'IN', 'IN', 'NN', 'IN', 'NN', '.']\n",
            "[' ', 'NNS', 'VBD', 'NNP', 'VBD', 'NN', 'TO', 'NN', 'NN', 'NN', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "[' ', 'IN', 'NNP', 'NNP', 'DT', 'NN', 'NN', 'NN', 'NN', ',', 'CC', 'DT', 'NN', 'NN', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'TO', 'NN', 'DT', 'NN', 'IN', 'NNP', 'NNS', 'IN', 'NNP', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "['IN', 'IN', 'NNP', ',', 'DT', 'NN', 'NN', 'NN', 'TO', 'VB', 'NNS', 'VB', 'DT', 'NNP', 'NN', 'DT', 'NN', 'TO', 'NNS', 'NNS', 'NNS', '.']\n",
            "['NNP', 'NNP', 'CD', 'IN', 'IN', 'NN', 'NN', 'IN', 'NN', 'JJ', 'IN', 'NN', ',', 'RB', 'JJ', 'NN', 'TO', 'NNS', 'NNS', 'IN', 'NN', 'NNS', 'NN', 'IN', 'NN', 'NN', 'NN', 'IN', 'NN', 'JJ', 'IN', 'NNP', '.']\n",
            "[' ', 'DT', ' ', 'VBD', 'TO', 'DT', 'NNP', 'NNP', 'IN', 'NNP', '``', 'NN', \"''\", 'IN', 'NNP', 'NNP', 'NN', 'NNP', '.']\n",
            "[' ', 'NNP', 'NNP', 'NNP', 'VBD', 'DT', 'NN', 'DT', 'NN', 'VBD', 'NN', 'CC', 'DT', 'NN', 'VBD', 'NN', '.', '.']\n",
            "['IN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'NNP', 'NNP', 'TO', 'NNS', 'IN', 'NN', 'IN', 'NN', 'CC', 'NN', 'NN', 'NNS', 'DT', 'NN', 'NN', 'VB', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "[' ', 'DT', ' ', 'NNP', 'DT', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', ',', 'JJ', 'DT', 'NN', 'DT', 'VB', 'VB', 'NN', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'NNP', 'JJ', 'VBD', 'DT', 'NN', ',', 'CD', 'NN', 'IN', 'IN', 'DT', 'NN', 'IN', 'NNP', 'NN', 'NN', 'NN', ',', 'VBD', 'NN', '.']\n",
            "['DT', 'NNP', 'NNP', 'VBD', 'DT', 'NN', 'NN', 'NN', 'NN', 'IN', 'NNP', 'CC', 'NN', 'NN', 'NNP', 'VB', 'TO', 'IN', 'IN', 'DT', 'NNP', 'IN', 'NNP', '.']\n",
            "['DT', 'NN', 'VBD', 'NN', 'IN', 'DT', 'NNP', 'IN', 'NN', 'DT', 'NNS', 'TO', 'VB', 'NN', 'IN', 'DT', 'NNP', 'CD', 'NNP', '.']\n",
            "['NNP', 'NNP', 'DT', 'NN', 'IN', 'NN', 'NN', 'TO', 'TO', 'NN', '``', 'NN', 'NNS', 'TO', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NNS', 'IN', 'NNP', 'NNP', '.']\n",
            "['DT', 'NNP', 'NNP', 'NN', 'NN', 'DT', 'NN', 'TO', 'TO', 'NN', 'DT', 'NNP', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'NN', 'VBZ', 'NNP', 'JJ', 'NN', 'NNS', ',', 'IN', 'DT', 'NNP', 'CC', 'NN', ',', 'TO', 'NN', 'VB', 'RB', 'IN', 'NN', 'IN', 'DT', 'NN', 'VBD', 'IN', 'NN', 'IN', 'DT', 'NN', 'DT', 'NN', 'IN', 'IN', 'IN', 'NNP', ',', 'IN', 'CD', 'IN', '.']\n",
            "['DT', 'NN', 'VBZ', 'NN', 'TO', 'NN', 'DT', 'NN', 'CC', 'NNP', 'NNP', 'NNP', 'DT', 'NNP', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'NNP', ',', 'NNP', 'NNP', 'CC', 'NNP', 'IN', 'NNP', 'IN', 'NN', 'NNP', 'IN', 'NNP', 'NNP', ',', 'NNP', ',', 'IN', 'NNP', 'NNP', 'IN', ',', 'IN', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'DT', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'IN', 'NNP', 'NN', 'NN', 'NN', 'NN', 'IN', 'IN', 'JJ', 'NN', 'NN', 'IN', 'DT', 'NNP', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', ',', 'NNP', 'IN', 'DT', 'NNP', 'NN', ',', 'VB', 'NNP', 'VB', 'NN', 'IN', 'DT', 'NN', 'NN', 'NNP', 'DT', 'NN', ',', 'DT', 'NN', 'VBD', '.']\n",
            "['NNP', 'DT', 'NNS', 'CD', 'CD', 'DT', 'NN', ',', 'IN', 'CD', 'CD', 'CD', ',', 'NNS', 'CC', 'DT', 'NN', 'CD', 'CD', 'CD', 'IN', 'NN', 'NNS', '.']\n",
            "[' ', ' ', 'VBZ', 'NNP', 'NNP', 'NN', 'TO', 'NN', 'NN', 'NNP', 'NNP', 'CC', 'NNP', 'NNP', 'TO', 'NN', 'DT', 'NN', '.']\n",
            "['NNP', 'NNP', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'IN', '$', 'CD', 'CD', 'DT', 'NNP', 'TO', 'NN', 'NNP', '.']\n",
            "[' ', 'VBZ', 'IN', 'NN', 'IN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'IN', 'DT', 'NN', 'TO', 'VB', 'IN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "['CC', 'NNS', 'NNS', 'IN', 'NN', 'TO', 'NNS', 'DT', 'NN', '.']\n",
            "[' ', 'NNP', 'VBZ', 'VBD', 'NNS', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'NN', 'NN', 'NN', 'DT', 'RB', 'DT', 'NN', 'IN', 'IN', 'CD', 'IN', ',', 'IN', 'CD', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['DT', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'VBD', 'NNS', 'IN', 'VBD', 'IN', 'DT', 'NN', 'DT', 'JJ', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NNS', 'IN', 'RB', 'TO', 'RB', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['PRP', 'VBD', 'DT', 'NN', 'VB', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', 'IN', 'CD', 'CD', 'CD', 'TO', 'VB', 'IN', 'IN', 'DT', 'NN', 'IN', 'NN', '.']\n",
            "['IN', 'NN', ',', 'IN', 'DT', 'DT', 'CD', 'NNS', ',', 'NNP', 'NNP', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'IN', 'NN', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "[' ', 'IN', 'NNP', 'NNP', 'NNP', 'NN', 'NN', 'NN', 'NN', ',', 'RB', 'DT', 'VBD', 'NN', 'NN', 'IN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNS', 'NNP', 'NNP', 'NNS', 'CC', 'DT', 'NN', 'IN', 'IN', 'TO', 'NNS', 'NN', 'NNS', '.']\n",
            "[' ', ' ', 'VBZ', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', 'NN', ',', 'IN', 'NN', 'VBZ', 'RB', 'NN', 'CC', 'NN', 'NN', 'IN', 'IN', 'NN', 'NNP', 'CC', 'DT', 'NNP', 'NNP', 'NNS', 'NN', 'IN', 'NN', 'NNS', '.']\n",
            "[' ', 'NNP', ',', 'DT', 'JJ', 'NN', 'NN', 'IN', 'NN', 'NN', ',', 'NN', 'DT', 'CD', 'NN', 'NNS', 'NN', 'IN', 'NN', 'NN', 'NN', '.']\n",
            "['IN', 'DT', 'NN', 'NN', 'NN', ',', 'PRP', 'NN', 'NNP', 'CD', 'NNS', ',', 'NNP', 'CD', 'CD', 'CD', 'NN', 'IN', 'IN', 'CD', 'CD', 'NN', 'DT', 'NN', 'IN', '.']\n",
            "['NNS', 'NNP', 'CD', 'NN', 'TO', 'NN', 'CD', 'NNS', 'IN', 'NNP', 'CD', 'NNP', '.']\n",
            "[' ', 'NNS', 'NNP', 'CD', 'NN', 'TO', 'NN', 'CD', 'NNS', 'IN', 'CD', 'CD', 'NNS', '.']\n",
            "[' ', ' ', 'NNP', 'TO', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', '.']\n",
            "[' ', 'NNS', 'NN', 'NN', 'TO', 'NN', 'IN', 'NN', 'NN', 'IN', 'NN', 'NNS', 'IN', 'NN', 'CC', 'NN', 'NN', 'NNS', '.']\n",
            "[' ', 'NN', 'IN', 'NN', 'NN', ',', 'JJ', 'IN', 'NN', 'NNS', 'CC', 'NNS', 'NNP', 'TO', 'NNP', 'CD', 'NNS', 'IN', 'NNP', 'CD', 'NNS', '.']\n",
            "[' ', 'IN', 'NN', 'CC', 'NNP', 'NNP', 'IN', 'NNP', ',', 'RB', 'NN', 'TO', 'NN', 'NN', 'IN', 'NN', 'NNS', ',', 'NNS', 'NN', 'NNP', 'NN', 'CD', 'NN', '.']\n",
            "[' ', ' ', 'DT', 'IN', 'DT', 'NN', 'NN', 'NN', 'NNP', 'NNP', 'NN', 'VB', 'NNS', 'TO', 'CD', 'CD', 'NNS', 'IN', 'NNP', 'CD', 'NNP', ',', 'CD', 'NN', 'IN', 'NN', 'IN', 'CD', 'CD', 'NNP', ',', 'IN', 'IN', 'NN', 'CD', 'CD', 'IN', 'NN', 'NNP', '.']\n",
            "[' ', 'DT', 'NN', 'TO', 'NN', 'TO', 'CD', 'CD', 'NNS', 'IN', 'NNP', 'CD', 'NN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', 'NN', 'NN', 'TO', 'VB', 'JJ', 'IN', ',', 'NN', 'NN', 'NN', '.']\n",
            "[' ', ' ', 'CC', 'NN', 'NNS', 'IN', 'JJ', 'NN', 'IN', 'NNP', ',', 'IN', 'NN', 'NNS', 'VBD', 'NN', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "['RB', ',', 'NNS', 'NNS', 'NNS', 'RB', 'JJ', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'VBZ', 'NN', 'IN', 'NN', 'TO', 'NN', 'NN', 'NN', 'NN', 'NN', 'TO', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['RB', 'RB', 'VBZ', 'RB', 'NN', 'RB', 'VB', 'DT', 'NN', 'NN', 'VB', 'VB', 'IN', 'DT', 'NN', '.']\n",
            "['NNP', ' ', 'VBD', 'IN', 'DT', 'NNP', 'CC', 'NNP', 'NNP', ',', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NN', 'NN', 'NN', 'DT', 'DT', 'NNP', 'DT', 'NN', 'TO', 'VB', 'NN', 'IN', 'NN', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', 'CD', 'NNP', ',', 'TO', 'CD', 'NN', ',', 'IN', 'NN', '.']\n",
            "['DT', 'NNP', 'NNP', 'NN', 'DT', 'NNS', '``', 'NNP', 'NNP', \"''\", 'TO', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['IN', ',', 'NN', 'NN', 'NNP', 'NNP', 'VBD', 'IN', 'VB', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', 'NN', 'NN', 'NNS', 'RB', 'RB', 'DT', 'NN', 'IN', 'DT', \"''\", 'NNS', \"''\", 'IN', 'NN', '.']\n",
            "['NNP', 'NNP', 'NN', 'DT', 'NNP', 'NN', 'NN', 'IN', 'NN', 'NNP', 'NNP', 'CC', 'NNP', 'NNP', 'IN', '$', 'CD', 'DT', 'NN', ',', 'IN', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['DT', 'NN', ',', 'DT', 'NN', 'DT', 'NN', 'NN', 'NN', 'DT', 'DT', 'NN', 'IN', 'NNP', ',', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['DT', ' ', 'NNP', 'NNP', 'IN', 'IN', 'NN', 'CC', 'NNP', 'NNP', 'NNS', 'NN', 'IN', 'DT', 'NNP', '.']\n",
            "['DT', 'NN', 'NN', ',', 'DT', 'NN', 'DT', 'NN', 'NN', 'IN', 'DT', 'IN', 'IN', 'IN', 'NNP', ',', 'VBZ', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'NN', 'TO', 'NN', 'IN', 'IN', 'CD', 'NN', 'IN', 'NNP', 'NN', 'NN', 'NN', ',', 'NN', 'IN', 'IN', 'NN', 'NN', '.']\n",
            "[' ', 'NNS', 'VBD', 'RB', 'NN', 'DT', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', '.']\n",
            "['DT', 'NN', 'NN', 'NNP', 'DT', 'NN', 'IN', 'DT', 'NNP', '.']\n",
            "['DT', 'NN', 'TO', 'VB', 'RB', 'NNS', 'IN', 'DT', 'NN', 'NN', 'TO', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "[' ', 'DT', 'NN', 'IN', 'NNP', 'IN', 'JJ', 'NN', 'CC', 'NN', 'NNS', 'IN', 'IN', 'NNP', 'NNS', 'CC', 'IN', 'NNS', 'DT', 'NN', 'NN', 'IN', '$', 'CD', 'CD', '.']\n",
            "[' ', 'NNP', 'NNP', 'NNP', 'NNP', 'VBD', 'IN', 'VBZ', 'NN', 'IN', 'DT', 'NN', 'NNP', 'IN', 'VBZ', 'NN', 'IN', 'CD', 'IN', '.']\n",
            "['DT', 'NNP', 'VBD', 'RB', 'NNP', '.']\n",
            "[' ', 'NNP', 'VBD', 'DT', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'DT', 'DT', 'NN', 'DT', 'NNP', 'NN', ',', 'NN', 'NN', 'IN', 'DT', 'NNP', 'CC', 'NNP', 'NNP', ',', 'NNP', 'NNP', '.']\n",
            "[' ', 'NNS', 'CC', 'NNS', 'VB', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNS', 'IN', 'NNP', 'NN', 'IN', 'DT', 'NN', 'NNP', '.']\n",
            "['DT', 'NNP', 'NNP', 'TO', 'NNS', 'CD', 'CD', 'CD', 'IN', 'NN', 'CC', 'NNS', 'NN', 'NN', 'RB', 'VB', 'NN', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'DT', 'NN', 'NN', '.']\n",
            "['NNP', 'NNS', 'DT', 'NN', 'NN', 'NNP', 'TO', 'DT', 'NN', 'CD', 'CD', 'CD', 'IN', 'IN', 'NN', 'DT', 'IN', 'DT', 'NN', 'NNS', 'NN', '.']\n",
            "['IN', 'NN', 'NNS', 'IN', 'JJ', 'JJ', 'NNS', 'NN', 'IN', 'DT', 'JJ', 'IN', 'NN', 'NN', ',', 'IN', 'NNS', 'IN', 'NN', 'NNS', 'NN', '.']\n",
            "[' ', ' ']\n",
            "['NNP', ',', 'NN', 'NNP', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', ',', 'IN', 'NNP', ',', 'NN', 'NNP', ',', 'IN', 'CD', ',', 'NNS', 'NNP', ',', 'IN', 'CD', '.']\n",
            "[' ', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'IN']\n",
            "[' ', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'IN', 'NNP', ',', 'NN', 'NN', 'NNP', ',', 'IN', 'CD', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', ',', 'IN', 'NNP', ',', 'NNP', 'NN', ',', 'IN', 'NN', '.']\n",
            "[' ', ' ', ',', 'DT', 'NN', 'NNP', 'CC', 'NN', 'NNP', 'NN', ',', 'DT', 'NNP', 'NNP', 'NNP', 'NN', ',', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "['IN', 'DT', 'VBZ', 'IN', 'DT', 'NNP', 'IN', 'NNP', 'NN', 'NNP', 'NNP', 'NN', 'CC', 'DT', 'NNP', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', ',', 'IN', 'DT', '$', 'CD', 'CD', 'NNP', 'NNP', ',', 'NNP', ',', 'NNP', 'IN', 'JJ', 'NNS', 'NNS', '.']\n",
            "[' ', 'RB', 'NN', 'NNP', 'NNP', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'TO', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "['CC', 'IN', 'NNS', 'NN', 'NNP', 'NNP', 'NNP', 'IN', 'NN', ',', 'IN', 'NN', 'NNS', 'IN', 'NN', 'DT', 'NN', 'CC', 'NN', 'IN', 'IN', 'NNP', 'NNP', 'NN', 'NNS', '.']\n",
            "['NNP', 'NNP', 'NNP', 'CD', 'NNP', 'NNP', ',', 'IN', 'NN', 'NNP', 'NNP', 'VBD', 'DT', 'NN', 'IN', 'NN', 'DT', 'NNP', 'NNP', 'TO', 'TO', 'DT', 'NN', 'NN', '.']\n",
            "[' ', ',', 'NNS', 'NNS', 'RB', 'NNP', 'NN', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'TO', '$', 'CD', 'CD', 'IN', 'RB', 'RB', ',', 'NN', 'DT', 'NN', 'VB', 'RB', 'NN', '.']\n",
            "['RB', 'IN', 'JJ', 'JJ', ',', 'NNP', 'VBZ', 'NNP', 'IN', ',', 'NN', 'IN', 'NNP', 'NNP', ',', 'IN', 'NN', ',', 'NN', 'IN', 'NN', 'NN', 'DT', 'DT', 'NN', 'VB', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'RB', 'VB', 'NNP', 'NNP', 'NNP', 'NNP', 'NNS', 'NNS', 'JJ', 'NNS', ',', 'CC', 'DT', 'NN', 'VBZ', '$', 'CD', 'CD', 'IN', 'NN', 'NN', 'NN', 'NN', 'NNS', '.']\n",
            "['DT', 'DT', 'NN', 'CD', 'CD', 'IN', 'NN', 'IN', 'NN', 'NNP', 'NN', ',', 'IN', 'NN', 'NN', 'NN', ',', 'RB', 'IN', 'NNS', 'NNS', 'VB', 'NN', 'DT', 'NN', '.']\n",
            "['NNP', 'VBZ', 'IN', 'IN', 'CD', 'CD', 'JJ', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "['DT', 'NNP', 'DT', 'VBZ', 'CD', 'NN', 'IN', 'DT', 'NN', 'CC', 'CD', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['IN', 'NN', 'JJ', 'NNS', 'NNS', 'NNP', 'NNP', 'NNP', 'NNP', 'NN', ',', 'NN', 'NNP', 'NNP', 'CC', 'NNP', 'NN', 'NNP', ',', 'RB', 'DT', 'NN', 'NN', 'DT', 'NN', 'DT', 'NN', '.']\n",
            "['IN', 'NNS', 'JJ', 'VB', 'NN', 'DT', 'NN', 'IN', 'NNP', ',', 'NNS', 'NN', 'NNP', 'NNP', 'VBZ', 'NN', 'IN', 'DT', 'NN', 'TO', 'NN', 'NNP', 'NN', 'NN', 'NNS', '.']\n",
            "[' ', ',', 'NNP', 'NNS', 'NNP', 'VBD', 'VBD', 'RB', 'IN', 'NN', 'IN', 'NN', 'DT', 'NN', 'NN', 'TO', 'NN', 'NNP', 'NNP', 'NN', 'NN', 'CC', 'JJ', 'RB', 'NNP', 'NN', '.']\n",
            "['NNP', ' ', 'RB', 'NN', 'IN', 'IN', 'DT', 'NN', '.']\n",
            "['RB', 'RB', 'IN', 'NNS', ',', 'RB', 'NN', 'NN', 'TO', 'NNS', 'NNS', 'NN', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'TO', 'RB', 'DT', 'NNS', 'JJ', 'TO', 'VB', 'NN', 'IN', 'DT', 'NN', 'IN', 'RB', '.']\n",
            "['IN', 'NN', 'NN', 'NNS', 'TO', 'NNS', 'IN', 'IN', 'NNS', 'TO', 'NN', 'NN', ',', 'IN', 'NNS', 'DT', 'NN', 'IN', 'CD', 'IN', '.']\n",
            "['DT', 'DT', 'NN', 'NNP', 'RB', 'NNP', 'IN', '$', 'CD', 'CD', 'IN', 'DT', 'NNS', 'CC', 'NNS', 'CD', 'CD', 'CD', 'IN', 'NN', 'NNS', 'NNS', '.']\n",
            "['RB', 'RB', 'NNP', 'VB', 'VB', 'DT', 'NNS', 'NNS', 'NN', 'IN', 'DT', 'NN', 'NN', 'RB', 'NN', 'IN', 'IN', 'NN', 'NN', ',', 'NN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'NN', 'VB', 'RB', 'IN', '.', '.']\n",
            "['NNP', ',', 'DT', 'NNP', 'NNP', 'NN', ',', 'NN', 'RB', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "['RB', 'DT', 'CD', 'NN', 'NN', 'NNP', 'IN', 'NN', 'NN', 'NN', 'IN', 'DT', 'JJ', 'NNS', 'DT', 'RB', 'RB', 'RB', 'NN', '.']\n",
            "['NNS', 'IN', 'NNP', 'NNS', ',', 'NNP', 'NN', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', 'NN', 'CC', 'NNP', 'NN', ',', 'RB', 'NNS', 'IN', 'NNS', 'IN', 'NNP', 'NNP', 'NN', 'IN', 'NNS', '.', 'NN', '.']\n",
            "[' ', ' ', 'DT', ',', 'NNP', 'NNP', 'CD', 'RB', 'VBZ', 'JJ', 'NNS', 'IN', 'NNP', 'NNS', 'NN', 'NNS', 'IN', 'IN', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['RB', 'IN', 'NN', 'IN', 'NN', 'NN', 'IN', 'IN', 'RB', 'IN', '$', 'CD', 'CD', 'IN', 'NN', 'NNS', 'IN', 'NN', 'CC', 'NNS', '.']\n",
            "['DT', 'NN', 'NN', 'NNP', 'NNP', 'VBZ', 'VBD', 'TO', 'VB', 'NN', 'TO', 'NNS', ',', 'NNP', 'RB', 'RB', 'NN', 'IN', ',', 'IN', 'NNP', 'NNP', 'VBD', 'NN', 'IN', 'DT', 'NN', 'NN', 'CC', 'DT', 'NN', 'NN', '.']\n",
            "['RB', 'NNP', 'NNP', 'NN', 'NN', 'TO', 'VB', 'DT', 'NNS', 'NN', ',', 'IN', 'DT', 'NN', 'NN', 'TO', 'VB', 'DT', 'NN', 'NN', 'NN', ',', 'NN', 'IN', 'IN', 'NNP', 'NNP', 'NN', 'NN', ',', 'NN', 'NNP', 'CC', 'NN', 'NNS', '.']\n",
            "['IN', 'RB', 'NNP', 'NNP', 'NNP', ',', 'DT', 'VBZ', 'DT', 'NN', 'DT', 'NNP', 'NNP', 'NN', 'NN', ',', 'VB', 'VB', 'NN', 'IN', ',', 'NNS', '$', 'CD', 'CD', ',', 'CC', 'NNS', 'TO', 'DT', 'NN', 'NN', 'DT', 'NN', 'DT', 'NNP', 'NN', '.']\n",
            "['DT', 'NNP', ' ', 'VB', 'RB', 'NN', 'IN', 'IN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', ',', 'NN', 'NN', 'NNS', 'NN', '.']\n",
            "[' ', ',', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NNS', 'NNP', 'CC', 'IN', 'IN', 'NNP', 'RB', 'RB', 'NN', 'IN', 'TO', 'NNP', 'NN', ',', 'IN', 'NNP', 'NNP', ',', 'VBD', 'VB', 'IN', 'VB', 'DT', 'NNP', 'NN', ',', 'NNS', 'NNS', '.']\n",
            "['RB', 'VBZ', 'RB', 'NN', 'VB', 'RB', 'DT', 'NN', 'TO', 'TO', 'NNP', 'NN', '.']\n",
            "['RB', '``', 'DT', 'NN', 'VBZ', 'NN', '.']\n",
            "[' ', 'NNS', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'CC', 'NNS', 'IN', 'IN', 'DT', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', ',', \"''\", 'NN', 'NNP', 'NN', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NN', 'NN', 'NN', 'DT', 'DT', 'NN', 'IN', 'NN', 'IN', 'NN', 'NNP', '.']\n",
            "[' ', 'IN', 'RB', 'NNP', 'NNP', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', ',', 'DT', 'NN', 'NN', 'VB', 'NN', 'NNP', 'TO', '.', '.']\n",
            "['``', 'RB', 'VBP', 'RB', 'RB', 'DT', 'NN', ',', \"''\", 'NNP', 'NNP', 'NNP', ',', 'DT', 'NNP', 'NNP', 'NNP', 'NNP', '.']\n",
            "['IN', 'NN', ',', 'NNS', 'TO', 'VB', 'TO', 'NN', 'NNP', 'NN', 'NN', '.']\n",
            "['CC', 'IN', 'NN', 'NNS', 'NNS', 'DT', 'NN', 'VBZ', 'RB', 'NN', 'IN', 'DT', 'NN', 'RB', 'VBZ', 'NNS', 'NNP', 'NNP', 'NNP', 'NNS', 'NNP', 'NN', '.']\n",
            "[' ', ' ', 'IN', 'NNP', 'NNP', 'NNP', 'TO', 'DT', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'NN', '.', 'NNP', 'NNP']\n",
            "['NNP', ',', 'NNS', 'CC', 'NN']\n",
            "['IN', 'NNP', 'NNP', 'NNP', ',', 'NNP', ',', 'NN', 'NN', ',', '$', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN']\n",
            "['DT', 'NN', ',', 'NNP', 'CD', ',', 'NNP', ',', 'NN', 'NN', ',', '$', 'NN', 'DT', 'NN', 'NNP', 'NN', 'NN', ',', 'CD', 'NN', 'DT', 'NN']\n",
            "[' ', 'NN', 'NN', 'NN', 'NNP', 'NNP', 'NNP']\n",
            "[' ', 'NNP', 'NN', 'NNP', 'CD', 'CD']\n",
            "[' ', ',', 'IN', 'NN', 'NNS', 'NNS', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', ',', 'NNP', ',', 'NNP', ',', 'VBD', 'DT', 'DT', 'NN', 'NNP', 'NNS', 'IN', 'NN', 'CC', 'NN', 'JJ', '.', '.']\n",
            "['DT', 'NN', 'IN', 'NN', 'NN', 'NNS', 'CC', 'NNS', 'IN', 'TO', 'VB', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'JJ', 'NNS', 'NN', '.']\n",
            "[' ', 'NNP', 'VBZ', 'NNP', 'NNS', 'NN', 'CC', 'NN', 'NN', 'IN', 'NN', 'IN', 'NN', 'NNP', 'CC', 'DT', 'JJ', 'JJ', 'NN', 'IN', '.', '.']\n",
            "[' ', 'IN', 'TO', 'IN', 'NN', 'NN', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', ',', 'NN', 'NN', 'NNS', 'CC', 'IN', 'NNP', 'NN', ',', 'NNP', 'NNP', 'VBD', '.']\n",
            "['DT', 'DT', 'NN', 'NN', 'NN', 'NN', ' ', ',', 'DT', 'NN', 'NN', 'VB', 'VB', 'NN', 'IN', 'NNP', 'NN', '.']\n",
            "['DT', ' ', ' ', ' ', 'NN', ' ', 'CC', 'NN', 'JJ', 'CC', 'JJ', 'IN', 'JJ', 'NN', 'IN', 'NN', 'NN', ',', 'NNP', 'NNP', 'VBD', '.']\n",
            "['DT', 'NN', 'NN', 'DT', 'RB', 'VBZ', 'NN', 'NN', 'NNS', '``', 'IN', 'DT', 'JJ', 'JJ', 'IN', 'NNS', 'JJ', 'JJ', \"''\", 'CC', 'DT', 'NN', 'IN', 'NN', 'DT', 'DT', 'DT', 'VBZ', 'VBZ', 'NN', '.']\n",
            "[' ', ' ', 'IN', 'RB', 'JJ', 'IN', 'NN', 'NN', 'CC', 'IN', 'NN', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', 'CC', 'NNS', 'NNS', ',', 'DT', 'NN', 'VBD', '.']\n",
            "['DT', 'NNP', 'NN', 'NNP', 'NN', 'IN', 'NNP', 'NNP', 'TO', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NN', 'DT', 'NN', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NN', 'NN', 'NNP', 'NNP', 'NNP', 'IN', 'DT', '``', 'NN', \"''\", 'NN', ',', 'JJ', 'IN', '``', 'IN', 'NN', '.', \"''\"]\n",
            "['IN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', ',', 'DT', 'VB', 'NN', 'IN', 'DT', 'NN', ',', 'VBD', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NNS', 'NNS', 'TO', 'NN', 'DT', 'NN', 'NN', 'IN', 'NNS', 'IN', 'DT', 'NN', '.']\n",
            "['NNP', 'NNP', ',', 'NNP', 'NNP', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', ',', 'TO', 'NNS', 'DT', 'NN', 'NN', 'TO', 'DT', 'NN', 'NNS', 'NN', '.']\n",
            "[' ', 'RB', 'NNP', 'IN', 'IN', 'NN', 'NN', 'DT', 'NN', 'NN', 'IN', 'NNS', 'NNS', 'CC', 'IN', 'NN', 'NN', 'IN', 'JJ', 'NNS', '.']\n",
            "[' ', 'DT', 'IN', 'DT', 'NNP', 'IN', 'NN', 'IN', 'DT', 'NN', 'NNS', 'VBD', 'RB', 'NN', 'NNP', 'NNP', 'NNP', 'NN', 'NN', 'IN', '``', 'JJ', 'NNS', 'IN', 'IN', 'NN', 'NN', 'CC', 'NN', 'NN', 'IN', 'DT', 'NN', '.', \"''\"]\n",
            "['DT', 'NNP', 'NNP', 'NNP', 'NN', ',', 'NN', ',', 'VBD', 'DT', 'NN', 'VBZ', 'RB', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['``', 'RB', 'RB', 'NN', 'DT', 'NN', 'NN', 'IN', 'NN', ',', \"''\", 'NNP', 'NNP', ',', 'DT', 'NN', 'NNP', 'NNP', 'NN', ',', 'VBD', 'IN', 'DT', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'DT', '``', 'NN', \"''\", 'NN', 'TO', 'NNS', 'RB', 'NN', 'VB', 'VB', '``', 'NNS', \"''\", 'IN', 'DT', 'NN', '.']\n",
            "['IN', 'NN', ',', 'DT', 'NN', 'NN', 'NN', 'NN', 'DT', '``', 'IN', 'NN', \"''\", 'NN', 'TO', 'NNS', '``', 'NN', 'IN', 'DT', 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "[' ', ' ', 'VBD', 'RB', 'NN', 'TO', 'NN', 'CD', 'NN', 'IN', 'NNP', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'NNP', '.']\n",
            "[' ', 'IN', 'RB', 'NN', '.']\n",
            "[' ', ',', 'DT', 'NN', 'NN', ',', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'VBD', 'VBZ', 'DT', 'NN', 'DT', 'NN', 'IN', 'DT', 'NNS', 'NN', 'NN', 'TO', 'NN', 'DT', 'NN', 'IN', 'NN', 'NNS', 'IN', 'NN', 'NNS', '.']\n",
            "[' ', ' ', 'NN', 'NN', 'IN', 'NNS', 'JJ', 'CC', 'NNS', 'NN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', '.', 'NNP', 'NN', 'NN', 'NN', ',', 'DT', 'NN', 'VBD', '.']\n",
            "['DT', 'NN', 'DT', 'DT', 'IN', 'DT', 'NN', 'TO', 'NN', 'IN', 'DT', 'NN', 'NNS', 'NN', ',', 'NN', 'CC', 'NN', 'NN', 'NN', 'IN', 'NN', 'NNS', 'NN', ',', 'DT', 'NN', 'VBD', '.']\n",
            "[' ', 'VBD', 'NNP', 'NN', 'IN', 'CD', 'CD', 'NN', 'NN', 'CD', 'NN', 'CD', 'NN', 'CC', 'VBZ', 'DT', 'NN', 'NN', 'NNS', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['DT', 'NN', 'NN', 'IN', 'IN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', 'IN', 'NNP', 'NN', '.']\n",
            "['DT', 'NN', 'TO', 'VB', 'DT', 'NN', 'TO', 'NN', 'IN', 'NN', 'NN', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNP', 'NN', 'NNS', '.']\n",
            "['DT', 'NNP', 'NNP', 'NN', 'NN', 'NNP', 'NN', 'NNS', 'IN', 'DT', 'NNP', 'NNS', 'NN', 'DT', 'NN', 'IN', 'NNS', 'IN', 'NN', 'NN', ',', 'NNP', 'CC', 'NNP', 'NNP', 'IN', 'VB', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['RB', 'IN', 'DT', 'JJ', ',', 'DT', 'NN', 'NNP', 'VB', 'NNS', 'TO', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'NNS', 'IN', 'DT', 'NNS', 'NNS', 'IN', 'DT', 'NNP', 'IN', 'NNS', 'NN', 'NNS', 'IN', 'NN', 'IN', 'DT', 'NNP', 'NNS', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'NNS', 'JJ', 'NNS', 'IN', 'NNS', 'NNS', 'DT', 'NN', 'IN', 'NN', 'IN', 'NNS', 'NNS', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', '.']\n",
            "[' ', ' ', 'VBD', 'DT', 'NNP', 'NNP', 'CC', 'NNP', 'NNS', 'NN', 'RB', 'VB', 'IN', 'NN', 'NNP', '.', 'NNP', '.']\n",
            "['RB', 'CC', 'NNS', 'VB', 'NNS', 'IN', 'DT', 'NNP', 'NN', 'NN', ',', 'DT', 'NNP', 'TO', 'NNS', 'NN', 'NN', 'IN', 'DT', 'NN', ',', 'IN', 'NNS', 'NNS', 'NNS', 'TO', 'NNS', 'NNS', 'IN', 'NNS', 'NN', 'CC', 'NNS', 'NN', 'NNS', '.']\n",
            "[' ', 'IN', 'NNP', 'NNS', 'IN', 'NNP', 'CD', 'IN', 'CD', 'CD', 'CD', 'IN', 'NN', ',', '$', 'CD', 'CD', 'IN', 'NNP', 'NNP', 'CC', 'CD', 'CD', 'CD', 'IN', 'NN', 'NN', ',', 'NN', 'TO', 'DT', 'NN', '.']\n",
            "['IN', 'DT', 'NN', ',', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', ',', 'NNP', ',', 'IN', 'NNS', 'IN', 'NNS', ',', 'DT', 'NN', 'IN', 'NN', 'NN', ',', 'IN', 'NNP', 'CC', 'NNP', 'NNP', '.']\n",
            "['NNS', 'NNS', 'CD', 'IN', 'CD', 'CD', 'CD', 'IN', 'CD', '.']\n",
            "[' ', 'NNP', 'VBD', 'RB', 'VB', 'NN', 'DT', 'JJ', 'NN', 'NN', 'TO', 'IN', 'NNS', 'IN', 'NNS', 'NNS', 'IN', 'DT', 'NN', 'NN', 'NN', 'TO', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', 'VBD', 'VBD', 'RB', 'VB', 'RB', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'RB', 'NN', 'IN', 'NNS', ',', 'CC', 'RB', 'NNS', ',', 'VB', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['RB', 'DT', 'NN', 'NN', 'VBD', 'VBZ', '``', 'NN', 'DT', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'VB', 'IN', 'IN', 'NNS', 'JJ', 'NN', '.', \"''\"]\n",
            "['DT', 'NN', ',', 'NNS', 'TO', 'NNP', 'NNS', 'CD', 'IN', 'NN', 'IN', 'NNS', ',', 'VB', 'NN', 'DT', 'NN', 'NN', 'NN', 'NNS', 'CD', 'NN', 'TO', 'CD', 'NN', '.']\n",
            "['IN', 'NN', ',', 'NNP', 'DT', 'NN', 'DT', 'NN', 'NN', 'NN', 'NN', 'TO', 'CD', 'NN', 'IN', 'NN', 'NNS', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', 'DT', 'NN', 'DT', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', 'TO', 'NN', 'NN', 'NN', 'CC', \"''\", 'DT', 'NN', 'NN', 'NN', '.', \"''\"]\n",
            "['RB', 'IN', 'NNS', 'NN', 'VB', 'IN', 'IN', 'DT', 'NN', 'DT', 'NN', 'NN', 'VB', 'VB', ',', 'RB', 'NNS', 'NNS', 'VB', 'NN', 'IN', 'RB', 'NN', '.']\n",
            "['``', 'RB', 'DT', 'DT', 'NN', 'NN', ',', \"''\", 'VBD', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', '.']\n",
            "['NNP', 'TO', 'NNP', 'NNP', 'NN', ',', 'IN', 'CD', 'NN', 'TO', 'CD', 'NN', 'IN', 'DT', 'NNS', 'NNS', 'NNS', 'VB', 'TO', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "[' ', 'IN', 'CD', 'DT', 'IN', 'CD', 'NN', 'IN', 'DT', 'NNS', 'VBD', 'NN', 'IN', 'JJ', 'NN', 'IN', 'RB', '.', '.']\n",
            "['IN', 'DT', 'NN', ',', 'NNP', 'VB', 'VB', 'NNS', 'IN', 'IN', 'CD', 'TO', 'CD', 'IN', 'DT', 'IN', 'IN', 'CD', 'NNS', 'NNS', '.']\n",
            "['IN', 'NNP', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'NN', 'NN', ',', 'NNP', 'NN', 'NNP', 'CD', 'NN', 'TO', 'CD', 'NN', 'CD', '.']\n",
            "['DT', 'NNP', 'VBD', 'VBD', 'IN', 'VBD', '``', 'VBD', 'RB', \"''\", 'TO', 'NN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NN', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', ',', 'IN', 'JJ', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'VBD', 'DT', 'NN', 'NN', 'DT', 'NN', 'NN', 'TO', 'NNP', 'IN', 'NN', 'JJ', '.']\n",
            "['DT', 'NN', 'VBD', 'DT', 'DT', 'DT', 'DT', 'JJ', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "['VBD', ' ', 'NN', 'RB', 'NNS', 'IN', 'CD', 'NNS', ',', 'DT', 'NN', 'VBD', '.']\n",
            "[' ', 'NNP', '.', ' ', 'NNP', ',', 'NNP', 'NNP', 'NNP']\n",
            "['NNP', 'NNP', ',', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', ',', 'VBD', 'NNP', 'DT', 'NNP', 'IN', 'DT', 'NN', 'NN', 'NN', 'CC', 'NNS', 'NN', '.']\n",
            "['IN', 'NN', 'DT', 'NN', 'TO', 'CD', '.']\n",
            "['``', ' ', 'NN', \"''\", 'NNP', 'NNP', 'NNP', ',', 'NNP', 'NNS', ',', 'CD', 'NN', 'NN', ',', 'DT', 'NN', 'JJ', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'NNP', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['DT', 'IN', 'DT', 'IN', 'DT', 'NN', ',', 'NNP', 'NNP', 'NNP', 'NN', 'NNP', 'DT', 'NN', 'IN', 'IN', 'NN', 'NN', '.']\n",
            "['IN', 'NN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NNP', ',', 'NNP', 'NNP', 'IN', ',', 'TO', 'NNP', ',', 'NNP', ',', 'IN', 'DT', 'IN', 'NNP', 'NNP', 'NN', ',', 'IN', 'NNP', 'DT', 'NN', ',', '``', 'NN', 'IN', 'NN', 'RB', 'IN', 'NN', 'IN', 'NNS', 'RB', 'IN', 'NN', 'IN', ',', 'RB', 'NN', '.', \"''\"]\n",
            "['DT', 'NN', 'IN', 'TO', 'NN', 'DT', 'NNP', 'VB', 'NN', 'DT', 'NN', ',', 'JJ', 'NN', 'IN', 'NN', 'VBZ', 'NN', 'VBZ', 'NN', 'IN', 'NN', 'DT', 'NN', 'IN', '.', 'NNS', 'CC', 'NNS', 'NNS', '.']\n",
            "[' ', 'IN', 'NN', ',', 'NNP', 'NNP', 'CC', 'IN', 'NNP', ',', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NNP', ',', 'IN', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NN', 'TO', 'DT', 'NN', 'IN', 'NN', 'NN', 'NN', ',', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNS', 'NN', 'NNS', 'IN', 'DT', 'NN', 'CC', 'NNP', '.']\n",
            "['DT', 'NN', 'NN', 'IN', 'NNP', 'NNP', ',', 'DT', 'NNP', 'IN', 'DT', 'NN', ',', 'CC', 'NNP', 'NNP', ',', ',', 'NNP', 'IN', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', 'NN', '.']\n",
            "[' ', 'NNP', 'IN', 'NNP', ',', 'NNP', 'VBD', 'RB', 'RB', 'VB', 'NN', 'IN', 'NNP', ',', 'IN', 'NNP', 'NNP', 'NNP', 'DT', 'NN', 'NN', 'NN', 'NN', 'NNP', 'NNP', 'DT', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "['DT', 'DT', 'DT', 'NN', ',', 'IN', 'NN', 'NN', 'DT', 'NN', 'NNS', 'NN', 'NNS', 'VB', 'NN', 'NN', 'TO', 'NN', 'NNS', '.']\n",
            "['NNP', 'NNP', ' ', 'DT', ',', 'NN', 'IN', 'NN', 'NNP', ',', 'NNP', 'NNP', 'RB', 'VB', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'IN', 'VBD', 'NNP', 'IN', 'NNP', 'NNP', '.']\n",
            "['DT', 'IN', 'NNP', 'NN', 'VBD', 'TO', 'NNS', 'DT', 'NN', 'NN', 'IN', 'DT', 'NNP', '.']\n",
            "[' ', 'IN', 'NNP', 'RB', 'NNP', ',', 'IN', 'NN', 'IN', ',', 'NN', 'NNP', ',', 'NN', 'NNP', ',', 'CC', 'RB', 'IN', 'IN', 'DT', 'NN', 'CC', 'IN', 'TO', 'DT', '.', '.']\n",
            "[' ', 'RB', 'DT', '``', 'NN', 'NN', '``', 'NN', 'VBD', 'NNP', 'IN', 'DT', 'NNP', 'NNP', ',', 'DT', 'NN', 'IN', ',', 'IN', 'NNP', 'IN', 'NNP', 'NNP', 'IN', 'IN', 'NNP', 'NN', 'NN', '.']\n",
            "['DT', 'NN', ' ', 'NN', 'NN', 'IN', 'NNP', 'NN', 'NN', 'IN', 'NN', 'DT', 'NNP', 'NNP', 'CC', 'JJ', 'IN', 'DT', 'NN', 'NNP', 'NNP', 'NNP', 'NN', 'IN', 'DT', 'NNP', 'NN', '.']\n",
            "[' ', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', 'RB', 'NNP', 'DT', 'NN', 'NN', 'NN', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', 'NN', ',', 'NNP', 'CC', 'NN', 'NN', 'NN', 'CC', 'NNS', 'IN', 'TO', 'NN', 'NN', ',', 'DT', 'IN', 'TO', 'CC', 'IN', 'NNP', 'NNP', 'NNP', ',', 'NNP', 'NNP', 'CC', 'NNP', 'TO', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', '.']\n",
            "[' ', 'VBD', 'RB', 'RB', 'NN', 'NN', 'JJ', 'NN', '.']\n",
            "['DT', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NNS', 'IN', 'NN', 'NN', ',', 'NN', 'NNS', 'NN', '``', 'NN', \"''\", 'NN', 'NNS', ',', 'NNP', 'NNS', 'CC', 'JJ', 'NNS', ',', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', '.']\n",
            "['IN', 'NN', ',', 'RB', 'NN', 'CC', 'NN', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "[' ', 'DT', ' ', 'NNP', 'NNP', 'IN', 'DT', 'NN', '.']\n",
            "[' ', ' ', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['RB', 'RB', 'IN', 'NNS', 'NN', 'IN', 'DT', 'NNS', 'NN', 'RB', 'NN', 'RB', 'IN', 'NN', 'IN', 'DT', 'NN', ',', 'RB', 'NN', '.']\n",
            "['RB', 'RB', 'IN', 'RB', 'DT', 'NN', 'NNP', ',', 'RB', 'IN', 'NN', 'IN', 'IN', 'DT', 'JJ', ',', 'DT', 'NN', 'DT', 'NN', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NN', 'NNP', 'NN', '``', 'NN', \"''\", 'NN', '.']\n",
            "['RB', 'NN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'CC', 'DT', 'JJ', ',', 'NNS', 'NN', 'NNP', 'NN', ',', '``', 'NN', 'NN', \"''\", 'JJ', 'NN', 'IN', 'IN', 'NN', 'NN', '.']\n",
            "[' ', 'IN', 'DT', 'NNS', 'NN', 'RB', 'JJ', ',', 'NNS', 'IN', 'NN', 'DT', 'IN', 'NN', 'IN', 'DT', 'NN', '.']\n",
            "[' ', ' ', ' ', ' ', ' ', 'RB', 'TO', 'NN', 'IN', '.']\n",
            "['DT', ' ', 'NNS', 'IN', 'NN', 'NN', 'JJ', ',', 'JJ', 'NNS', 'VBD', 'VBD', 'NN', 'NNS', ',', 'NN', 'NNS', ',', 'NN', 'IN', ',', 'NNS', 'NNS', '.']\n",
            "['IN', 'DT', 'NN', 'IN', 'RB', ',', 'RB', 'DT', 'VBZ', 'NNP', 'IN', 'NN', 'CC', 'NN', ',', 'IN', 'JJ', 'NN', 'IN', 'RB', 'NN', '.', '.']\n",
            "['DT', 'DT', 'NN', 'IN', 'CD', 'JJ', 'NN', 'VBD', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NN', 'VBD', 'NN', 'IN', 'NN', 'TO', 'NNP', 'NNP', 'NNP', 'CC', 'NNP', 'DT', 'NN', 'NN', 'CC', 'NNP', 'IN', 'DT', 'NN', 'IN', 'NN', '.']\n",
            "['IN', 'NNP', 'DT', 'NN', 'IN', 'DT', 'NN', ',', 'RB', 'IN', 'IN', 'TO', 'VB', 'NNP', '.']\n",
            "[' ', 'IN', ' ', 'IN', '``', 'NN', 'NN', 'NN', \"''\", 'NNS', ',', 'DT', 'NNS', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', ',', 'NN', 'DT', 'NN', 'NNP', 'NN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NN', 'NNP', 'DT', 'NN', 'IN', '.', '.']\n",
            "['RB', 'RB', 'IN', 'CD', 'NNS', 'IN', 'TO', 'NN', 'DT', 'DT', 'NNS', 'VB', 'VB', 'TO', 'NN', \"''\", 'NN', 'NN', 'NN', 'NNS', '.', \"''\"]\n",
            "[' ', 'IN', 'NN', 'NNP', 'NN', 'DT', 'NN', 'NNS', 'DT', 'NN', 'RB', 'IN', 'NN', 'IN', 'DT', 'NNP', 'CC', 'IN', 'NN', 'NN', 'IN', 'NNS', 'RB', 'IN', 'TO', 'NN', 'RB', 'IN', '.']\n",
            "[' ', 'IN', 'NNS', ',', 'NNS', 'IN', 'DT', 'NNS', 'IN', 'NNP', ',', 'NNS', 'DT', 'NN', 'NN', 'IN', 'NN', '.']\n",
            "['RB', 'TO', 'IN', 'IN', 'NN', 'NNS', 'DT', 'NNS', 'NNS', 'IN', 'NN', '.']\n",
            "[' ', 'VBP', 'NNS', 'RB', 'DT', 'RB', 'NN', '.']\n",
            "['``', ' ', 'NN', '``', 'VBZ', 'NN', 'DT', 'NNS', 'JJ', '.']\n",
            "['IN', 'CC', 'IN', 'IN', 'NNS', 'IN', 'NN', 'IN', 'DT', 'NNP', 'NNS', 'NNS', 'IN', 'IN', 'VBD', 'VB', 'NN', 'RB', 'NN', 'IN', 'NN', 'TO', 'DT', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "['RB', 'RB', 'DT', 'NN', 'NN', 'VBZ', 'NN', 'NN', ',', 'NN', 'NN', 'IN', 'NN', 'DT', 'JJ', 'NN', 'NN', ',', 'IN', 'VBZ', 'NN', 'NN', 'TO', 'VB', 'IN', 'IN', 'NN', ',', 'NN', 'IN', 'NNS', 'DT', 'NN', 'CC', 'NNS', 'IN', 'NN', '.']\n",
            "['RB', 'VBP', 'NN', 'DT', 'IN', 'DT', 'NNP', 'NN', 'NN', 'NN', 'CC', 'RB', 'RB', 'NN', 'NN', 'NN', 'TO', 'VB', 'RB', 'NN', '.']\n",
            "['RB', 'NNS', 'NN', 'NNS', 'CC', 'NNS', 'NNS', 'RB', 'RB', 'DT', 'DT', 'NNS', 'IN', 'JJ', 'NNS', '.']\n",
            "['DT', 'DT', 'DT', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', 'CC', 'NNP', 'NN', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'NN', 'NN', 'NNP', ',', 'NNP', '.']\n",
            "['DT', 'NN', 'NN', 'CC', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'NN', 'TO', 'DT', 'DT', 'NN', 'NN', 'TO', 'NN', 'JJ', 'IN', 'DT', 'NN', 'NNP', 'NN', 'NN', 'IN', 'CD', 'NNS', '.']\n",
            "['DT', 'NNP', 'NN', 'VB', 'TO', 'TO', 'NN', 'DT', 'NNP', 'NN', 'NNS', ',', 'NNS', 'VBD', '.']\n",
            "['``', 'DT', 'NN', 'VBZ', 'DT', 'DT', 'NN', 'NN', 'VB', 'VB', 'IN', 'IN', 'DT', 'NNP', 'NN', '.']\n",
            "[' ', 'RB', 'RB', 'IN', 'IN', 'IN', 'DT', 'NNP', 'NN', ',', \"''\", 'VBD', 'NN', 'NNP', ',', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', ',', 'NNP', 'NN', 'IN', 'NNP', 'NNP', '.']\n",
            "[' ', 'DT', 'NN', 'VBZ', 'NN', ',', 'DT', 'NNP', 'NN', 'VB', 'NN', 'NN', 'IN', 'NN', 'NN', 'TO', 'NN', 'IN', 'NN', 'NN', 'NN', 'NN', 'NNP', 'NNS', '.']\n",
            "[' ', 'TO', 'RB', 'NN', 'DT', 'NN', 'CC', 'DT', 'NN', 'NN', 'TO', 'IN', 'NN', 'VBZ', 'NN', 'TO', 'NN', 'DT', 'NN', 'IN', 'NNS', 'NNS', 'IN', 'NN', 'NN', 'NN', 'IN', 'NN', 'NNP', ',', 'NN', 'NN', 'VBD', '.']\n",
            "['IN', 'DT', 'NN', 'NNP', 'NN', ',', 'DT', 'NN', 'CC', 'NN', 'NN', 'IN', 'NNP', 'VB', 'NN', 'NN', 'NN', 'IN', 'DT', 'NNP', 'NN', ',', 'DT', 'IN', 'CD', 'CD', 'NN', 'CD', 'NN', 'CD', 'CD', 'CD', 'CD', '.']\n",
            "[' ', ' ', 'DT', 'TO', 'NN', 'CD', 'CD', 'CD', ',', 'JJ', 'IN', 'RB', 'IN', 'NN', 'NN', ',', 'CC', 'TO', 'DT', 'NN', 'NN', 'IN', 'DT', 'NNP', 'NN', '.']\n",
            "[' ', 'NN', 'NNS', 'IN', 'NN', 'NNP', 'NN', 'NNS', 'JJ', 'NNS', 'NNS', 'TO', 'NNS', 'IN', 'IN', 'DT', 'NN', 'CD', 'CD', 'CD', 'IN', 'NN', 'IN', ',', 'NN', 'NN', 'VBD', '.']\n",
            "[' ', 'NNP', 'DT', 'NN', 'NN', 'VBZ', 'NN', 'NN', 'NN', 'NNS', 'NNP', '.']\n",
            "[' ', ',', 'DT', 'VBZ', 'IN', 'JJ', 'IN', 'NN', 'IN', 'NNP', 'NNP', ',', 'NNP', 'NN', 'IN', '$', 'CD', 'CD', 'NN', 'IN', 'DT', 'NN', 'NN', 'DT', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', 'NN', 'NN', 'IN', 'NNP', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'TO', 'RB', 'NN', 'NN', ',', 'NN', 'NN', 'NNP', 'VBD', 'RB', 'NN', 'TO', 'NNS', 'IN', 'IN', 'DT', 'NN', 'CC', 'NN', 'NN', 'NN', 'IN', 'NNP', 'CC', 'IN', 'NNS', 'NNS', 'TO', 'NNS', 'DT', 'NN', 'CC', 'NNS', 'IN', 'IN', '.']\n",
            "['IN', 'CC', ',', 'DT', 'NN', 'NN', 'TO', 'NNS', '$', 'CD', 'CD', 'IN', 'NNS', 'IN', 'DT', 'NN', ',', 'DT', 'VB', 'RB', 'NN', 'DT', 'NN', 'NN', ',', 'DT', 'NN', 'VBD', '.']\n",
            "['IN', 'NN', ',', 'DT', 'NN', 'VBZ', 'NNP', 'DT', 'NNP', 'CC', 'NNP', 'NNP', ',', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', ',', 'TO', 'NNP', 'NNP', 'NNP', 'NNP', '.']\n",
            "['NNP', ' ', 'VBD', 'IN', 'VBD', '``', 'JJ', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'RB', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', 'DT', 'JJ', 'IN', 'NN', '.', \"''\"]\n",
            "[' ', 'IN', 'NNP', 'NNP', 'NNP', 'NN', ',', 'NN', 'NN', 'NNP', 'DT', 'NN', 'NNP', 'IN', 'NNP', ',', 'NNP', ',', 'TO', 'NNP', 'NNP', ',', 'IN', 'DT', 'NN', 'NN', 'DT', 'NN', 'NN', 'NNS', '.']\n",
            "['NNP', ' ', 'NNP', 'IN', 'NNP', '.']\n",
            "[' ', ' ', 'VBD', 'VBD', 'TO', 'RB', 'NN', 'IN', 'NN', 'IN', 'IN', 'NNP', 'NNP', 'IN', 'NNP', ',', 'NNP', ',', 'RB', 'DT', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'CC', 'NN', 'NN', 'IN', 'NN', '.']\n",
            "['IN', 'NNP', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'NN', 'NN', 'NN', ',', 'NN', 'NN', 'NN', 'IN', '$', 'CD', 'DT', 'NN', ',', 'IN', 'CD', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NNP', 'DT', 'CD', 'NN', 'NN', 'IN', 'NN', 'NN', ',', 'NN', 'NN', 'NN', 'IN', 'IN', 'IN', 'DT', 'NNS', 'NNS', 'NN', 'NN', 'NN', '.']\n",
            "['DT', 'NNP', 'NNP', 'NN', 'NNP', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'DT', 'NN', ',', 'CD', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'DT', 'NN', 'NN', '.']\n",
            "['NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'CD', 'CD', 'CD', ',', 'DT', 'CD', 'NN', 'NN', 'IN', 'IN', 'IN', 'NN', 'CD', 'CD', 'CD', '.']\n",
            "['IN', 'DT', 'NN', 'NN', 'NNP', 'CD', ',', 'NNP', 'NNP', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'IN', 'CD', 'NN', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'JJ', 'DT', 'NN', 'IN', '$', 'CD', 'CD', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "['NNS', 'IN', 'DT', 'NN', 'NN', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['NNP', 'VBD', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNP', ',', 'NNP', ',', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNP', 'CC', 'DT', 'NN', 'IN', 'NN', 'NNS', 'DT', 'NN', '.']\n",
            "['DT', ' ', 'NN', ',', 'DT', 'NN', 'NN', 'NN', ' ', 'CC', 'NN', 'NN', 'NNS', ',', 'TO', 'RB', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'RB', ',', 'DT', 'NN', 'VBD', '.']\n",
            "[' ', ' ', 'DT', 'NN', 'NN', 'NN', 'TO', 'NN', 'NN', 'IN', 'NNS', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'RB', 'IN', 'NN', 'NN', ',', 'IN', 'NNS', 'NN', 'NN', 'NN', '.']\n",
            "['IN', 'DT', 'NN', ',', 'NN', 'NN', 'NN', 'VBD', 'NN', ',', 'DT', 'NN', 'VBD', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', ',', 'RB', 'IN', 'IN', 'IN', 'IN', 'NN', '.']\n",
            "['DT', 'NN', 'NNS', 'NN', 'NN', 'IN', 'NN', 'NNS', 'IN', 'NN', 'CC', 'IN', 'NN', 'NN', 'NN', ',', 'RB', 'NN', '.']\n",
            "['NNP', 'VBD', 'DT', 'NN', 'NN', 'NN', 'VBD', 'NN', 'IN', 'NN', 'NN', 'JJ', 'IN', 'NNP', 'NNP', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NN', 'IN', 'CD', 'NNP', ',', 'IN', 'CD', 'CD', ',', 'IN', 'NNP', 'NNP', 'NNP', 'NN', 'NNP', 'NN', '.']\n",
            "['NNS', 'NNP', 'NNS', 'NN', 'NN', 'NN', 'NN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'NNS', 'NN', 'NN', '.']\n",
            "['DT', 'NNS', 'NNS', 'NN', 'IN', 'IN', 'CD', 'IN', 'NNS', ',', 'CC', 'VBD', 'DT', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'CC', 'NN', 'NN', 'JJ', 'NNS', 'NNS', 'NNS', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'IN', 'CD', 'IN', 'NNS', 'NNS', 'NNS', 'NNS', 'IN', 'DT', 'NNS', 'CD', 'CD', '.']\n",
            "[' ', ',', 'NN', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['IN', 'NNP', 'NNP', 'VBD', 'PRP', 'NN', 'DT', '$', 'CD', 'CD', 'NN', 'NN', 'IN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NNP', 'NNP', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'DT', 'NN', 'JJ', 'NNS', 'IN', 'DT', 'NNP', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'NNS', 'NNS', 'RB', 'NN', 'DT', 'NNS', 'NNS', 'NNS', 'TO', 'VB', 'RB', 'NNP', 'NNS', 'CC', 'NNS', 'TO', 'NN', 'DT', 'NN', 'NNS', 'NN', 'NN', 'TO', 'NNS', 'IN', 'NN', 'NN', 'NN', 'JJ', '.']\n",
            "[' ', ' ', 'NNS', 'NNS', 'NNS', 'CD', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', 'NNS', 'CC', 'IN', 'NNS', 'NNS', 'NNS', 'DT', 'NN', 'NN', 'IN', 'NN', '.']\n",
            "['CC', 'IN', 'NNS', 'NNS', 'NNS', 'JJ', 'DT', 'NNS', 'NNS', 'VB', 'NNS', 'DT', 'NN', 'IN', 'NNS', 'NNS', 'TO', 'VB', 'VB', 'IN', 'DT', 'NN', 'TO', 'NN', 'VB', 'NNS', 'TO', 'DT', '.', '.']\n",
            "['DT', 'NN', 'NN', 'NNP', 'CD', 'CD', 'CD', 'CD', 'IN', 'NNP', 'NN', 'IN', 'NNP', ',', 'DT', 'DT', 'DT', 'JJ', 'NN', 'NNP', 'TO', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NNP', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'RB', 'IN', 'RB', 'NN', 'IN', 'NNP', ',', 'DT', 'VB', 'VB', 'DT', 'NN', 'IN', 'JJ', 'IN', '.']\n",
            "['RB', 'RB', 'VBZ', 'JJ', 'NNS', 'DT', 'NN', 'NN', 'IN', 'NN', 'IN', 'NNS', 'IN', 'DT', 'NNP', 'NNP', ',', 'IN', 'DT', 'NN', 'IN', 'IN', 'DT', 'NNP', 'NN', 'DT', 'VBZ', 'NNS', 'NNS', '.']\n",
            "['``', 'RB', 'VBP', 'NN', 'DT', 'JJ', 'NNS', 'IN', 'DT', 'IN', 'IN', 'IN', 'NN', 'TO', 'DT', 'NN', 'IN', 'NN', ',', \"''\", 'VBD', 'NNP', 'NNP', ',', 'DT', 'NNP', 'NN', 'NNP', 'NN', 'NN', '.']\n",
            "['``', 'RB', 'VBZ', 'RB', 'TO', 'VB', 'NN', 'NN', '.', \"''\"]\n",
            "[' ', 'IN', 'NN', 'NN', 'JJ', 'IN', 'DT', 'NNP', 'NNP', ',', 'DT', 'IN', 'NN', 'IN', 'DT', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'VBZ', 'RB', 'NN', 'DT', 'NNS', 'NNP', 'NNS', 'NNS', 'NNS', 'NNS', 'DT', 'JJ', 'IN', 'NNS', 'IN', 'NNS', 'NN', 'IN', 'DT', '.', '.']\n",
            "['IN', 'DT', 'JJ', 'JJ', ',', 'NNS', 'NNS', 'RB', 'NN', 'RB', 'RB', 'VB', 'TO', 'NNS', 'NN', 'NN', 'IN', 'IN', 'NNP', 'NNP', 'RB', 'DT', 'NNP', 'NN', 'NN', 'IN', 'NNS', 'DT', 'NN', 'TO', 'NN', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NNP', '.']\n",
            "['DT', 'NN', 'NN', 'DT', 'NN', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'IN', 'IN', 'NNS', 'VBD', 'IN', 'NN', 'RB', 'IN', 'NN', 'IN', 'NNS', 'IN', 'DT', 'NNS', 'DT', 'NN', '.', '.']\n",
            "[' ', 'NNS', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'NN', 'IN', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'VB', 'NN', 'NN', 'DT', 'NN', '.']\n",
            "['RB', 'DT', 'NN', 'NN', 'IN', 'NNS', 'NN', 'DT', 'NNP', 'NN', 'TO', 'NNS', 'NN', 'DT', 'NN', '.']\n",
            "['IN', 'NNP', 'NNP', ',', 'DT', 'NN', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'VBZ', 'NN', 'NN', 'IN', 'CD', 'NN', 'CC', 'RB', 'VB', 'NN', 'DT', 'NNS', 'CD', 'IN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'DT', 'NN', ',', 'DT', 'NN', 'NN', 'NN', 'VBD', '.']\n",
            "[' ', 'NNS', ' ', ' ', 'NNS', 'IN', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'CD', 'IN', '.']\n",
            "['RB', 'RB', ',', 'DT', 'NN', 'NN', 'NN', 'NN', 'JJ', 'JJ', 'RB', 'RB', 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNS', 'NNS', 'IN', 'DT', 'NNP', 'NN', 'IN', 'NN', '.']\n",
            "[' ', ' ', 'NNS', 'CC', 'NNS', 'IN', 'DT', 'NN', 'IN', 'DT', 'NNS', 'NNS', 'NNS', 'NNS', 'IN', 'TO', 'NNS', 'DT', 'NN', 'RB', 'NN', 'TO', 'NNS', 'NNS', 'IN', 'NNS', '.']\n",
            "['IN', 'DT', 'NN', 'IN', 'NN', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNP', 'NN', 'NN', 'CD', 'NN', 'DT', 'NN', 'TO', 'NNS', 'IN', 'CD', 'CD', 'DT', 'NN', '.']\n",
            "[' ', 'NNS', 'RB', 'IN', 'NN', 'DT', 'NN', 'JJ', 'DT', 'NN', 'JJ', 'NN', 'NN', 'DT', 'NN', 'VBZ', 'NN', 'NNS', 'TO', 'NN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NNP', 'NN', '.']\n",
            "['IN', 'DT', 'NN', 'NN', 'NN', ',', 'NN', ',', 'IN', 'NNS', 'NNS', 'NNS', 'DT', 'NNS', 'VB', 'NN', 'IN', 'IN', 'NNS', 'IN', 'NNP', 'NNS', 'TO', 'TO', 'NNS', 'DT', 'NN', 'RB', 'NNS', 'NNS', 'TO', 'NNS', '.']\n",
            "[' ', 'IN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNS', 'IN', 'TO', 'NN', 'IN', 'NNS', 'NNS', '.']\n",
            "[' ', 'DT', 'NN', 'NN', 'NNP', 'NNS', ',', 'RB', 'RB', 'IN', 'IN', 'RB', 'NNS', 'NN', 'IN', 'IN', 'IN', 'NN', ',', 'CC', 'DT', 'NNS', 'VB', 'TO', 'NNS', 'IN', 'NNS', 'TO', 'NN', '.']\n",
            "['IN', 'IN', 'IN', 'NNP', ',', 'IN', 'NN', ',', 'IN', 'NNS', 'NNS', 'NNS', 'NNS', 'NNS', 'CD', 'CD', 'DT', 'NN', 'IN', 'NN', '.']\n",
            "['IN', 'NNS', 'RB', 'VB', 'RB', 'NNS', 'IN', 'NNS', 'NN', 'IN', 'CD', 'CD', 'NN', 'DT', 'NN', ',', 'VBD', 'NNP', 'NNP', ',', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', ',', 'NNP', '.']\n",
            "['RB', 'VBZ', 'RB', 'NN', ',', 'NN', ',', 'VBD', 'VB', 'NN', 'DT', 'NN', '.', '.']\n",
            "[' ', 'NNP', 'NNS', 'NNS', 'NN', 'IN', 'NNS', 'CD', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', ',', 'DT', 'NN', 'NN', 'NNS', 'DT', 'CD', 'NN', 'IN', 'DT', 'NN', 'VB', 'RB', 'RB', 'IN', 'NN', 'IN', 'DT', 'NNP', 'NN', 'NN', 'NN', '.']\n",
            "['IN', 'NNS', 'NNS', 'NNS', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'JJ', 'VB', 'NN', 'NNS', 'TO', 'NNS', 'NNS', 'NNS', 'NNS', 'NNS', 'NNP', 'IN', 'TO', 'VB', '.', 'NN', '.']\n",
            "['``', 'DT', 'NN', 'DT', 'NN', 'DT', 'NN', 'IN', 'IN', 'NN', 'IN', 'VBZ', 'NN', 'IN', 'NN', 'TO', 'VB', 'NNS', ',', \"''\", 'VBD', 'NNP', 'NNP', ',', 'NNP', 'NNP', 'NNP', 'NNP', '.']\n",
            "['RB', 'RB', 'IN', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'TO', 'IN', 'NNP', 'IN', 'NN', ',', 'RB', 'VBZ', 'NN', 'IN', 'NNS', 'TO', 'NNS', 'DT', 'NNP', 'NNP', 'IN', 'NN', 'DT', 'NN', 'NN', 'IN', 'NN', 'IN', 'NN', 'TO', 'DT', 'NN', '.']\n",
            "[' ', 'IN', 'DT', 'NN', 'NNP', 'CC', 'NNP', 'NNP', 'VB', 'IN', 'JJ', 'NN', 'IN', 'NNP', 'NNP', '.']\n",
            "['DT', 'NNP', ',', 'IN', 'NN', ',', 'VBZ', 'NN', 'NN', 'DT', 'NN', 'NNS', 'NN', 'IN', 'NNP', 'TO', 'NNP', '.']\n",
            "['CC', 'RB', 'VBZ', 'RB', 'NN', 'DT', 'DT', 'NN', 'NN', 'VB', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', 'NN', 'IN', 'NNS', '.']\n",
            "['DT', 'NN', 'NN', 'JJ', 'NN', 'NN', 'NNP', 'NNS', 'VBD', 'IN', 'DT', 'NN', '.']\n",
            "['RB', 'DT', 'NNS', 'NN', 'IN', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'IN', 'IN', 'NN', 'NNS', '.']\n",
            "['IN', 'NNS', 'NN', 'NNS', 'NN', ',']\n",
            "[' ', 'NNP', 'NNS', 'NN', 'NNP', 'NNS', 'NN', 'IN', 'NNS', 'NN', ',', 'RB', 'IN', 'IN', 'DT', 'NN', 'IN', 'IN', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', 'IN', 'DT', 'NN', 'DT', 'DT', 'NN', 'IN', 'NN', 'NN', 'VBD', 'NN', 'IN', 'DT', 'NN', ',', 'NNS', 'DT', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'NN', 'IN', 'NNP', 'NN', 'NN', 'IN', 'NNP', 'NN', 'DT', 'NN', ',', 'IN', 'DT', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'IN', 'NNP', 'NN', 'NNP', 'CD', 'NN', 'TO', '$', 'NN', 'DT', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', 'DT', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "[' ', ' ', ',', 'NNP', 'NNS', 'NNP', 'IN', 'NN', 'NN', 'CC', 'NN', 'IN', 'IN', 'DT', 'NNP', 'NNS', '.']\n",
            "['NNP', 'NN', 'NN', 'NNP', 'CD', 'NN', 'DT', 'NN', 'TO', '$', 'NN', '.']\n",
            "['NNP', 'NNP', 'NNP', 'NN', 'NN', 'DT', 'NN', 'TO', '$', 'NN', '.']\n",
            "['NNP', 'NNP', 'DT', 'NN', 'CD', 'CD', 'DT', 'NN', 'IN', 'CD', 'NN', '.']\n",
            "[' ', ' ', ',', 'NNP', 'IN', 'NN', ',', 'NN', 'NNS', 'IN', 'JJ', 'IN', 'IN', 'NN', 'NN', 'JJ', 'IN', 'DT', 'NN', 'IN', 'NNS', 'NNS', 'NN', 'NN', 'NN', ',', 'NN', 'TO', 'NNP', 'NNP', ',', 'NNP', 'NNP', 'IN', 'NNP', 'IN', 'NNS', 'NNP', 'IN', 'NNP', 'NNP', '.']\n",
            "['``', 'DT', 'NN', 'NN', 'IN', 'NN', 'NNP', 'VBD', 'DT', 'NN', 'IN', 'NN', 'CC', 'NNS', 'IN', 'NNP', ',', \"''\", 'IN', 'VBD', '.']\n",
            "[' ', ',', 'DT', 'NN', 'NN', 'NNP', 'NN', ',', 'JJ', 'DT', 'JJ', 'NN', 'NN', 'JJ', 'JJ', 'NNS', 'NNS', ',', 'IN', 'VBD', '.']\n",
            "[' ', 'CC', 'NN', ',', 'DT', 'RB', 'IN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', ',', 'IN', 'RB', 'NN', ',', 'IN', 'VBD', '.']\n",
            "[' ', 'VBZ', 'IN', 'IN', 'NN', 'IN', '``', 'JJ', 'IN', '``', 'NNS', 'IN', 'NNS', 'IN', 'DT', 'NN', 'NN', ',', 'IN', 'VBD', '.']\n",
            "[' ', ',', 'NNS', 'NNS', 'NNP', 'IN', 'NNP', 'CD', 'TO', 'DT', 'NN', 'IN', 'NNP', 'CD', ',', 'NN', 'TO', 'DT', 'NN', 'NN', '.']\n",
            "[' ', ' ', 'NNP', 'NNS', 'NN', 'VBD', 'NNP', 'NN', 'NN', 'NN', 'NN', 'NNS', 'NNP', 'TO', 'NN', '.']\n",
            "['DT', 'NNP', 'NN', 'NNP', 'NN', 'NN', 'DT', 'NN', 'TO', 'CD', 'CD', '.']\n",
            "['IN', 'NNP', ',', 'NNS', 'IN', 'JJ', 'NN', 'NNP', ',', 'NNP', 'NNP', 'CC', 'NN', 'NNP', ',', 'DT', 'NNS', 'TO', 'DT', 'NN', 'NN', 'NNP', ',', 'NN', 'NNP', 'TO', 'NNS', 'DT', 'NN', 'NN', 'NN', ',', 'DT', 'NNP', 'VBD', '.']\n",
            "[' ', 'IN', 'DT', 'NN', ',', 'DT', 'NNP', 'VBD', ',', 'IN', 'DT', 'JJ', 'IN', 'JJ', 'NNS', ',', 'IN', 'IN', 'DT', 'NN', 'TO', 'NN', '.']\n",
            "['DT', 'NNP', 'NN', 'DT', 'IN', 'NN', 'IN', 'CC', 'JJ', 'NNS', 'VBD', 'DT', 'JJ', 'NN', 'TO', 'NNS', '.']\n",
            "['IN', 'DT', 'NN', 'IN', 'NN', ',', 'IN', 'VBD', ',', 'DT', 'NN', 'NN', 'IN', 'NNS', 'IN', 'NN', 'IN', 'NN', 'IN', 'NNP', 'NNS', 'NN', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'IN', 'DT', '.', '.']\n",
            "['IN', 'NN', 'TO', 'DT', 'NN', 'IN', 'NN', ',', 'DT', 'NNP', 'NN', ',', 'VBD', 'DT', 'NN', 'IN', 'NNP', 'NN', 'NNS', ',', 'DT', 'NN', 'DT', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'VBZ', 'NN', 'IN', 'NN', 'CC', 'NN', 'DT', 'NN', 'IN', 'DT', 'DT', 'NN', 'NN', 'VB', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'TO', 'NN', 'NN', 'IN', 'IN', 'NN', 'NN', 'IN', 'NNS', 'CD', 'CD', 'NN', '.']\n",
            "['DT', 'NNP', 'NNP', 'NN', 'NNP', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'CD', 'NN', 'NNS', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', ',', 'IN', 'DT', 'NN', 'NN', 'CD', 'NN', 'CD', 'TO', 'NN', '.']\n",
            "['DT', 'NNP', 'NN', 'NN', 'DT', 'NN', 'DT', 'DT', 'NNP', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NN', 'NN', 'VB', 'IN', 'IN', 'DT', 'NN', 'NN', 'CD', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', 'IN', 'NNS', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNS', 'NNS', 'CC', 'NNP', 'NNP', 'NNS', 'NN', 'TO', 'VB', 'DT', 'NN', 'NN', 'TO', 'NNS', 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNS', '.']\n",
            "['DT', 'NNP', 'NN', 'VBZ', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NN', 'NN', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', 'DT', 'CD', 'NN', 'NN', 'IN', 'NN', 'NN', ',', 'IN', 'NN', 'NN', 'NN', 'NN', 'TO', 'NNS', 'NN', 'IN', 'NNP', 'CC', 'NN', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'NNP', 'CD', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'DT', 'NN', ',', 'NN', 'IN', 'DT', 'NN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'NN', 'DT', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'NN', 'NNS', 'IN', 'CD', 'CD', 'CD', 'IN', 'NN', 'NN', ',', 'IN', 'IN', 'NNS', 'IN', 'DT', 'NN', 'NN', 'CD', 'CD', 'CD', 'CD', '.']\n",
            "['IN', 'DT', 'NNP', 'NN', ',', 'NNP', 'IN', 'VBD', 'DT', '$', 'CD', 'CD', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "['NNS', 'NNP', 'CD', 'NN', 'TO', 'CD', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'JJ', 'NNS', 'IN', 'NN', 'IN', 'IN', 'NN', 'NN', 'JJ', 'NN', 'IN', 'NN', ',', 'IN', 'DT', 'NN', 'IN', 'NN', 'DT', 'NN', 'NN', 'IN', 'NN', 'CC', 'NN', '.']\n",
            "[' ', ',', 'NN', 'NN', 'NN', 'NN', 'CD', 'NN', ',', 'IN', 'NNP', 'NNP', 'NN', 'NNS', 'IN', 'DT', 'NN', 'CC', 'NNP', 'NNS', ',', 'NNS', 'NNS', 'IN', 'NNS', 'NN', '.']\n",
            "['IN', 'NNS', 'DT', 'NNS', 'TO', 'NNS', ',', 'RB', ',', 'DT', 'NN', 'NN', 'NNP', 'NN', 'NN', 'TO', 'NNS', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NNS', 'NN', 'DT', 'NN', 'NN', 'CC', 'NNS', 'NNS', '.']\n",
            "['NNP', 'NNP', ',', 'DT', 'NNP', 'IN', 'NNP', 'NNP', ',', 'VBD', 'DT', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'NN', 'IN', 'NN', 'NN', 'NN', ',', 'NN', 'NNP', 'NN', '.']\n",
            "[' ', ',', 'NNP', 'NNS', 'IN', 'IN', 'NNS', 'NNS', ',', 'CC', 'DT', 'NNS', 'NN', 'VBZ', 'IN', 'IN', 'NNS', 'JJ', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'NN', 'NN', 'CC', 'NNS', 'IN', 'DT', 'NN', 'NN', 'TO', 'DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'NNP', ',', 'NNP', ',', 'NN', ',', 'DT', 'VBZ', 'DT', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', '.']\n",
            "['IN', 'DT', 'NN', 'NN', ',', 'NN', 'NN', 'NN', 'CD', 'NN', 'TO', '$', 'CD', 'CD', '.']\n",
            "[' ', 'NN', 'NN', 'IN', 'NNP', 'NNS', 'CD', 'TO', 'IN', '$', 'CD', 'DT', 'NN', 'IN', 'CD', 'CD', 'DT', 'NN', 'IN', 'NN', 'CC', 'CD', 'CD', 'DT', 'NN', 'IN', 'DT', 'DT', 'NN', ',', 'NNS', 'VBD', '.']\n",
            "['RB', ',', 'NNP', 'NNS', 'RB', 'IN', 'NNS', 'JJ', 'NNS', ',', 'NN', 'IN', 'NN', 'NN', 'IN', 'NNP', 'NNS', 'IN', 'RB', 'NNP', 'NNP', 'NNP', ',', 'IN', 'NN', 'DT', 'CD', 'NN', 'NN', 'IN', 'NN', 'NN', ',', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'NN', 'NN', 'NN', 'CD', 'NN', '.']\n",
            "['IN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NN', 'NN', ',', 'NNP', 'NN', 'NNP', 'IN', 'CD', 'CD', ',', 'IN', 'CD', 'NN', ',', 'IN', 'DT', 'NN', 'NNS', 'NN', 'NN', 'IN', 'IN', 'NNS', 'VBD', 'VBD', 'RB', 'NN', 'IN', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', '.']\n",
            "['DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'IN', 'NNS', 'DT', 'NN', 'DT', 'NNP', 'NN', 'NNP', 'NN', 'NNS', 'NNS', 'IN', 'IN', 'NNS', 'NNS', 'NN', '.']\n",
            "['NNP', 'NNP', ',', 'DT', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'NNS', ',', 'VBD', 'NNP', 'IN', 'NNS', 'NN', 'NN', 'NN', 'IN', 'NNS', 'VBD', 'IN', 'NN', 'IN', 'NN', 'NNS', 'VBD', 'DT', 'NN', '.']\n",
            "['PRP', 'VBD', 'NNP', 'IN', 'NNP', 'TO', 'NNS', 'DT', 'NNS', 'NN', 'IN', 'NNP', 'NNS', ',', 'IN', 'IN', 'DT', 'NNS', 'NNS', 'NN', 'CC', 'NNS', 'NNS', 'NN', ',', 'IN', 'JJ', 'NNS', 'NNS', '.']\n",
            "['DT', 'NN', 'NN', ',', 'IN', 'DT', 'CD', 'NN', 'NN', 'IN', 'NN', 'NN', ',', 'DT', 'NN', 'DT', 'NN', 'NN', 'NN', '.']\n",
            "[' ', 'JJ', 'NN', 'NNS', 'NN', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NNP', 'NN', 'TO', '$', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['DT', 'NNP', 'NN', 'NNP', 'NN', 'NN', 'NN', 'TO', 'NNS', 'IN', 'DT', 'DT', ',', 'JJ', 'NNS', 'NNS', 'TO', 'CD', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "[' ', 'NNP', 'IN', 'NNP', 'NN', 'RB', 'VBD', 'JJ', 'NN', 'TO', 'NNS', 'NN', 'NN', 'NN', 'CC', 'NN', 'NNS', '.']\n",
            "[' ', 'IN', 'DT', 'NN', 'NNS', 'TO', 'RB', 'IN', 'TO', 'NNS', 'NN', 'CC', 'NNS', 'IN', 'NN', '.']\n",
            "['DT', 'NN', 'NN', 'DT', 'RB', 'VBZ', 'NN', 'NNS', 'IN', '$', 'CD', 'CD', 'IN', 'DT', 'NN', 'IN', 'NNP', 'CC', 'NNP', 'IN', 'IN', 'CD', 'CD', 'NN', 'IN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "[' ', 'VBZ', 'IN', 'CD', 'CD', 'CD', 'IN', 'NN', 'NNS', 'CC', 'CD', 'CD', 'NN', 'NN', '.']\n",
            "['DT', 'NNP', 'NN', 'IN', 'DT', 'NN', 'VBD', 'NN', 'IN', 'NN', 'NN', 'NN', 'NNP', 'NNP', 'VBD', 'NN', 'IN', 'NN', 'IN', 'NNP', 'TO', 'NN', 'NN', 'CC', 'NN', 'DT', 'NN', 'IN', 'NNS', 'NN', 'NN', '.']\n",
            "['NNP', ' ', 'VBZ', 'VBD', 'PRP', 'NN', 'NNP', 'TO', 'RB', 'NN', 'IN', 'RB', 'NN', 'IN', 'IN', 'NN', 'CC', 'NN', 'NNS', '.']\n",
            "[' ', 'IN', 'DT', 'CD', 'NNS', 'NN', 'CD', 'NN', 'TO', '$', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', ',', 'IN', 'CD', 'CD', 'CD', ',', 'IN', 'CD', 'CD', 'DT', 'NN', '.']\n",
            "['NNS', 'NNP', 'CD', 'NN', 'TO', '$', 'CD', 'CD', 'IN', 'CD', 'CD', 'CD', '.']\n",
            "['NNP', 'NNP', 'NNP', ',', 'CD', ',', 'NNP', 'NNP', 'NNP', 'NNP', 'CC', 'NNP', 'NN', 'NN', ',', 'VBD', 'NNP', 'NNP', 'CC', 'NNP', 'NN', 'NN', ',', 'NNS', 'IN', 'VBD', 'RB', 'NN', '.']\n",
            "['NNP', 'NNP', 'NN', ',', 'NNP', 'NNP', 'CC', 'NNP', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', ',', 'CC', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'NN', ',', 'IN', 'NNP', 'NN', ',', 'NN', 'NN', 'NN', 'TO', 'CD', '.']\n",
            "['NNP', 'NNP', 'NNP', ',', 'NNP', 'IN', 'NN', 'NN', 'NN', ',', 'VBD', 'NNP', 'TO', 'DT', 'NNS', 'NN', 'IN', 'NN', 'NNP', 'NNP', ',', 'NN', 'NNS', ',', 'IN', 'DT', 'NN', ',', 'NN', 'CC', 'NNP', 'NNS', 'NN', ',', 'NNP', 'NNP', 'NNP', 'NNP', ',', ',', 'IN', 'NNP', 'NNP', 'CC', 'NNP', 'NN', 'NN', 'IN', 'NNP', '.']\n",
            "['IN', 'NN', 'NNP', 'NNS', 'VBD', 'NNP', 'NNP', 'VBZ', 'RB', 'VB', 'DT', 'NN', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', ' ', 'IN', 'DT', 'NNP', 'IN', 'NNP', 'CC', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', 'NNP', 'VBD', 'DT', 'NN', 'IN', 'NNP', 'NNP', 'TO', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', 'VB', 'NN', 'DT', 'NN', 'IN', 'DT', 'NN', 'CC', 'DT', 'NN', 'IN', 'DT', 'NNS', ',', 'IN', 'IN', 'IN', 'DT', 'NN', 'IN', 'NN', 'NNS', '.']\n",
            "['DT', ' ', 'NN', 'DT', 'DT', 'NN', 'DT', 'VB', 'VB', 'DT', 'NN', 'TO', 'NN', 'DT', 'IN', 'DT', 'NN', 'NN', 'NN', 'NNP', 'IN', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', '.']\n",
            "['NNP', 'NNP', 'VBZ', 'VBD', 'PRP', 'VB', 'RB', 'TO', 'RB', 'VB', 'TO', 'VB', 'DT', 'NN', '.']\n",
            "['DT', 'NNP', 'NNP', 'VBD', 'VBD', 'IN', 'NN', 'DT', 'DT', 'NN', 'VBZ', 'NN', 'NN', 'DT', 'DT', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'NN', 'TO', 'VB', 'DT', 'NN', 'NN', '.']\n",
            "['RB', 'DT', 'JJ', 'NN', 'NNS', ',', 'NN', 'TO', 'DT', 'NN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', 'IN', 'DT', 'NN', 'NN', 'DT', 'DT', 'NN', '``', 'NN', 'DT', 'NN', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', '.', \"''\"]\n",
            "['DT', 'IN', 'NNS', 'NNS', 'NNS', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'NNP', 'NNP', 'DT', 'DT', 'NN', 'CC', 'NNP', 'NNP', 'VBZ', 'DT', 'NN', '.']\n",
            "['DT', 'IN', 'NNS', 'VBD', 'DT', 'NN', 'NN', 'DT', 'NNP', 'TO', 'NN', 'NN', 'NN', ',', 'RB', 'NN', 'NN', '.']\n",
            "[' ', ',', 'RB', 'VBD', 'DT', 'DT', 'NN', 'NNP', 'NN', 'CD', 'IN', 'NNP', 'NNS', 'NNS', 'NNS', 'NNS', ',', 'CC', 'IN', 'DT', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', '.']\n",
            "['RB', 'IN', 'VBD', 'DT', 'IN', 'IN', 'DT', 'NNS', 'NNS', 'NNS', 'DT', 'IN', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', ',', 'CC', '``', 'IN', 'RB', 'NN', 'DT', 'NN', 'DT', 'IN', 'NN', 'NN', 'VBZ', 'NN', 'DT', 'NN', \"''\", 'IN', 'DT', 'NNP', '.']\n",
            "['NNP', 'NNP', 'VBD', 'IN', 'DT', 'NN', 'NN', 'DT', 'IN', 'NN', 'NN', 'TO', 'NN', 'DT', 'NN', 'NN', 'NN', 'NN', ',', 'RB', 'DT', 'RB', 'VB', 'VB', 'DT', 'NN', 'NN', 'NN', 'IN', 'NN', \"''\", 'IN', 'NNP', 'NNP', 'TO', 'NN', 'DT', 'NN', 'JJ', 'NN', 'NN', '.']\n",
            "[' ', 'NNP', 'NNP', 'VBD', 'RB', 'NN', 'DT', 'NN', 'NN', 'TO', 'NNS', 'CD', 'NN', 'NNS', 'TO', 'NN', 'NN', 'NNP', 'IN', 'NNP', '.']\n",
            "[' ', 'IN', 'RB', 'NN', '.']\n",
            "['NNP', 'VBD', 'RB', 'NN', 'TO', 'NNS', 'NN', 'IN', 'DT', 'IN', 'NN', 'IN', 'NN', 'NN', '.']\n"
          ]
        }
      ],
      "source": [
        "# this is to check the output\n",
        "\n",
        "predictions = bidirect_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class indices\n",
        "predicted_label_indices = np.argmax(predictions, axis=-1)\n",
        "\n",
        "padding_token_index = 0\n",
        "\n",
        "# Now map indices to tags, ignoring padding tokens\n",
        "predicted_tags = []\n",
        "for sequence_idx, sequence in enumerate(predicted_label_indices):\n",
        "    sequence_tags = []\n",
        "    for token_idx, token_prediction in enumerate(sequence):\n",
        "        # Only add the tag if the corresponding token in X_test is not a padding token\n",
        "        if X_test[sequence_idx, token_idx] != padding_token_index:\n",
        "            sequence_tags.append(treebank_index_to_tag[token_prediction])\n",
        "    predicted_tags.append(sequence_tags)\n",
        "\n",
        "# Each element in predicted_tags is now a list of tag names corresponding to each non-padding token in each sequence\n",
        "for sequence in predicted_tags:\n",
        "    print(sequence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xUM8CVEiTDj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 600, 200)          2126400   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, 600, 128)          135680    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " additional_LSTM (LSTM)      (None, 600, 32)           20608     \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDi  (None, 600, 46)           1518      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2284206 (8.71 MB)\n",
            "Trainable params: 157806 (616.43 KB)\n",
            "Non-trainable params: 2126400 (8.11 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Copy the baseline_model\n",
        "model_1 = Sequential()\n",
        "model_1.add(Embedding(input_dim     = len(word_to_idx),\n",
        "                             output_dim    = embedding_dimension,\n",
        "                             input_length  = padding_length,\n",
        "                             weights       = [embedding_matrix],\n",
        "                             trainable     = False\n",
        "))\n",
        "model_1.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# Add one additional LSTM layer\n",
        "model_1.add(LSTM(32, return_sequences=True, name='additional_LSTM'))\n",
        "model_1.add(TimeDistributed(Dense(units=len(treebank_index_to_tag), activation='softmax')))\n",
        "\n",
        "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyENMQhGiTDj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "31/31 [==============================] - 22s 627ms/step - loss: 1.7724 - accuracy: 0.8989 - val_loss: 0.3468 - val_accuracy: 0.9611\n",
            "Epoch 2/2\n",
            "31/31 [==============================] - 19s 608ms/step - loss: 0.2456 - accuracy: 0.9614 - val_loss: 0.1963 - val_accuracy: 0.9634\n"
          ]
        }
      ],
      "source": [
        "model_1_training = model_1.fit(X_train, Y_train, batch_size=64, epochs=2, validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXMDML8iiTDj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 2s 81ms/step - loss: 0.1954 - accuracy: 0.9639\n"
          ]
        }
      ],
      "source": [
        "loss_1, accuracy_1 = model_1.evaluate(X_test, Y_test, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaTKPjUbiTDj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 600, 200)          2126400   \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, 600, 128)          135680    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " additional_Dense_layer (De  (None, 600, 64)           8256      \n",
            " nse)                                                            \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDi  (None, 600, 46)           2990      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2273326 (8.67 MB)\n",
            "Trainable params: 146926 (573.93 KB)\n",
            "Non-trainable params: 2126400 (8.11 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Embedding(input_dim     = len(word_to_idx),\n",
        "                             output_dim    = embedding_dimension,\n",
        "                             input_length  = padding_length,\n",
        "                             weights       = [embedding_matrix],\n",
        "                             trainable     = False\n",
        "))\n",
        "model_2.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# Add one additional dense layer\n",
        "model_2.add(Dense(64, activation='relu', name='additional_Dense_layer'))\n",
        "model_2.add(TimeDistributed(Dense(units=len(treebank_index_to_tag), activation='softmax')))\n",
        "\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md13gHHkiTDj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "31/31 [==============================] - 18s 505ms/step - loss: 1.3890 - accuracy: 0.9300 - val_loss: 0.1447 - val_accuracy: 0.9631\n",
            "Epoch 2/2\n",
            "31/31 [==============================] - 15s 491ms/step - loss: 0.1295 - accuracy: 0.9650 - val_loss: 0.1192 - val_accuracy: 0.9700\n"
          ]
        }
      ],
      "source": [
        "model_2_training = model_2.fit(X_train, Y_train, batch_size=64, epochs=2, validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdAzFrLqiTDj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 1s 61ms/step - loss: 0.1165 - accuracy: 0.9706\n"
          ]
        }
      ],
      "source": [
        "loss_2, accuracy_2 = model_2.evaluate(X_test, Y_test, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u-HNNUaiTDj"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'bidirect_training' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\università\\Magistrale\\NLP\\Assignement\\Assignment1NLP\\Assignment_1_Checkpoint_1.ipynb Cell 59\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/universit%C3%A0/Magistrale/NLP/Assignement/Assignment1NLP/Assignment_1_Checkpoint_1.ipynb#Y123sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# visualise training history\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/universit%C3%A0/Magistrale/NLP/Assignement/Assignment1NLP/Assignment_1_Checkpoint_1.ipynb#Y123sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(bidirect_training\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/universit%C3%A0/Magistrale/NLP/Assignement/Assignment1NLP/Assignment_1_Checkpoint_1.ipynb#Y123sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(bidirect_training\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/universit%C3%A0/Magistrale/NLP/Assignement/Assignment1NLP/Assignment_1_Checkpoint_1.ipynb#Y123sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mmodel accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'bidirect_training' is not defined"
          ]
        }
      ],
      "source": [
        "# visualise training history\n",
        "plt.plot(bidirect_training.history['accuracy'])\n",
        "plt.plot(bidirect_training.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE40VjJqiTDj"
      },
      "source": [
        "**Section 7:**\n",
        "\n",
        "Definition of the evaluation metrics for comparison."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

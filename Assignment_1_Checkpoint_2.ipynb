{"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7100610,"sourceType":"datasetVersion","datasetId":4093107}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Today\n- decide if we want to inspect sentences from training\n- for ovv remove from list of words in training and test also words from glove, other than the ones in training\n- can we split compound terms?","metadata":{"id":"ydPwziBqiTDB"}},{"cell_type":"markdown","source":"# Assignment 1\n\n**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n\n**Keywords**: POS tagging, Sequence labelling, RNNs","metadata":{"id":"oweJIGOAiTDF"}},{"cell_type":"markdown","source":"# [Task 1 - 0.5 points] Corpus\n\nYou are going to work with the [Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip).\n\n**Ignore** the numeric value in the third column, use **only** the words/symbols and their POS label.\n\n### Example\n\n```Pierre\tNNP\t2\nVinken\tNNP\t8\n,\t,\t2\n61\tCD\t5\nyears\tNNS\t6\nold\tJJ\t2\n,\t,\t2\nwill\tMD\t0\njoin\tVB\t8\nthe\tDT\t11\nboard\tNN\t9\nas\tIN\t9\na\tDT\t15\nnonexecutive\tJJ\t15\ndirector\tNN\t12\nNov.\tNNP\t9\n29\tCD\t16\n.\t.\t8\n```\n\n### Splits\n\nThe corpus contains 200 documents.\n\n   * **Train**: Documents 1-100\n   * **Validation**: Documents 101-150\n   * **Test**: Documents 151-199\n### Instructions\n\n* **Download** the corpus.\n* **Encode** the corpus into a pandas.DataFrame object.\n* **Split** it in training, validation, and test sets.","metadata":{"id":"UUQyJvmSiTDG"}},{"cell_type":"markdown","source":"# [Task 2 - 0.5 points] Text encoding\n\nTo train a neural POS tagger, you first need to encode text into numerical format.\n### Instructions\n\n* Embed words using **GloVe embeddings**.\n* You are **free** to pick any embedding dimension.\n* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**","metadata":{"id":"HbygS-f2iTDG"}},{"cell_type":"markdown","source":"# [Task 3 - 1.0 points] Model definition\n\nYou are now tasked to define your neural POS tagger.\n### Instructions\n\n* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n* You are **free** to experiment with hyper-parameters to define the baseline model.\n\n* **Model 1**: add an additional LSTM layer to the Baseline model.\n* **Model 2**: add an additional Dense layer to the Baseline model.\n\n* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n\n**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches.","metadata":{"id":"-xMAIuumiTDH"}},{"cell_type":"markdown","source":"# [Task 4 - 1.0 points] Metrics\n\nBefore training the models, you are tasked to define the evaluation metrics for comparison.\n\n### Instructions\n\n* Evaluate your models using macro F1-score, compute over **all** tokens.\n* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively)\n* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)\n\n**Note**: What about OOV tokens?\n   * All the tokens in the **training** set that are not in GloVe **must** be added to the vocabulary.\n   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **special token** (e.g., [UNK]) and a **static** embedding.\n   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)\n### More about OOV\n\nFor a given token:\n\n* **If in train set**: add to vocabulary and assign an embedding (use GloVe if token in GloVe, custom embedding otherwise).\n* **If in val/test set**: assign special token if not in vocabulary and assign custom embedding.\n\nYour vocabulary **should**:\n\n* Contain all tokens in train set; or\n* Union of tokens in train set and in GloVe $\\rightarrow$ we make use of existing knowledge!\n","metadata":{"id":"FEw9T5SPiTDH"}},{"cell_type":"markdown","source":"# [Task 5 - 1.0 points] Training and Evaluation\n\nYou are now tasked to train and evaluate the Baseline, Model 1, and Model 2.\n### Instructions\n\n* Train **all** models on the train set.\n* Evaluate **all** models on the validation set.\n* Compute metrics on the validation set.\n* Pick **at least** three seeds for robust estimation.\n* Pick the **best** performing model according to the observed validation set performance.","metadata":{"id":"QXpnk9Q1iTDH"}},{"cell_type":"markdown","source":"# [Task 6 - 1.0 points] Error Analysis\n\nYou are tasked to evaluate your best performing model.\n\n### Instructions\n\n* Compare the errors made on the validation and test sets.\n* Aggregate model errors into categories (if possible)\n* Comment the about errors and propose possible solutions on how to address them.","metadata":{"id":"I9bve1gSiTDI"}},{"cell_type":"markdown","source":"# [Task 7 - 1.0 points] Report\n\nWrap up your experiment in a short report (up to 2 pages).\n### Instructions\n\n* Use the NLP course report template.\n* Summarize each task in the report following the provided template.","metadata":{"id":"5nT-1UeoiTDJ"}},{"cell_type":"markdown","source":"### Recommendations\n\nThe report is not a copy-paste of graphs, tables, and command outputs.\n\n* Summarize classification performance in Table format.\n* **Do not** report command outputs or screenshots.\n* Report learning curves in Figure format.\n* The error analysis section should summarize your findings.","metadata":{"id":"TtOU9cDQiTDJ"}},{"cell_type":"markdown","source":"# FAQ\n\nPlease check this frequently asked questions before contacting us\n\n### Execution Order\n\nYou are **free** to address tasks in any order (if multiple orderings are available).\n\n### Trainable Embeddings\n\nYou are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings.\n\n### Model architecture\n\nYou **should not** change the architecture of a model (i.e., its layers).\n\nHowever, you are **free** to play with their hyper-parameters.\n\n### Neural Libraries\n\nYou are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)\n\n### Keras TimeDistributed Dense layer\n\nIf you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`.\n\n### Robust Evaluation\n\nEach model is trained with at least 3 random seeds.\n\nTask 4 requires you to compute the average performance over the 3 seeds and its corresponding standard deviation.\n\n### Model Selection for Analysis\n\nTo carry out the error analysis you are **free** to either\n\n* Pick examples or perform comparisons with an individual seed run model (e.g., Baseline seed 1337)\n* Perform ensembling via, for instance, majority voting to obtain a single model.\n\n### Error Analysis\n\nSome topics for discussion include:\n   * Model performance on most/less frequent classes.\n   * Precision/Recall curves.\n   * Confusion matrices.\n   * Specific misclassified samples.\n\n### Punctuation\n\n**Do not** remove punctuation from documents since it may be helpful to the model.\n\nYou should **ignore** it during metrics computation.\n\nIf you are curious, you can run additional experiments to verify the impact of removing punctuation.","metadata":{"id":"hpTvvXjgiTDJ"}},{"cell_type":"code","source":"import sys\nimport shutil\nimport urllib\nimport os\n\nimport zipfile\nfrom pathlib import Path\nimport requests\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom typing import Iterable, List, Callable, Dict\nfrom tqdm import tqdm\nimport random\nimport tensorflow as tf\nimport keras\n\n\n\nseed = 812\n\ntf.config.threading.set_inter_op_parallelism_threads(1)\ntf.config.threading.set_intra_op_parallelism_threads(1)\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\n\ntf.config.experimental.enable_op_determinism()\n# Set environment variable for TensorFlow\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\nos.environ['TF_CUDNN_DETERMINISTIC'] = '1'","metadata":{"id":"YlPAIyouiTDK","execution":{"iopub.status.busy":"2023-12-01T18:56:04.938760Z","iopub.execute_input":"2023-12-01T18:56:04.939167Z","iopub.status.idle":"2023-12-01T18:56:17.568402Z","shell.execute_reply.started":"2023-12-01T18:56:04.939138Z","shell.execute_reply":"2023-12-01T18:56:17.567530Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"glorot_normal_1 = keras.initializers.GlorotNormal(seed=seed)\nglorot_normal_2 = keras.initializers.GlorotNormal(seed=seed)\n\ninput_dim, neurons = 3, 5\n\n# Call two different objects with same shape\nresult_1 = glorot_normal_1(shape=(input_dim, neurons))\nresult_2 = glorot_normal_2(shape=(input_dim, neurons))\nprint(result_1)\nprint(result_2)\n# Check if the results are equal.\nequal = np.allclose(result_1, result_2)\nprint(f\"Are the results equal? {equal}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:56:17.570564Z","iopub.execute_input":"2023-12-01T18:56:17.571219Z","iopub.status.idle":"2023-12-01T18:56:17.680256Z","shell.execute_reply.started":"2023-12-01T18:56:17.571182Z","shell.execute_reply":"2023-12-01T18:56:17.679491Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[-0.6387855  -0.89870685  0.07983305  0.19414163 -0.76766497]\n [-0.38364235  0.4428017   0.6928357  -0.8514683   0.09465076]\n [ 0.21068816  0.3536609  -0.43506557 -1.0789914   0.34279203]], shape=(3, 5), dtype=float32)\ntf.Tensor(\n[[-0.6387855  -0.89870685  0.07983305  0.19414163 -0.76766497]\n [-0.38364235  0.4428017   0.6928357  -0.8514683   0.09465076]\n [ 0.21068816  0.3536609  -0.43506557 -1.0789914   0.34279203]], shape=(3, 5), dtype=float32)\nAre the results equal? True\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"8pJ4eaLciTDL","execution":{"iopub.status.busy":"2023-12-01T18:56:17.681338Z","iopub.execute_input":"2023-12-01T18:56:17.681901Z","iopub.status.idle":"2023-12-01T18:56:17.685934Z","shell.execute_reply.started":"2023-12-01T18:56:17.681871Z","shell.execute_reply":"2023-12-01T18:56:17.685149Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class DownloadProgressBar(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None:\n            self.total = tsize\n        self.update(b * bsize - self.n)\n\ndef download_dataset(download_path: Path, url: str):\n    response = requests.get(url)\n    with open(download_path, 'wb') as f:\n        f.write(response.content)\n\ndef download_url(download_path: Path, url: str):\n    print(\"Downloading dataset...\")\n    download_url(url=url, download_path=download_path)\n    print(\"Download complete!\")\n\ndef extract_dataset(download_path: Path, extract_path: Path):\n    print(\"Extracting dataset... (it may take a while...)\")\n    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_path)\n    print(\"Extraction completed!\")","metadata":{"id":"hF3goeVNiTDL","execution":{"iopub.status.busy":"2023-12-01T18:56:17.687415Z","iopub.execute_input":"2023-12-01T18:56:17.688158Z","iopub.status.idle":"2023-12-01T18:56:17.701513Z","shell.execute_reply.started":"2023-12-01T18:56:17.688114Z","shell.execute_reply":"2023-12-01T18:56:17.700624Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\ndataset_name = \"dependency_treebank\"\n\nprint(f\"Current work directory: {Path.cwd()}\")\ndataset_folder = Path.cwd().joinpath(\"Datasets\")\n\nif not dataset_folder.exists():\n    dataset_folder.mkdir(parents=True)\n\ndataset_zip_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\ndataset_path = dataset_folder.joinpath(dataset_name)\n\nif not dataset_zip_path.exists():\n    download_dataset(dataset_zip_path, url)\n\nif not dataset_path.exists():\n    extract_dataset(dataset_zip_path, dataset_folder)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMnZiRO2iTDL","outputId":"d24ece9e-0d08-460f-951a-6ae19f69c579","execution":{"iopub.status.busy":"2023-12-01T18:56:17.704004Z","iopub.execute_input":"2023-12-01T18:56:17.704913Z","iopub.status.idle":"2023-12-01T18:56:17.929359Z","shell.execute_reply.started":"2023-12-01T18:56:17.704878Z","shell.execute_reply":"2023-12-01T18:56:17.928626Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Current work directory: /kaggle/working\nExtracting dataset... (it may take a while...)\nExtraction completed!\n","output_type":"stream"}]},{"cell_type":"code","source":"folder = dataset_folder.joinpath(dataset_name)\nfolder","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nF-Vs1HPiTDM","outputId":"2bb0834e-95e2-4b5b-dcad-4ac854ac111e","execution":{"iopub.status.busy":"2023-12-01T18:56:17.930576Z","iopub.execute_input":"2023-12-01T18:56:17.931431Z","iopub.status.idle":"2023-12-01T18:56:17.939576Z","shell.execute_reply.started":"2023-12-01T18:56:17.931388Z","shell.execute_reply":"2023-12-01T18:56:17.938418Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"PosixPath('/kaggle/working/Datasets/dependency_treebank')"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize an empty list to store the data rows\ndataframe_rows = []\nindex = 0\ntag_set = set([])\n# Iterate through the files in the directory with the '.dp' extension\nfor file_path in folder.glob('*.dp'):\n#file_path = folder.joinpath('wsj_0001.dp')\n    with file_path.open(mode='r', encoding='utf-8') as text_file:\n        index+=1\n        sentence =  '' # word1 + word2\n        tag = []\n        lines = text_file.readlines()\n        # Split the line by whitespace to separate columns\n        for line in lines:\n            line_parts = line.split('\\t')\n            if len(line_parts) == 1: #case '\\n'\n                dataframe_row = {\n                    \"sentence\": sentence,\n                    \"POS\": tag,\n                    \"index\": index,\n                    \"split\": 'train' if index <=100 else  'validation' if index<=150 else 'test'\n                }\n                dataframe_rows.append(dataframe_row)\n                sentence =  ''\n                tag = []\n            else:\n                sentence += line_parts[0] + \" \"\n                tag.append(line_parts[1])\n                tag_set.add(line_parts[1])\n        # Last sentence\n        dataframe_row = {\n                    \"sentence\": sentence,\n                    \"POS\": tag,\n                    \"index\": index,\n                    \"split\": 'train' if index <=100 else  'validation' if index<=150 else 'test'\n                }\n        dataframe_rows.append(dataframe_row)\n# Create a Pandas DataFrame\ndf = pd.DataFrame(dataframe_rows)\ndf.to_pickle(folder.with_name(dataset_name + \".pkl\"))","metadata":{"id":"7roXidYqiTDM","execution":{"iopub.status.busy":"2023-12-01T18:56:17.940827Z","iopub.execute_input":"2023-12-01T18:56:17.941112Z","iopub.status.idle":"2023-12-01T18:56:18.123427Z","shell.execute_reply.started":"2023-12-01T18:56:17.941088Z","shell.execute_reply":"2023-12-01T18:56:18.122197Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Initialize an empty list to store the data rows\ndataframe_rows = []\n# Iterate through the files in the directory with the '.dp' extension\nfor file_path in folder.glob('*.dp'):\n#file_path = folder.joinpath('wsj_0001.dp')\n    file_sentences =  [] # word1 + word2\n    tag = []\n    with file_path.open(mode='r', encoding='utf-8') as text_file:\n        lines = text_file.readlines()\n        # Split the line by whitespace to separate columns\n        for line in lines:\n            line_parts = line.split('\\t')\n            if len(line_parts) != 1: #case '\\n'\n                file_sentences.append(line_parts[0])\n                tag.append(line_parts[1])\n        # Last sentence\n        dataframe_row = {\n                    \"sentence\": file_sentences,\n                    \"POS\": tag,\n                }\n        dataframe_rows.append(dataframe_row)\n# Create a Pandas DataFrame\ndf_file = pd.DataFrame(dataframe_rows)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:56:18.126533Z","iopub.execute_input":"2023-12-01T18:56:18.127002Z","iopub.status.idle":"2023-12-01T18:56:18.235194Z","shell.execute_reply.started":"2023-12-01T18:56:18.126960Z","shell.execute_reply":"2023-12-01T18:56:18.233937Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_file","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:56:18.236828Z","iopub.execute_input":"2023-12-01T18:56:18.237534Z","iopub.status.idle":"2023-12-01T18:56:18.288442Z","shell.execute_reply.started":"2023-12-01T18:56:18.237493Z","shell.execute_reply":"2023-12-01T18:56:18.287339Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                              sentence  \\\n0    [Travelers, Corp., 's, third-quarter, net, inc...   \n1    [Tony, Lama, Co., said, that, Equus, Investmen...   \n2    [The, U.S., and, Soviet, Union, are, holding, ...   \n3    [INTER-TEL, Inc, ., -LRB-, Chandler, ,, Ariz.,...   \n4    [ORTEGA, ENDED, a, truce, with, the, Contras, ...   \n..                                                 ...   \n194  [John, F., Barrett, ,, 40, ,, formerly, execut...   \n195  [A, man, from, the, Bush, administration, came...   \n196  [Bank, of, New, England, Corp., said, it, has,...   \n197  [Meridian, National, Corp., said, it, sold, 75...   \n198  [Since, chalk, first, touched, slate, ,, schoo...   \n\n                                                   POS  \n0    [NNPS, NNP, POS, NN, NN, NN, VBD, CD, NN, ,, R...  \n1    [NNP, NNP, NNP, VBD, IN, NNP, NNP, NNP, NNP, N...  \n2    [DT, NNP, CC, NNP, NNP, VBP, VBG, JJ, NNS, IN,...  \n3    [NNP, NNP, ., -LRB-, NNP, ,, NNP, -RRB-, :, NN...  \n4    [NNP, VBD, DT, NN, IN, DT, NNPS, CC, VBD, NNS,...  \n..                                                 ...  \n194  [NNP, NNP, NNP, ,, CD, ,, RB, JJ, NN, NN, CC, ...  \n195  [DT, NN, IN, DT, NNP, NN, VBD, IN, DT, NNP, NN...  \n196  [NNP, IN, NNP, NNP, NNP, VBD, PRP, VBZ, VBN, N...  \n197  [NNP, NNP, NNP, VBD, PRP, VBD, CD, NNS, IN, PR...  \n198  [IN, NN, RB, VBD, NN, ,, NN, VBP, VBN, TO, VB,...  \n\n[199 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>POS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Travelers, Corp., 's, third-quarter, net, inc...</td>\n      <td>[NNPS, NNP, POS, NN, NN, NN, VBD, CD, NN, ,, R...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[Tony, Lama, Co., said, that, Equus, Investmen...</td>\n      <td>[NNP, NNP, NNP, VBD, IN, NNP, NNP, NNP, NNP, N...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[The, U.S., and, Soviet, Union, are, holding, ...</td>\n      <td>[DT, NNP, CC, NNP, NNP, VBP, VBG, JJ, NNS, IN,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[INTER-TEL, Inc, ., -LRB-, Chandler, ,, Ariz.,...</td>\n      <td>[NNP, NNP, ., -LRB-, NNP, ,, NNP, -RRB-, :, NN...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[ORTEGA, ENDED, a, truce, with, the, Contras, ...</td>\n      <td>[NNP, VBD, DT, NN, IN, DT, NNPS, CC, VBD, NNS,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>[John, F., Barrett, ,, 40, ,, formerly, execut...</td>\n      <td>[NNP, NNP, NNP, ,, CD, ,, RB, JJ, NN, NN, CC, ...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>[A, man, from, the, Bush, administration, came...</td>\n      <td>[DT, NN, IN, DT, NNP, NN, VBD, IN, DT, NNP, NN...</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>[Bank, of, New, England, Corp., said, it, has,...</td>\n      <td>[NNP, IN, NNP, NNP, NNP, VBD, PRP, VBZ, VBN, N...</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>[Meridian, National, Corp., said, it, sold, 75...</td>\n      <td>[NNP, NNP, NNP, VBD, PRP, VBD, CD, NNS, IN, PR...</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>[Since, chalk, first, touched, slate, ,, schoo...</td>\n      <td>[IN, NN, RB, VBD, NN, ,, NN, VBP, VBN, TO, VB,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>199 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"kMWpUXp3iTDN","outputId":"f5482db0-479c-4247-b21f-54c0e2013d75","execution":{"iopub.status.busy":"2023-12-01T18:56:18.290057Z","iopub.execute_input":"2023-12-01T18:56:18.290738Z","iopub.status.idle":"2023-12-01T18:56:18.313220Z","shell.execute_reply.started":"2023-12-01T18:56:18.290697Z","shell.execute_reply":"2023-12-01T18:56:18.312155Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                               sentence  \\\n0     Travelers Corp. 's third-quarter net income ro...   \n1     Net advanced to $ 94.2 million , or 89 cents a...   \n2     But revenue declined to $ 3 billion from $ 3.2...   \n3     Travelers estimated that the California earthq...   \n4     The insurer 's earnings from commercial proper...   \n...                                                 ...   \n3909  When Scoring High first came out in 1979 , it ...   \n3910                        McGraw-Hill was outraged .    \n3911  In a 1985 advisory to educators , McGraw-Hill ...   \n3912  But in 1988 , McGraw-Hill purchased the Random...   \n3913  Messrs. Brownell and Kean say they are unaware...   \n\n                                                    POS  index  split  \n0     [NNPS, NNP, POS, NN, NN, NN, VBD, CD, NN, ,, R...      1  train  \n1     [NN, VBD, TO, $, CD, CD, ,, CC, CD, NNS, DT, N...      1  train  \n2        [CC, NN, VBD, TO, $, CD, CD, IN, $, CD, CD, .]      1  train  \n3     [NNPS, VBD, IN, DT, NNP, NN, JJ, NN, MD, VB, I...      1  train  \n4     [DT, NN, POS, NNS, IN, JJ, NN, NNS, VBD, CD, N...      1  train  \n...                                                 ...    ...    ...  \n3909  [WRB, NNP, NNP, RB, VBD, RB, IN, CD, ,, PRP, V...    199   test  \n3910                                  [NNP, VBD, JJ, .]    199   test  \n3911  [IN, DT, CD, NN, TO, NNS, ,, NNP, VBD, NNP, NN...    199   test  \n3912  [CC, IN, CD, ,, NNP, VBD, DT, NNP, NNP, NN, WD...    199   test  \n3913  [NNPS, NNP, CC, NNP, VBP, PRP, VBP, JJ, IN, DT...    199   test  \n\n[3914 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>POS</th>\n      <th>index</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Travelers Corp. 's third-quarter net income ro...</td>\n      <td>[NNPS, NNP, POS, NN, NN, NN, VBD, CD, NN, ,, R...</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Net advanced to $ 94.2 million , or 89 cents a...</td>\n      <td>[NN, VBD, TO, $, CD, CD, ,, CC, CD, NNS, DT, N...</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>But revenue declined to $ 3 billion from $ 3.2...</td>\n      <td>[CC, NN, VBD, TO, $, CD, CD, IN, $, CD, CD, .]</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Travelers estimated that the California earthq...</td>\n      <td>[NNPS, VBD, IN, DT, NNP, NN, JJ, NN, MD, VB, I...</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The insurer 's earnings from commercial proper...</td>\n      <td>[DT, NN, POS, NNS, IN, JJ, NN, NNS, VBD, CD, N...</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>When Scoring High first came out in 1979 , it ...</td>\n      <td>[WRB, NNP, NNP, RB, VBD, RB, IN, CD, ,, PRP, V...</td>\n      <td>199</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>McGraw-Hill was outraged .</td>\n      <td>[NNP, VBD, JJ, .]</td>\n      <td>199</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>3911</th>\n      <td>In a 1985 advisory to educators , McGraw-Hill ...</td>\n      <td>[IN, DT, CD, NN, TO, NNS, ,, NNP, VBD, NNP, NN...</td>\n      <td>199</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>3912</th>\n      <td>But in 1988 , McGraw-Hill purchased the Random...</td>\n      <td>[CC, IN, CD, ,, NNP, VBD, DT, NNP, NNP, NN, WD...</td>\n      <td>199</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>3913</th>\n      <td>Messrs. Brownell and Kean say they are unaware...</td>\n      <td>[NNPS, NNP, CC, NNP, VBP, PRP, VBP, JJ, IN, DT...</td>\n      <td>199</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>3914 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#test for same lengths in sentences and POS\ndifferent_length = [1 if len(input.split()) != len(output) else 0 for input, output in zip(df['sentence'].values, df['POS'])]\nprint(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"306npgAkiTDN","outputId":"87bb4519-5ec7-488f-8b41-47cb3d0ae5a5","execution":{"iopub.status.busy":"2023-12-01T18:56:18.314712Z","iopub.execute_input":"2023-12-01T18:56:18.315215Z","iopub.status.idle":"2023-12-01T18:56:18.331161Z","shell.execute_reply.started":"2023-12-01T18:56:18.315177Z","shell.execute_reply":"2023-12-01T18:56:18.330001Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"0 sentences have disparate input-output lengths.\n","output_type":"stream"}]},{"cell_type":"code","source":"#dictionaries with all the tags in the corpus\ntreebank_index_to_tag = {}\ntreebank_tag_to_index = {}\nindex = 1\nfor tag in tag_set:\n    treebank_index_to_tag[index] = tag\n    treebank_tag_to_index[tag] = index\n    index+=1\nprint(treebank_index_to_tag)\nprint(treebank_tag_to_index)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qeksn63yiTDO","outputId":"c3902039-0462-418d-ff42-69c119fbf138","execution":{"iopub.status.busy":"2023-12-01T18:56:18.332503Z","iopub.execute_input":"2023-12-01T18:56:18.333053Z","iopub.status.idle":"2023-12-01T18:56:18.347018Z","shell.execute_reply.started":"2023-12-01T18:56:18.333022Z","shell.execute_reply":"2023-12-01T18:56:18.345813Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{1: \"''\", 2: 'CC', 3: 'WDT', 4: 'LS', 5: '-RRB-', 6: 'VBN', 7: 'PRP', 8: 'RP', 9: 'CD', 10: 'FW', 11: 'TO', 12: ':', 13: 'VBZ', 14: 'PRP$', 15: 'MD', 16: 'JJS', 17: '$', 18: '``', 19: '.', 20: 'NN', 21: 'SYM', 22: 'POS', 23: 'NNP', 24: 'VB', 25: 'NNS', 26: 'WRB', 27: 'VBD', 28: 'JJR', 29: 'VBP', 30: '#', 31: 'RB', 32: '-LRB-', 33: 'RBR', 34: 'VBG', 35: 'UH', 36: 'NNPS', 37: 'EX', 38: 'IN', 39: 'WP', 40: 'PDT', 41: 'WP$', 42: ',', 43: 'JJ', 44: 'RBS', 45: 'DT'}\n{\"''\": 1, 'CC': 2, 'WDT': 3, 'LS': 4, '-RRB-': 5, 'VBN': 6, 'PRP': 7, 'RP': 8, 'CD': 9, 'FW': 10, 'TO': 11, ':': 12, 'VBZ': 13, 'PRP$': 14, 'MD': 15, 'JJS': 16, '$': 17, '``': 18, '.': 19, 'NN': 20, 'SYM': 21, 'POS': 22, 'NNP': 23, 'VB': 24, 'NNS': 25, 'WRB': 26, 'VBD': 27, 'JJR': 28, 'VBP': 29, '#': 30, 'RB': 31, '-LRB-': 32, 'RBR': 33, 'VBG': 34, 'UH': 35, 'NNPS': 36, 'EX': 37, 'IN': 38, 'WP': 39, 'PDT': 40, 'WP$': 41, ',': 42, 'JJ': 43, 'RBS': 44, 'DT': 45}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Section 2:**\n\nText pre-processing, Lemmatization, (Stemming ?)","metadata":{"id":"bd_19p33iTDO"}},{"cell_type":"code","source":"from functools import reduce\nfrom nltk.corpus import stopwords\n\ndef lower(text: str) -> str:\n    return text.lower() # lower casing words\n\nPREPROCESSING_PIPELINE = [\n                          lower\n                        ]\n\ndef text_prepare(text: str,\n                 filter_methods: List[Callable[[str], str]] = None) -> str:\n    \"\"\"\n    Applies a list of pre-processing functions in sequence (reduce).\n    Note that the order is important here!\n    \"\"\"\n    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n    return reduce(lambda txt, f: f(txt), filter_methods, text)","metadata":{"id":"uV-CnbxniTDO","execution":{"iopub.status.busy":"2023-12-01T18:56:18.348726Z","iopub.execute_input":"2023-12-01T18:56:18.349472Z","iopub.status.idle":"2023-12-01T18:56:18.372235Z","shell.execute_reply.started":"2023-12-01T18:56:18.349433Z","shell.execute_reply":"2023-12-01T18:56:18.370958Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(f'[Debug] Before:\\n{df.sentence.values[50]}')\ndf['sentence'] = df['sentence'].apply(lambda txt: text_prepare(txt))\nprint(f'[Debug] After:\\n{df.sentence.values[50]}')\n#maybe convert also POS into lower case","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GdbYruDniTDP","outputId":"1f37f712-1c4b-437a-dfa6-379718a9b62c","execution":{"iopub.status.busy":"2023-12-01T18:56:18.378352Z","iopub.execute_input":"2023-12-01T18:56:18.379166Z","iopub.status.idle":"2023-12-01T18:56:18.409872Z","shell.execute_reply.started":"2023-12-01T18:56:18.379123Z","shell.execute_reply":"2023-12-01T18:56:18.408643Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[Debug] Before:\nGunmen in Lebanon assassinated a Saudi Arabian Embassy employee , and the pro-Iranian Islamic Jihad took responsibility for the slaying to avenge the beheading of 16 terrorists by Riyadh 's government in September . \n[Debug] After:\ngunmen in lebanon assassinated a saudi arabian embassy employee , and the pro-iranian islamic jihad took responsibility for the slaying to avenge the beheading of 16 terrorists by riyadh 's government in september . \n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import OrderedDict\ndef build_vocabulary(df: pd.DataFrame) -> (Dict[int, str],\n                                           Dict[str, int],\n                                           List[str]): # builds the vocabulary of the dataset\n\n    idx_to_word = OrderedDict() # vocabulary index to word map\n    word_to_idx = OrderedDict() # word to vocabulary index map (inverse of idx_to_word)\n\n    curr_idx = 0\n    for sentence in tqdm(df.sentence.values):\n        tokens = sentence.split()\n        for token in tokens:\n            if token not in word_to_idx:\n                word_to_idx[token] = curr_idx\n                idx_to_word[curr_idx] = token\n                curr_idx += 1\n\n    word_listing = list(idx_to_word.values()) # set of unique terms that make up the vocabulary\n    return idx_to_word, word_to_idx, word_listing","metadata":{"id":"jqRSShmYiTDa","execution":{"iopub.status.busy":"2023-12-01T18:56:18.411055Z","iopub.execute_input":"2023-12-01T18:56:18.412068Z","iopub.status.idle":"2023-12-01T18:56:18.418253Z","shell.execute_reply.started":"2023-12-01T18:56:18.412035Z","shell.execute_reply":"2023-12-01T18:56:18.417265Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"idx_to_word_corpus, word_to_idx_corpus, word_listing_corpus = build_vocabulary(df)\nprint(f'[Debug] Index -> Word vocabulary size: {len(idx_to_word_corpus)}')\nprint(f'[Debug] Word -> Index vocabulary size: {len(word_to_idx_corpus)}')\nprint(f'[Debug] Some words: {[(idx_to_word_corpus[idx], idx) for idx in np.arange(10) + 1]}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGifYYXqiTDa","outputId":"0b020406-8027-4b09-f6e3-c141e6d38c3c","execution":{"iopub.status.busy":"2023-12-01T18:56:18.419646Z","iopub.execute_input":"2023-12-01T18:56:18.420182Z","iopub.status.idle":"2023-12-01T18:56:18.468775Z","shell.execute_reply.started":"2023-12-01T18:56:18.420153Z","shell.execute_reply":"2023-12-01T18:56:18.467830Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 3914/3914 [00:00<00:00, 164301.43it/s]","output_type":"stream"},{"name":"stdout","text":"[Debug] Index -> Word vocabulary size: 10947\n[Debug] Word -> Index vocabulary size: 10947\n[Debug] Some words: [('corp.', 1), (\"'s\", 2), ('third-quarter', 3), ('net', 4), ('income', 5), ('rose', 6), ('11', 7), ('%', 8), (',', 9), ('even', 10)]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"idx_to_word_train, word_to_idx_train, word_listing_train = build_vocabulary(df[df['split']=='train'])\nprint(f'[Debug] Index -> Word vocabulary size: {len(idx_to_word_train)}')\nprint(f'[Debug] Word -> Index vocabulary size: {len(word_to_idx_train)}')\nprint(f'[Debug] Some words in training: {[(idx_to_word_train[idx], idx) for idx in np.arange(10) + 1]}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdPkt5n4iTDb","outputId":"b098d525-6381-4488-f4a0-d0847fb41df0","execution":{"iopub.status.busy":"2023-12-01T18:56:18.470204Z","iopub.execute_input":"2023-12-01T18:56:18.470844Z","iopub.status.idle":"2023-12-01T18:56:18.503075Z","shell.execute_reply.started":"2023-12-01T18:56:18.470806Z","shell.execute_reply":"2023-12-01T18:56:18.502108Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"100%|██████████| 2143/2143 [00:00<00:00, 125497.66it/s]","output_type":"stream"},{"name":"stdout","text":"[Debug] Index -> Word vocabulary size: 7621\n[Debug] Word -> Index vocabulary size: 7621\n[Debug] Some words in training: [('corp.', 1), (\"'s\", 2), ('third-quarter', 3), ('net', 4), ('income', 5), ('rose', 6), ('11', 7), ('%', 8), (',', 9), ('even', 10)]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"_, _, word_listing_val_and_test = build_vocabulary(df[df['split']!='train'])\nprint(f'[Debug] vocabulary size validation and test: {len(word_listing_val_and_test)}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jin2AmXSiTDb","outputId":"e1d651fe-b3b1-4009-9336-ecff14477a08","execution":{"iopub.status.busy":"2023-12-01T18:56:18.504500Z","iopub.execute_input":"2023-12-01T18:56:18.505117Z","iopub.status.idle":"2023-12-01T18:56:18.535703Z","shell.execute_reply.started":"2023-12-01T18:56:18.505081Z","shell.execute_reply":"2023-12-01T18:56:18.534663Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 1771/1771 [00:00<00:00, 95020.24it/s]","output_type":"stream"},{"name":"stdout","text":"[Debug] vocabulary size validation and test: 6781\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"words_in_train_set = set(word_listing_train)\nwords_in_val_and_test_set = set(word_listing_val_and_test)\noov = set(words_in_val_and_test_set).difference(words_in_train_set)\nprint('words in training set:',len(words_in_train_set))\nprint('words in validation and test set:',len(words_in_val_and_test_set))\nprint('words not present in training set:',len(oov))\nprint('size vocabulary of corpus', len(word_listing_corpus))\nprint('size vocabulary of corpus', len(words_in_train_set)+len(oov))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iWEUNCppiTDb","outputId":"94b3187f-9935-41cb-900e-5043f2eedf33","execution":{"iopub.status.busy":"2023-12-01T18:56:18.537269Z","iopub.execute_input":"2023-12-01T18:56:18.537936Z","iopub.status.idle":"2023-12-01T18:56:18.549785Z","shell.execute_reply.started":"2023-12-01T18:56:18.537896Z","shell.execute_reply":"2023-12-01T18:56:18.548678Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"words in training set: 7621\nwords in validation and test set: 6781\nwords not present in training set: 3326\nsize vocabulary of corpus 10947\nsize vocabulary of corpus 10947\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check size, content, consistency and toy example\ndef evaluate_vocabulary(idx_to_word: Dict[int, str], word_to_idx: Dict[str, int],\n                        word_listing: List[str], df: pd.DataFrame, check_default_size: bool = False):\n    print(\"[Vocabulary Evaluation] Size checking...\")\n    assert len(idx_to_word) == len(word_to_idx)\n    assert len(idx_to_word) == len(word_listing)\n\n    print(\"[Vocabulary Evaluation] Content checking...\")\n    for i in tqdm(range(0, len(idx_to_word))):\n        assert idx_to_word[i] in word_to_idx\n        assert word_to_idx[idx_to_word[i]] == i\n\n    print(\"[Vocabulary Evaluation] Consistency checking...\")\n    _, _, first_word_listing = build_vocabulary(df)\n    _, _, second_word_listing = build_vocabulary(df)\n    assert first_word_listing == second_word_listing\n\n    print(\"[Vocabulary Evaluation] Toy example checking...\")\n    toy_df = pd.DataFrame.from_dict({\n        'sentence': [\"all that glitters is not gold\", \"all in all i like this assignment\"]\n    })\n    _, _, toy_word_listing = build_vocabulary(toy_df)\n    toy_valid_vocabulary = set(' '.join(toy_df.sentence.values).split())\n    assert set(toy_word_listing) == toy_valid_vocabulary","metadata":{"id":"oc5CmPiJiTDc","execution":{"iopub.status.busy":"2023-12-01T18:56:18.551724Z","iopub.execute_input":"2023-12-01T18:56:18.552684Z","iopub.status.idle":"2023-12-01T18:56:18.562216Z","shell.execute_reply.started":"2023-12-01T18:56:18.552642Z","shell.execute_reply":"2023-12-01T18:56:18.561460Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(\"Vocabulary evaluation...\")\nevaluate_vocabulary(idx_to_word_corpus, word_to_idx_corpus, word_listing_corpus, df)\nprint(\"Evaluation completed!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7DLPCcuiTDc","outputId":"281d164e-ea2b-4c3c-aab8-5e0fda2d19d0","execution":{"iopub.status.busy":"2023-12-01T18:56:18.563897Z","iopub.execute_input":"2023-12-01T18:56:18.564687Z","iopub.status.idle":"2023-12-01T18:56:18.672351Z","shell.execute_reply.started":"2023-12-01T18:56:18.564646Z","shell.execute_reply":"2023-12-01T18:56:18.671314Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Vocabulary evaluation...\n[Vocabulary Evaluation] Size checking...\n[Vocabulary Evaluation] Content checking...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10947/10947 [00:00<00:00, 1334274.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Vocabulary Evaluation] Consistency checking...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3914/3914 [00:00<00:00, 126795.80it/s]\n100%|██████████| 3914/3914 [00:00<00:00, 153136.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Vocabulary Evaluation] Toy example checking...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2/2 [00:00<00:00, 7294.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Evaluation completed!\n","output_type":"stream"}]},{"cell_type":"code","source":"import gensim\nimport gensim.downloader as gloader\n\ndef load_embedding_model(embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:  #50,100,200\n    download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n    try:\n        emb_model = gloader.load(download_path)\n    except ValueError as e:\n        print(\"Glove: 50, 100, 200, 300\")\n        raise e\n    return emb_model","metadata":{"id":"Ac4ZxCZViTDd","execution":{"iopub.status.busy":"2023-12-01T18:56:18.673711Z","iopub.execute_input":"2023-12-01T18:56:18.674731Z","iopub.status.idle":"2023-12-01T18:56:39.381029Z","shell.execute_reply.started":"2023-12-01T18:56:18.674689Z","shell.execute_reply":"2023-12-01T18:56:39.380095Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"embedding_model_50 = load_embedding_model(embedding_dimension=50)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZX-SmHviTDd","outputId":"26bf9850-97cc-4817-8785-1509899ae9f0","execution":{"iopub.status.busy":"2023-12-01T18:56:39.382321Z","iopub.execute_input":"2023-12-01T18:56:39.382668Z","iopub.status.idle":"2023-12-01T18:57:06.157648Z","shell.execute_reply.started":"2023-12-01T18:56:39.382637Z","shell.execute_reply":"2023-12-01T18:57:06.155963Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[==================================================] 100.0% 66.0/66.0MB downloaded\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_model_100 = load_embedding_model(embedding_dimension=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:57:06.160608Z","iopub.execute_input":"2023-12-01T18:57:06.161754Z","iopub.status.idle":"2023-12-01T18:57:53.885924Z","shell.execute_reply.started":"2023-12-01T18:57:06.161704Z","shell.execute_reply":"2023-12-01T18:57:53.884863Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[==================================================] 100.0% 128.1/128.1MB downloaded\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_model_200 = load_embedding_model(embedding_dimension=200)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:57:53.887435Z","iopub.execute_input":"2023-12-01T18:57:53.888136Z","iopub.status.idle":"2023-12-01T18:59:23.665136Z","shell.execute_reply.started":"2023-12-01T18:57:53.888101Z","shell.execute_reply":"2023-12-01T18:59:23.664061Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[==================================================] 100.0% 252.1/252.1MB downloaded\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_model_300 = load_embedding_model(embedding_dimension=300)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T18:59:23.666421Z","iopub.execute_input":"2023-12-01T18:59:23.666780Z","iopub.status.idle":"2023-12-01T19:01:37.705361Z","shell.execute_reply.started":"2023-12-01T18:59:23.666749Z","shell.execute_reply":"2023-12-01T19:01:37.704081Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[=================================================-] 100.0% 375.9/376.1MB downloaded\n","output_type":"stream"}]},{"cell_type":"code","source":"def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n                    word_listing: List[str]):\n    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n    oov = set(word_listing).difference(embedding_vocabulary)\n    return list(oov)","metadata":{"id":"jHDwlyOCiTDd","execution":{"iopub.status.busy":"2023-12-01T19:01:37.707080Z","iopub.execute_input":"2023-12-01T19:01:37.707529Z","iopub.status.idle":"2023-12-01T19:01:37.715697Z","shell.execute_reply.started":"2023-12-01T19:01:37.707485Z","shell.execute_reply":"2023-12-01T19:01:37.714870Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# this should be the number of oov from val and test\nembedding_vocabulary = set(embedding_model_50.key_to_index.keys())\noov_terms = oov.difference(embedding_vocabulary) #words that appear only in val and test\noov_percentage = float(len(oov_terms)) * 100 / len(word_listing_val_and_test)\nprint(f\"Total OOV terms: {len(oov_terms)} ({oov_percentage:.2f}%)\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6DY8SBQViTDe","outputId":"a4444106-dd94-494a-a177-c379fe406279","execution":{"iopub.status.busy":"2023-12-01T19:01:37.717031Z","iopub.execute_input":"2023-12-01T19:01:37.717331Z","iopub.status.idle":"2023-12-01T19:01:37.780617Z","shell.execute_reply.started":"2023-12-01T19:01:37.717300Z","shell.execute_reply":"2023-12-01T19:01:37.779363Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Total OOV terms: 292 (4.31%)\n","output_type":"stream"}]},{"cell_type":"code","source":"# dictionary for oov to use for static embedding\nindex = 0 #1+len(oov_terms) #here we used word_listing_train instead of oov_terms to start from the last index of the vocabulary\noov_to_index_dict = {}\nindex_to_oov_dict = {}\nfor oov in oov_terms:\n    oov_to_index_dict[oov] = index\n    index_to_oov_dict[index] = oov\n    index+=1\nprint('Size OOV dictionary',len(index_to_oov_dict))\nprint('Same size', len(oov_to_index_dict) == len(index_to_oov_dict))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfDAHSUsiTDe","outputId":"abb14c16-8b4a-4814-fa4a-ed870ac57c64","execution":{"iopub.status.busy":"2023-12-01T19:01:37.782159Z","iopub.execute_input":"2023-12-01T19:01:37.782868Z","iopub.status.idle":"2023-12-01T19:01:37.795018Z","shell.execute_reply.started":"2023-12-01T19:01:37.782827Z","shell.execute_reply":"2023-12-01T19:01:37.794329Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Size OOV dictionary 292\nSame size True\n","output_type":"stream"}]},{"cell_type":"code","source":"oov_terms_train = check_OOV_terms(embedding_model_50, word_listing_train) #words to embed\noov_percentage_train = float(len(oov_terms_train)) * 100 / len(word_listing_train)\nprint(f\"Total OOV terms: {len(oov_terms_train)} ({oov_percentage_train:.2f}%)\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L60hr4JHiTDe","outputId":"e2db0d77-d860-4ae1-bb53-515d0fb59b56","execution":{"iopub.status.busy":"2023-12-01T19:01:37.796035Z","iopub.execute_input":"2023-12-01T19:01:37.797030Z","iopub.status.idle":"2023-12-01T19:01:37.874337Z","shell.execute_reply.started":"2023-12-01T19:01:37.796999Z","shell.execute_reply":"2023-12-01T19:01:37.873071Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Total OOV terms: 384 (5.04%)\n","output_type":"stream"}]},{"cell_type":"code","source":"new_POS_list = [[treebank_tag_to_index[tag] for tag in tags] for tags in df['POS']]\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWDxIGloiTDe","outputId":"457253fc-6476-417f-ed67-dea0ce73a7b4","execution":{"iopub.status.busy":"2023-12-01T19:01:37.875874Z","iopub.execute_input":"2023-12-01T19:01:37.876305Z","iopub.status.idle":"2023-12-01T19:01:37.970901Z","shell.execute_reply.started":"2023-12-01T19:01:37.876265Z","shell.execute_reply":"2023-12-01T19:01:37.969641Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#Vocabulary without oov\nword_listing = list(set(word_listing_corpus) - oov_terms)\nword_listing.append('UNK')\nword_listing.insert(0, (' '))  #may cause an error!!!\nprint(len(word_listing),len(word_listing_corpus),len(oov_terms),len(word_listing_corpus)-len(oov_terms))\nindex=0\nidx_to_word = {}\nword_to_idx = {}\nfor word in word_listing:\n    idx_to_word[index] = word\n    word_to_idx[word] = index\n    index+=1\nprint('Same length',len(word_to_idx)==len(idx_to_word))\nprint('Same length',len(word_listing)==len(idx_to_word))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7nuvyhBLiTDf","outputId":"18e71f27-03c1-4ca9-f21e-0a0ed04e09bf","execution":{"iopub.status.busy":"2023-12-01T19:01:37.972225Z","iopub.execute_input":"2023-12-01T19:01:37.972664Z","iopub.status.idle":"2023-12-01T19:01:37.990033Z","shell.execute_reply.started":"2023-12-01T19:01:37.972626Z","shell.execute_reply":"2023-12-01T19:01:37.988856Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"10657 10947 292 10655\nSame length True\nSame length True\n","output_type":"stream"}]},{"cell_type":"code","source":"sentences = []\n\nfor sentence in df[df['split'] == 'train'].sentence:\n    sentences.append(sentence)\n\nfor sentence in df[df['split'] != 'train'].sentence:\n    words = sentence.split()\n    modified_words = [word if word not in oov_terms else 'UNK' for word in words]\n    modified_sentence = ' '.join(modified_words)\n    sentences.append(modified_sentence)\nprint('Num of sentences: ',len(sentences))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ovng5DZkiTDg","outputId":"b7ae9843-3932-4919-8e2a-3234931fb888","execution":{"iopub.status.busy":"2023-12-01T19:01:37.991208Z","iopub.execute_input":"2023-12-01T19:01:37.992065Z","iopub.status.idle":"2023-12-01T19:01:38.022100Z","shell.execute_reply.started":"2023-12-01T19:01:37.992033Z","shell.execute_reply":"2023-12-01T19:01:38.020844Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Num of sentences:  3914\n","output_type":"stream"}]},{"cell_type":"code","source":"def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n                           embedding_dimension: int,\n                           word_to_idx: Dict[str, int],\n                           vocab_size: int,\n                           oov_terms: Dict[str,int] = None) -> np.ndarray:\n    embedding_matrix = np.zeros((vocab_size, embedding_dimension), dtype=np.float32)\n    for word, idx in tqdm(word_to_idx.items()):\n        if word == 'UNK':\n            embedding_matrix[idx] = np.zeros(embedding_dimension)\n        else:\n            try:\n                embedding_vector = embedding_model[word]\n            except (KeyError, TypeError):\n                embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n            embedding_matrix[idx] = embedding_vector\n\n    return embedding_matrix","metadata":{"id":"IV8KJlrHiTDg","execution":{"iopub.status.busy":"2023-12-01T19:01:38.023348Z","iopub.execute_input":"2023-12-01T19:01:38.023701Z","iopub.status.idle":"2023-12-01T19:01:38.031916Z","shell.execute_reply.started":"2023-12-01T19:01:38.023672Z","shell.execute_reply":"2023-12-01T19:01:38.030831Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Testing\nembedding_matrix_50 = build_embedding_matrix(embedding_model_50, 50, word_to_idx, len(word_to_idx))\nembedding_matrix_100 = build_embedding_matrix(embedding_model_100, 100, word_to_idx, len(word_to_idx))\nembedding_matrix_200 = build_embedding_matrix(embedding_model_200, 200, word_to_idx, len(word_to_idx))\nembedding_matrix_300 = build_embedding_matrix(embedding_model_300, 300, word_to_idx, len(word_to_idx))\n\nprint(f\"Embedding matrix shape: {embedding_matrix_50.shape}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHoKYUIAiTDg","outputId":"3307895c-81cf-46f1-992e-2d59e4d99bd2","execution":{"iopub.status.busy":"2023-12-01T19:01:38.033251Z","iopub.execute_input":"2023-12-01T19:01:38.033699Z","iopub.status.idle":"2023-12-01T19:01:38.217080Z","shell.execute_reply.started":"2023-12-01T19:01:38.033662Z","shell.execute_reply":"2023-12-01T19:01:38.215217Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"100%|██████████| 10657/10657 [00:00<00:00, 314186.59it/s]\n100%|██████████| 10657/10657 [00:00<00:00, 300337.96it/s]\n100%|██████████| 10657/10657 [00:00<00:00, 286020.41it/s]\n100%|██████████| 10657/10657 [00:00<00:00, 231553.88it/s]","output_type":"stream"},{"name":"stdout","text":"Embedding matrix shape: (10657, 50)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"encoded_sentences = [[word_to_idx[word] for word in sentence.split()] for sentence in sentences]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StdBH_QWiTDg","outputId":"e272960d-1cf5-45ac-fc14-ac0bd3da3cf5","execution":{"iopub.status.busy":"2023-12-01T19:01:38.218512Z","iopub.execute_input":"2023-12-01T19:01:38.218881Z","iopub.status.idle":"2023-12-01T19:01:38.249724Z","shell.execute_reply.started":"2023-12-01T19:01:38.218852Z","shell.execute_reply":"2023-12-01T19:01:38.248653Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# check length of longest sentence\nlengths = [len(seq) for seq in df['sentence']]\npadding_length = 600\nprint(\"Length of longest sentence: {}\".format(max(lengths)))\nprint(\"Amount of sentences: {}\".format((len(lengths))))\nsns.boxplot(lengths)\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"Z8GNIOfaiTDh","outputId":"9fce0892-face-4ed5-f0d8-6ada4db7af03","execution":{"iopub.status.busy":"2023-12-01T19:01:38.251084Z","iopub.execute_input":"2023-12-01T19:01:38.251487Z","iopub.status.idle":"2023-12-01T19:01:38.477689Z","shell.execute_reply.started":"2023-12-01T19:01:38.251460Z","shell.execute_reply":"2023-12-01T19:01:38.476649Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Length of longest sentence: 1265\nAmount of sentences: 3914\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"#df_file\nlengths_file = [len(seq) for seq in df_file['sentence']]\npadding_length = 600\nprint(\"Length of longest sentence: {}\".format(max(lengths_file)))\nprint(\"Amount of sentences: {}\".format((len(lengths_file))))\nsns.boxplot(lengths_file)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:01:38.479047Z","iopub.execute_input":"2023-12-01T19:01:38.479359Z","iopub.status.idle":"2023-12-01T19:01:38.648159Z","shell.execute_reply.started":"2023-12-01T19:01:38.479333Z","shell.execute_reply":"2023-12-01T19:01:38.647075Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Length of longest sentence: 4534\nAmount of sentences: 199\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"np_len = np.array(lengths)\nprint(np_len.shape)\nphrases = [seq for seq in df['sentence']]\nprint(len(phrases))\npositions = np_len > 600\nprint(positions)\n#print(sum(np_len < 200))\nlooooong_sentences = []\nfor i in range(np_len.shape[0]):\n    if positions[i]:\n        looooong_sentences.append(phrases[i])\nprint(looooong_sentences)\n\nfor i in range(len(phrases)):\n    if phrases[i] == looooong_sentences[0]:\n        print(i)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:01:38.649514Z","iopub.execute_input":"2023-12-01T19:01:38.650470Z","iopub.status.idle":"2023-12-01T19:01:38.661141Z","shell.execute_reply.started":"2023-12-01T19:01:38.650426Z","shell.execute_reply":"2023-12-01T19:01:38.659813Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"(3914,)\n3914\n[False False False ... False False False]\n['the following were barred or , where noted , suspended and consented to findings without admitting or denying wrongdoing : edward l. cole , jackson , miss. , $ 10,000 fine ; rita rae cross , denver , $ 2,500 fine and 30-day suspension ; thomas richard meinders , colorado springs , colo. , $ 2,000 fine , five-day suspension and eight-month suspension as a principal ; ronald a. cutrer , baton rouge , la. , $ 15,000 fine and one-month suspension ; karl grant hale , midvale , utah , $ 15,000 fine ; clinton p. hayne , new orleans , $ 7,500 fine and one-week suspension ; richard m. kane , coconut creek , fla. , $ 250,000 fine ; john b. merrick , aurora , colo. , $ 1,000 fine and 10-day suspension ; john p. miller , baton rouge , $ 2,000 fine and two-week suspension ; randolph k. pace , new york , $ 10,000 fine and 90-day suspension ; brian d. pitcher , new providence , n.j. , $ 30,000 fine ; wayne a. russo , bridgeville , pa. , $ 4,000 fine and 15-day suspension ; orville leroy sandberg , aurora , colo. , $ 3,500 fine and 10-day suspension ; richard t. marchese , las vegas , nev. , $ 5,000 and one-year suspension ; eric g. monchecourt , las vegas , $ 5,000 and one-year suspension ; and robert gerhard smith , carson city , nev. , two-year suspension . ']\n2500\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.utils import pad_sequences\npadded_sentences = pad_sequences(\n    encoded_sentences,\n    maxlen=padding_length,\n    padding='pre',\n    truncating='pre',\n    value=0 #his should be the space\n)\npadded_POS = pad_sequences(\n    new_POS_list,\n    maxlen=padding_length,\n    padding='pre',\n    truncating='pre',\n    value=0#10631\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOH_iX9fiTDh","outputId":"f8ed6bb5-a8f4-4b33-f42a-676ed809414b","execution":{"iopub.status.busy":"2023-12-01T19:01:38.662569Z","iopub.execute_input":"2023-12-01T19:01:38.662959Z","iopub.status.idle":"2023-12-01T19:01:38.708508Z","shell.execute_reply.started":"2023-12-01T19:01:38.662923Z","shell.execute_reply":"2023-12-01T19:01:38.707472Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# padded_sentences phrase x padding+real length\n#df_POS_new\nfrom keras.utils import to_categorical\ntraining_samples = df[df['split']=='train'].count().sentence\nvalidation_samples = df[df['split']=='validation'].count().sentence\nvalidation_samples+=training_samples\n\nX_train = padded_sentences[:training_samples,:]\nY_train = to_categorical(padded_POS[:training_samples,:])\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n\nX_val = padded_sentences[training_samples:validation_samples,:]\nY_val = to_categorical(padded_POS[training_samples:validation_samples,:])\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n\nX_test = padded_sentences[validation_samples:,:]\nY_test = to_categorical(padded_POS[validation_samples:,:])\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))","metadata":{"id":"HROcs8Y_iTDh","execution":{"iopub.status.busy":"2023-12-01T19:01:38.714657Z","iopub.execute_input":"2023-12-01T19:01:38.715020Z","iopub.status.idle":"2023-12-01T19:01:39.723734Z","shell.execute_reply.started":"2023-12-01T19:01:38.714988Z","shell.execute_reply":"2023-12-01T19:01:39.722821Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"variables = {\n    \"X_train\": X_train,\n    \"Y_train\": Y_train,\n    \"X_val\": X_val,\n    \"Y_val\": Y_val,\n    \"X_test\": X_test,\n    \"Y_test\": Y_test,\n    \"embedding_matrix\": embedding_matrix_50\n}\n\nfor name, value in variables.items():\n    print(f\"{name}.shape:\", value.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bRAfV8UgiTDh","outputId":"a9351bdf-db02-4434-ef1f-269f66be2f0f","execution":{"iopub.status.busy":"2023-12-01T19:01:39.725078Z","iopub.execute_input":"2023-12-01T19:01:39.725507Z","iopub.status.idle":"2023-12-01T19:01:39.733499Z","shell.execute_reply.started":"2023-12-01T19:01:39.725468Z","shell.execute_reply":"2023-12-01T19:01:39.732199Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"X_train.shape: (2143, 600)\nY_train.shape: (2143, 600, 46)\nX_val.shape: (985, 600)\nY_val.shape: (985, 600, 46)\nX_test.shape: (786, 600)\nY_test.shape: (786, 600, 46)\nembedding_matrix.shape: (10657, 50)\n","output_type":"stream"}]},{"cell_type":"code","source":"treebank_index_to_tag[0] = ' '\ntreebank_tag_to_index[' '] = 0\npunctuations_indeces = [0,27,36,41,42,43]","metadata":{"id":"ZVesomGAiTDh","execution":{"iopub.status.busy":"2023-12-01T19:01:39.735770Z","iopub.execute_input":"2023-12-01T19:01:39.736260Z","iopub.status.idle":"2023-12-01T19:01:39.742514Z","shell.execute_reply.started":"2023-12-01T19:01:39.736217Z","shell.execute_reply":"2023-12-01T19:01:39.741786Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import keras.backend as K\ndef macro_f1_score(num_classes, ignore_class_indices):\n    def f1(y_true, y_pred):\n        f1_scores = []\n        for i in range(num_classes):\n            if i not in ignore_class_indices:\n                true_positives = K.sum(K.cast(y_true[:, :, i] * y_pred[:, :, i], 'float32'))\n                possible_positives = K.sum(K.cast(y_true[:, :, i], 'float32'))\n                predicted_positives = K.sum(K.cast(y_pred[:, :, i], 'float32'))\n\n                precision = true_positives / (predicted_positives + K.epsilon())\n                recall = true_positives / (possible_positives + K.epsilon())\n\n                f1 = 2 * (precision * recall) / (precision + recall + K.epsilon()) if (precision + recall) > K.epsilon() else 0.0\n                f1_scores.append(f1)\n\n        macro_f1 = K.mean(K.stack(f1_scores), axis=0)\n        return macro_f1\n    return f1","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:01:39.743328Z","iopub.execute_input":"2023-12-01T19:01:39.743653Z","iopub.status.idle":"2023-12-01T19:01:39.755222Z","shell.execute_reply.started":"2023-12-01T19:01:39.743623Z","shell.execute_reply":"2023-12-01T19:01:39.754125Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed\nbidirect_model = Sequential()\nbidirect_model.add(Embedding(input_dim     = len(word_to_idx),\n                             output_dim    = 50,\n                             input_length  = padding_length,\n                             weights       = [embedding_matrix_50],\n                             trainable     = False\n))\nbidirect_model.add(Bidirectional(LSTM(64, return_sequences=True)))\nbidirect_model.add(TimeDistributed(Dense(units=len(treebank_index_to_tag), activation='softmax'))) #test if adding whitespace to vocabulary makes some differences\n# Compile the model\nbidirect_model.compile(optimizer='adam',\n                       loss='categorical_crossentropy',\n                       metrics=[macro_f1_score(num_classes=len(treebank_index_to_tag), ignore_class_indices=punctuations_indeces)])\n\n# Display the model summary\nbidirect_model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uiCGWGmLiTDi","outputId":"f864d2eb-44ce-4a43-dbcb-a2c4d51eee0c","execution":{"iopub.status.busy":"2023-12-01T19:01:39.756449Z","iopub.execute_input":"2023-12-01T19:01:39.756767Z","iopub.status.idle":"2023-12-01T19:01:39.876207Z","shell.execute_reply.started":"2023-12-01T19:01:39.756740Z","shell.execute_reply":"2023-12-01T19:01:39.874698Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embedding, Bidirectional, LSTM, Dense, TimeDistributed\n\u001b[1;32m      3\u001b[0m bidirect_model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m      4\u001b[0m bidirect_model\u001b[38;5;241m.\u001b[39madd(Embedding(input_dim     \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(word_to_idx),\n\u001b[0;32m----> 5\u001b[0m                              output_dim    \u001b[38;5;241m=\u001b[39m \u001b[43membedding_dimension\u001b[49m,\n\u001b[1;32m      6\u001b[0m                              input_length  \u001b[38;5;241m=\u001b[39m padding_length,\n\u001b[1;32m      7\u001b[0m                              weights       \u001b[38;5;241m=\u001b[39m [embedding_matrix],\n\u001b[1;32m      8\u001b[0m                              trainable     \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m ))\n\u001b[1;32m     10\u001b[0m bidirect_model\u001b[38;5;241m.\u001b[39madd(Bidirectional(LSTM(\u001b[38;5;241m64\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)))\n\u001b[1;32m     11\u001b[0m bidirect_model\u001b[38;5;241m.\u001b[39madd(TimeDistributed(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(treebank_index_to_tag), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))) \u001b[38;5;66;03m#test if adding whitespace to vocabulary makes some differences\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'embedding_dimension' is not defined"],"ename":"NameError","evalue":"name 'embedding_dimension' is not defined","output_type":"error"}]},{"cell_type":"code","source":"history_bidirectional_model = bidirect_model.fit(train_dataset, epochs=3, validation_data=validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:01:39.877375Z","iopub.status.idle":"2023-12-01T19:01:39.877797Z","shell.execute_reply.started":"2023-12-01T19:01:39.877612Z","shell.execute_reply":"2023-12-01T19:01:39.877630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model, which will use the custom F1 score metric that ignores punctuation\nloss, f1 = bidirect_model.evaluate(test_dataset, verbose=1)\n\n# Print the loss and macro F1 score\nprint(\"Loss: {0},\\nMacro F1 Score: {1}\".format(loss, f1))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:01:39.879447Z","iopub.status.idle":"2023-12-01T19:01:39.879838Z","shell.execute_reply.started":"2023-12-01T19:01:39.879658Z","shell.execute_reply":"2023-12-01T19:01:39.879676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_50[-1]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:05:11.338478Z","iopub.execute_input":"2023-12-01T19:05:11.338896Z","iopub.status.idle":"2023-12-01T19:05:11.346836Z","shell.execute_reply.started":"2023-12-01T19:05:11.338863Z","shell.execute_reply":"2023-12-01T19:05:11.345872Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from itertools import product\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import Adam, RMSprop, SGD\nimport numpy as np\n\n# Define hyperparameters\nembedding_matrices = [embedding_matrix_50, embedding_matrix_100, embedding_matrix_200, embedding_matrix_300] # build the actual matrices\noptimizers = [Adam, RMSprop, SGD]\nbatch_sizes = [32, 64, 128]\nlstm_sizes = [32, 64, 128]\nembedding_training_bool = [True,False]\nlearning_rates = [0.001, 0.01, 0.1]  # first one standard\n\n# Create a function to build and compile the model with given hyperparameters\ndef build_model(embedding_matrix, embedding_trainable_bool, lstm_size,optimizer,learning_rate):\n    model = Sequential()\n    model.add(Embedding(input_dim= len(word_to_idx),\n                        output_dim    = embedding_matrix.shape[-1],\n                        input_length  = padding_length,\n                        weights       = [embedding_matrix],\n                        trainable     = embedding_trainable_bool\n    ))    \n    model.add(Bidirectional(LSTM(units=lstm_size, return_sequences=True)))\n    model.add(TimeDistributed(Dense(units=len(treebank_index_to_tag), activation='softmax')))\n    model.compile(optimizer=optimizer(learning_rate=learning_rate),loss='categorical_crossentropy',\n                       metrics=[macro_f1_score(num_classes=len(treebank_index_to_tag), ignore_class_indices=punctuations_indeces)])\n    return model\n\n\n# Grid search loop\nbest_f1 = 0\nbest_params = {}\nfor (embedding_matrix, emb_training_bool, lstm_size, optimizer, learning_rate, batch_size) in product(embedding_matrices, embedding_training_bool, lstm_sizes, optimizers, learning_rates, batch_sizes):\n    model = build_model(embedding_matrix, emb_training_bool, lstm_size,optimizer,learning_rate)\n    \n    train_dataset = train_dataset.shuffle(buffer_size=len(X_train),seed=seed).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    validation_dataset = validation_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    \n    history_model = model.fit(train_dataset, epochs=40, validation_data=validation_dataset)\n    f1 = np.max(history_model.history['f1'])\n    if f1 > best_f1:\n        best_f1 = f1\n        best_params = {\n            'trainability embedding': emb_training_bool,\n            'lstm_size': lstm_size,\n            'embedding_matrix_shape': embedding_matrix.shape,\n            'optimizer': optimizer, \n            'learning_rate':learning_rate,\n            'batch_size': batch_size\n        }\n\nprint(\"Best f1:\", best_f1)\nprint(\"Best hyperparameters:\", best_params)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:09:15.638420Z","iopub.execute_input":"2023-12-01T19:09:15.639649Z","iopub.status.idle":"2023-12-01T19:10:47.104235Z","shell.execute_reply.started":"2023-12-01T19:09:15.639577Z","shell.execute_reply":"2023-12-01T19:10:47.102811Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Epoch 1/40\n67/67 [==============================] - 50s 623ms/step - loss: 1.3109 - f1: 0.0070 - val_loss: 0.1538 - val_f1: 0.0140\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[54], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m validation_dataset \u001b[38;5;241m=\u001b[39m validation_dataset\u001b[38;5;241m.\u001b[39mbatch(batch_size)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     40\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mbatch(batch_size)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m---> 42\u001b[0m history_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m f1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(history_model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f1 \u001b[38;5;241m>\u001b[39m best_f1:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1730\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1728\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():\n\u001b[0;32m-> 1730\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1731\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:2600\u001b[0m, in \u001b[0;36mModel.reset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m original_pss_strategy\n\u001b[1;32m   2598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(all_outputs)\n\u001b[0;32m-> 2600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2601\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resets the state of all the metrics in the model.\u001b[39;00m\n\u001b[1;32m   2602\u001b[0m \n\u001b[1;32m   2603\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2617\u001b[0m \n\u001b[1;32m   2618\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2619\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"wadawd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_bidirectional_model = bidirect_model.fit(X_train, Y_train, batch_size=64, epochs=10, validation_data=(X_val, Y_val))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OpSQPlRBiTDi","outputId":"27d047ed-0e26-4fa3-e368-44607bc231a5","execution":{"iopub.status.busy":"2023-12-01T19:01:39.882695Z","iopub.status.idle":"2023-12-01T19:01:39.883068Z","shell.execute_reply.started":"2023-12-01T19:01:39.882879Z","shell.execute_reply":"2023-12-01T19:01:39.882896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model, which will use the custom F1 score metric that ignores punctuation\nloss, f1 = bidirect_model.evaluate(X_test, Y_test, verbose=1)\n\n# Print the loss and macro F1 score\nprint(\"Loss: {0},\\nMacro F1 Score: {1}\".format(loss, f1))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ekSe-6E8iTDi","outputId":"0fc1aba7-140d-40e8-cb05-5e86c435fd9c","execution":{"iopub.status.busy":"2023-12-01T19:01:39.884719Z","iopub.status.idle":"2023-12-01T19:01:39.885232Z","shell.execute_reply.started":"2023-12-01T19:01:39.884976Z","shell.execute_reply":"2023-12-01T19:01:39.885002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true_classes = np.argmax(Y_test, axis=-1)\ny_true_classes.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:01:39.887281Z","iopub.status.idle":"2023-12-01T19:01:39.887838Z","shell.execute_reply.started":"2023-12-01T19:01:39.887537Z","shell.execute_reply":"2023-12-01T19:01:39.887564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_to_tag","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:01:39.889183Z","iopub.status.idle":"2023-12-01T19:01:39.889718Z","shell.execute_reply.started":"2023-12-01T19:01:39.889437Z","shell.execute_reply":"2023-12-01T19:01:39.889462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\ny_pred = bidirect_model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=-1)\nprint(y_pred_classes.shape)\n\ny_true_classes = np.argmax(Y_test, axis=-1)\ny_pred_classes_flat = y_pred_classes.flatten()\n\ny_true_classes_flat = y_true_classes.flatten()\n\nindex_to_word = {v: k for k, v in word_to_idx.items()}\nindex_to_tag = {v: k for k, v in treebank_index_to_tag.items()}\nmisclassified = []\nfor (pred, true) in zip(y_pred_classes_flat, y_true_classes_flat):\n    if pred != true:\n        #word_index = X_test[i // padding_length][i % padding_length]\n        #word = index_to_word[word_index]\n        true_tag = treebank_index_to_tag[pred]\n        pred_tag = treebank_index_to_tag[true]\n        misclassified.append((true_tag, pred_tag)) # (predicted_tag, true_tag, sentence_number, position_inside_sentence)\n\n\n#Count occurrences of each misclassified pair\nmisclassification_counter = Counter(misclassified)\n\n#Get the most common misclassified pairs\nmost_common_misclassifications = misclassification_counter.most_common()\n\n#Print or process the most common misclassifications\nfor pair, count in most_common_misclassifications:\n    print(f\"Misclassified Pair: {pair}, Frequency: {count}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-01T19:01:39.891237Z","iopub.status.idle":"2023-12-01T19:01:39.891782Z","shell.execute_reply.started":"2023-12-01T19:01:39.891493Z","shell.execute_reply":"2023-12-01T19:01:39.891520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is to check the output\n\npredictions = bidirect_model.predict(X_test)\n\n# Convert probabilities to class indices\npredicted_label_indices = np.argmax(predictions, axis=-1)\n\npadding_token_index = 0\n\n# Now map indices to tags, ignoring padding tokens\npredicted_tags = []\nfor sequence_idx, sequence in enumerate(predicted_label_indices):\n    sequence_tags = []\n    for token_idx, token_prediction in enumerate(sequence):\n        # Only add the tag if the corresponding token in X_test is not a padding token\n        if X_test[sequence_idx, token_idx] != padding_token_index:\n            sequence_tags.append(treebank_index_to_tag[token_prediction])\n    predicted_tags.append(sequence_tags)\n\n# Each element in predicted_tags is now a list of tag names corresponding to each non-padding token in each sequence\nfor sequence in predicted_tags:\n    print(sequence)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"BqHtzkj3iTDi","outputId":"f98841e7-b9e4-4625-b50a-b8e9eb093169","execution":{"iopub.status.busy":"2023-12-01T19:01:39.893483Z","iopub.status.idle":"2023-12-01T19:01:39.894033Z","shell.execute_reply.started":"2023-12-01T19:01:39.893757Z","shell.execute_reply":"2023-12-01T19:01:39.893782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy the baseline_model\nmodel_1 = Sequential()\nmodel_1.add(Embedding(input_dim     = len(word_to_idx),\n                             output_dim    = embedding_dimension,\n                             input_length  = padding_length,\n                             weights       = [embedding_matrix],\n                             trainable     = False\n))\nmodel_1.add(Bidirectional(LSTM(64, return_sequences=True)))\n# Add one additional LSTM layer\nmodel_1.add(LSTM(32, return_sequences=True, name='additional_LSTM'))\nmodel_1.add(TimeDistributed(Dense(units=len(treebank_index_to_tag), activation='softmax')))\n\nmodel_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_1.summary()\n","metadata":{"id":"_xUM8CVEiTDj","execution":{"iopub.status.busy":"2023-12-01T19:01:39.895565Z","iopub.status.idle":"2023-12-01T19:01:39.896263Z","shell.execute_reply.started":"2023-12-01T19:01:39.895940Z","shell.execute_reply":"2023-12-01T19:01:39.895992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1_training = model_1.fit(X_train, Y_train, batch_size=64, epochs=2, validation_data=(X_val, Y_val))","metadata":{"id":"dyENMQhGiTDj","execution":{"iopub.status.busy":"2023-12-01T19:01:39.897594Z","iopub.status.idle":"2023-12-01T19:01:39.898250Z","shell.execute_reply.started":"2023-12-01T19:01:39.898062Z","shell.execute_reply":"2023-12-01T19:01:39.898083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_1, accuracy_1 = model_1.evaluate(X_test, Y_test, verbose = 1)","metadata":{"id":"lXMDML8iiTDj","execution":{"iopub.status.busy":"2023-12-01T19:01:39.899649Z","iopub.status.idle":"2023-12-01T19:01:39.900150Z","shell.execute_reply.started":"2023-12-01T19:01:39.899966Z","shell.execute_reply":"2023-12-01T19:01:39.899987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2 = Sequential()\nmodel_2.add(Embedding(input_dim     = len(word_to_idx),\n                             output_dim    = embedding_dimension,\n                             input_length  = padding_length,\n                             weights       = [embedding_matrix],\n                             trainable     = False\n))\nmodel_2.add(Bidirectional(LSTM(64, return_sequences=True)))\n# Add one additional dense layer\nmodel_2.add(Dense(64, activation='relu', name='additional_Dense_layer'))\nmodel_2.add(TimeDistributed(Dense(units=len(treebank_index_to_tag), activation='softmax')))\n\nmodel_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_2.summary()","metadata":{"id":"EaTKPjUbiTDj","execution":{"iopub.status.busy":"2023-12-01T19:01:39.901799Z","iopub.status.idle":"2023-12-01T19:01:39.902221Z","shell.execute_reply.started":"2023-12-01T19:01:39.902030Z","shell.execute_reply":"2023-12-01T19:01:39.902050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2_training = model_2.fit(X_train, Y_train, batch_size=64, epochs=2, validation_data=(X_val, Y_val))","metadata":{"id":"md13gHHkiTDj","execution":{"iopub.status.busy":"2023-12-01T19:01:39.903536Z","iopub.status.idle":"2023-12-01T19:01:39.903966Z","shell.execute_reply.started":"2023-12-01T19:01:39.903774Z","shell.execute_reply":"2023-12-01T19:01:39.903793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_2, accuracy_2 = model_2.evaluate(X_test, Y_test, verbose = 1)","metadata":{"id":"CdAzFrLqiTDj","execution":{"iopub.status.busy":"2023-12-01T19:01:39.908412Z","iopub.status.idle":"2023-12-01T19:01:39.908901Z","shell.execute_reply.started":"2023-12-01T19:01:39.908686Z","shell.execute_reply":"2023-12-01T19:01:39.908710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualise training history\nplt.plot(bidirect_training.history['accuracy'])\nplt.plot(bidirect_training.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc=\"lower right\")\nplt.show()","metadata":{"id":"7u-HNNUaiTDj","execution":{"iopub.status.busy":"2023-12-01T19:01:39.910257Z","iopub.status.idle":"2023-12-01T19:01:39.910671Z","shell.execute_reply.started":"2023-12-01T19:01:39.910462Z","shell.execute_reply":"2023-12-01T19:01:39.910480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Section 7:**\n\nDefinition of the evaluation metrics for comparison.","metadata":{"id":"rE40VjJqiTDj"}}]}